"title","company","location","link","description"
"Mid-Junior DevOps Engineer - USA","HERE","New York, NY","https://www.linkedin.com/jobs/view/mid-junior-devops-engineer-usa-at-here-4347377348?position=1&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=4WoYN7%2B7XqnzGzCpiEizTg%3D%3D","Mid-Junior DevOps Engineer

Location: New York, NY / Hybrid Remote / Remote within USA (EST / CST time zone)

We have an office in New York City and this position can either be based in the office, hybrid remote, or remote within the EST/CST time zones (subject to your existing legal right to work in the jurisdiction).

About HERE

Everything works right here‚Ñ¢.

Traditional browsers weren't built for work. In today's enterprise environment‚Äîwhere security threats are constant and productivity is critical‚Äîlegacy browsers fall short. That's why we built HERE, the browser purpose-built for work.

Powered by Chromium, HERE Enterprise Browser combines enterprise-grade security, seamless productivity, and native AI integration in one secure, intelligent workspace. Designed for regulated industries, HERE offers deep policy controls, identity-based access, secure workspace isolation, and full interoperability across SaaS, legacy, and virtualized environments. Our platform enables teams to work faster, more securely, and more intelligently‚Äîwithout compromise.

HERE technology is trusted by 90% of global banks and also used within the U.S. Intelligence Community and other sectors. We're backed by some of the world's most respected financial institutions and venture firms, including Bain Capital Ventures, Bank of America, J.P. Morgan, Wells Fargo and IQT, the not-for-profit strategic investor that accelerates the introduction of groundbreaking technologies to enhance the national security of America and its allies.

About the Role

HERE is seeking a mid-junior DevOps Engineer to join our infrastructure team! The primary responsibilities for this role will span CI/CD pipeline engineering and cloud operations, maintaining and improving our GitHub and GitLab CI/CD pipelines, and supporting our AWS cloud infrastructure. In this role, you will gain hands-on experience with real production build systems and cloud platforms- while having the opportunity to work on practical projects that directly impact both our development velocity and operational reliability.

We're actively evolving toward a cloud-agnostic, multi-cloud architecture and migrating to Kubernetes for container orchestration. While current AWS and ECS experience is essential, having exposure to Azure, GCP, and Kubernetes will position you well for our infrastructure roadmap.

This role offers the opportunity to collaborate with senior engineers who will provide guidance and mentorship, whilst giving you ownership of projects across the DevOps lifecycle. This is an excellent platform for building practical experience with modern build engineering (CI/CD automation, cloud infrastructure, and deployment practices) within a production environment.

Responsibilities


CI/CD Pipeline Development:
Build, maintain, and optimize GitLab CI/CD pipelines for multi-platform builds (Windows, macOS, Linux).
Work with YAML configurations, pipeline stages, artifacts, and deployment workflows.
Cloud Infrastructure Operations:
Help maintain and improve AWS infrastructure including ECS/Fargate deployments, RDS databases, Route53 DNS, VPC networking, and IAM policies.
Support multi-tenant and multi-region architecture.
Container & Deployment Management:
Work with Docker containers, ECS task definitions, and ECR registries.
Deploy and manage containerized Node.js applications in production environments.
Release Management:
Help manage release processes including version promotion, release channels (canary, beta, stable), and automated deployment to staging and production environments.
Database Operations:
Support PostgreSQL on AWS RDS‚Äîbackups, SSH tunneling through bastion hosts, read-only user management, and database configuration for multi-tenant environments.
Automation & Scripting:
Write and maintain automation scripts in Bash, PowerShell, Python, and Node.js.
Build tools to improve infrastructure reliability and developer experience.
Internal Tools Support:
Help maintain web-based DevOps tools built with Express.js, React, and TypeScript‚Äîtools for cloud settings management, tenant provisioning, and deployment monitoring.

What We're Looking For

Ideally 2 to 4 years of experience with the following core requirements:


GitLab CI/CD: Experience with GitLab CI/CD pipelines‚ÄîYAML configuration, stages, jobs, artifacts, rules, dependencies.
Understanding of CI/CD best practices and pipeline optimization.
AWS Cloud Fundamentals: Practical experience with core AWS services‚ÄîEC2, ECS/Fargate, RDS, Route53, VPC, IAM, Secrets Manager, CloudWatch. Comfortable navigating the AWS Console and CLI.
Multi-Platform Scripting: Solid scripting skills in Bash (Linux) and PowerShell (Windows). Ability to write maintainable automation scripts for both platforms.
Containerization: Hands-on Docker experience‚Äîbuilding images, writing Dockerfiles, docker-compose, understanding container networking, and working with ECS/ECR.
Build Systems: Experience with build tools and package managers‚Äînpm/Node.js, .NET/NuGet, Python packaging. Understanding of dependency management and build artifacts.
Version Control: Strong Git fundamentals‚Äîbranching strategies, merge requests, tagging. Experience with GitHub (or GitLab) workflows and code review practices.
Linux/Unix & Windows: Comfortable in both environments‚ÄîSSH, file permissions, package managers, systemd, PowerShell. Understanding of cross-platform operational challenges.
Node.js/JavaScript: Comfortable reading and writing JavaScript/Node.js code. Experience with npm, package.json, and basic Express.js applications for tooling.


Nice to Have


Kubernetes experience (EKS, GKE, AKS) or willingness to learn, we're migrating from ECS to K8s
Multi-cloud experience (Azure, GCP) or cloud-agnostic architecture knowledge
GitLab Runner administration and configuration
AWS CDK or CloudFormation for Infrastructure as Code
Terraform for multi-cloud infrastructure management
TypeScript development experience
PostgreSQL database administration and optimization
.NET build systems and NuGet package management
React or frontend framework experience
Airflow or workflow orchestration tools
Helm charts and Kubernetes manifest management


What We're Offering

Benefits -


Generous Paid Time Off, Paid Holidays & Sick Time
Competitive & Comprehensive Health Insurance
Thoughtfully-Planned Paid Parental Leave
Financial Well-Being Plans (FSA) (401k) (Life Insurance)
Stock Options
Professional Development Courses
Employee Resource Groups


Additional Perks -


One Medical - Free Membership
Talkspace - Mental Health Therapy 24/7
Team Lunches
Casual dress code
Commuter Benefits (NYC employees only)
Citibike (NYC employees only)


Life at HERE

At HERE, we pride ourselves on fostering a friendly, collaborative, and supportive culture that truly respects the diversity of thought. Our goal is to create a space where employees can learn and innovate, and overall, have a good time doing it. We value and appreciate that our employees have a wide set of interests and experiences and put importance on taking the time to get to know one another and form relationships. From virtual socials and in-person events, to informal meetings and employee resource groups, we make it easy to engage and connect. Our environment promotes a productive, enjoyable learning experience - aligned together, working to create compelling solutions for our clients. Everything works right here.‚Ñ¢

We are HERE - Read about our recent rebrand from OpenFin to HERE

Recent Awards


Voted ""Enterprise Browser of the Year"" by CIO Review (2025)
Voted ""100 Best Midsize Companies to Work For in NYC"" by BuiltIn (2025)
Voted ""Top 10 Contact Center Technologies & Capabilities of 2024"" by CX Today (2024)
Voted ""Best Enterprise Environment for Interoperability"" by TradingTech Insight Awards Europe (2024)
Voted ""Top 50 Best Startups to Work for in the US"" & ""Top 50 Best Startups to Work for in New York"" by BuiltIn (2024)
Voted as a ""Best Employer Award"" finalist at the UK FinTech Awards (2023)
Voted ""Best FinTech Company CEO"" at the FinTech Breakthrough Awards (2023)
Voted ""Best Internal Talent Team"" by Financial Technologist (2023)
Voted ""Best Solution for Workflow Automation"" at the Trading Tech Insight Awards (2023)
Voted ""Top Innovator Across Financial Markets"" in TabbFORUM NOVA Awards (2023)
Voted ""Best User Interface Innovation"" in the Risk Markets Technology Awards (2023)
Voted ""Top 100 Most Promising Private FinTech Companies"" by CB Insights (2023)
Voted ""Most Influential Financial Technology Firm"" by Harrington Starr (2023)


RECRUITERS NOTICE: Recruiters - if you wish to reach out to us regarding this job posting, you may reach out to externalrecruitment@here.io in order for your communication to be reviewed. HERE will review these communications if external help is needed for a position. Agencies may not contact individuals within our organization with solicitations. Firms that do not follow these guidelines risk having all communication from their firm being blocked. We thank you in advance for your cooperation in following our process.

Sponsorship - While we highly value all of our candidates, we are not offering sponsorship for this role.

Salary Range: $70k - $120k

Salary Range Disclaimer: This base salary range represents the low and high end salary range for this particular position; not all encompassing of the total compensation package. Actual salaries may vary depending upon but not limited to experience, special skill set, education and location. This range represents only one aspect of HERE's total compensation package offered to employees. Other forms of compensation may be stock options, commissions, paid time off and other variable benefits. Learn more about additional HERE compensation benefits above."
"junior devops engineer","OVA.Work","Alpharetta, GA","https://www.linkedin.com/jobs/view/junior-devops-engineer-at-ova-work-4309344701?position=2&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=THU4aigkkfKy8A4BQest%2BA%3D%3D","Job Title: Junior DevOps Engineer

Location: Remote

Job Type: Full-time

Experience Level: Entry-Level (0-2 years)

Department: IT / Engineering / DevOps

Job Summary

We are looking for a motivated and detail-oriented Junior DevOps Engineer to join our growing DevOps team. This role is ideal for someone with a foundational understanding of DevOps practices and a passion for automation, cloud technologies, and continuous integration/deployment. You will assist in maintaining and improving our infrastructure, deployment pipelines, and monitoring systems.

Key Responsibilities


Assist in the setup, maintenance, and monitoring of CI/CD pipelines.
Support cloud infrastructure (AWS, Azure, GCP) and help manage deployments.
Collaborate with development and operations teams to ensure reliable software delivery.
Write scripts and automation tools to streamline operations and deployments.
Monitor system performance and troubleshoot issues in development and production environments.
Maintain documentation for infrastructure and deployment processes.
Learn and apply best practices in security, scalability, and reliability.


Required Qualifications


Bachelor's degree in Computer Science, Information Technology, or related field.
Basic understanding of DevOps principles and software development lifecycle.
Familiarity with Linux/Unix systems and shell scripting.
Exposure to cloud platforms (AWS, Azure, or GCP).
Experience with version control systems (e.g., Git).
Knowledge of CI/CD tools (e.g., Jenkins, GitLab CI, GitHub Actions).
Strong problem-solving and communication skills.
Eagerness to learn and grow in a fast-paced environment.


Preferred Qualifications


Internship or project experience in DevOps or system administration.
Familiarity with containerization tools (Docker) and orchestration (Kubernetes).
Experience with Infrastructure as Code (Terraform, Ansible).
Basic knowledge of monitoring tools (Prometheus, Grafana, ELK Stack).


Benefits


Competitive salary and growth opportunities.
Mentorship from senior engineers.
Health and wellness benefits.
Flexible work hours and remote work options.
Access to training and certification programs."
"DevOps Engineer - Remote","The Dignify Solutions, LLC","Newtown Square, PA","https://www.linkedin.com/jobs/view/devops-engineer-remote-at-the-dignify-solutions-llc-4341955705?position=3&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=voMTeOJraISKk8dt%2FwGsew%3D%3D","Over 12 -15 years of overall expereince needed.
A solid foundation in computer science, with strong competencies in data structures, algorithms, and software design.
Large systems software design and development experience.
Experience performing in-depth troubleshooting and unit testing with both new and legacy production systems.
Experience in programming and experience with problem diagnosis and resolution.
Kubernetes (3-4 YOE) and Fieldglass Experience (1-2 YOE)"
"DevOps Engineer - Remote","The Dignify Solutions, LLC","Newtown Square, PA","https://www.linkedin.com/jobs/view/devops-engineer-remote-at-the-dignify-solutions-llc-4347005704?position=4&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=e9rtde0cgCWmAvwsXQQv0A%3D%3D","Bachelor's degree in a technical field such as computer science, computer engineering or related field required 0-2 years experience required.
1-2 years of experience with Kubernetes.
ISBN experience preferred.
A solid foundation in computer science , with strong competencies in data structures, algorithms, and software design large systems software design and development experience.
Experience performing in-depth troubleshooting and unit testing with both new and legacy production systems experience in programming and experience with problem diagnosis and resolution."
"Junior DevOps Engineer","GliaCell Technologies","Hanover, MD","https://www.linkedin.com/jobs/view/junior-devops-engineer-at-gliacell-technologies-4338894490?position=5&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=36uXRnltvpOGN%2BEUUQO1iA%3D%3D","An active or rein-statable TS/SCI with Polygraph security clearance is REQUIRED. Please do not apply if you currently do not possess this level of clearance.***


Are you a Junior DevOps Engineer who is ready for a new challenge that will launch your career to the next level?


Tired of being treated like a company drone?
Tired of promised adventures during the hiring phase, then being dropped off on a remote contract and never seen or heard from the mothership again?
Our engineers were certainly tired of the same.


At GliaCell our slogan is ‚ÄúWe make It happen‚Äù.


We will immerse you in the latest technologies.
We will develop and support your own personalized training program to continue your individual growth.
We will provide you with work that matters with our mission-focused customers, and surround you with a family of brilliant engineers.


Culture isn‚Äôt something you need to talk about‚Ä¶if it just exists.

If this sounds interesting to you, then we‚Äôd like to have a discussion regarding your next adventure! If you want to be a drone, this isn‚Äôt the place for you.

We Make It Happen!

GliaCell Technologies focuses on Software & System Engineering in Enterprise and Cyber Security solution spaces. We excel at delivering stable and reliable software solutions using Agile Software Development principles. These provide us the capability to deliver a quick turn-around using interactive applications and the integration of industry standard software stacks.

GliaCell‚Äôs Enterprise capabilities include Full-Stack Application Development, Big Data, Cloud Technologies, Analytics, Machine Learning, AI, and DevOps Containerization. We also provide customer solutions in the areas of CND, CNE, and CNO by providing our customers with assessments and solutions in Threat Mitigation, Vulnerability Exposure, Penetration Testing, Threat Hunting, and Preventing Advanced Persistent Threat.

We Offer


Long term job security
Competitive salaries & bonus opportunities
Challenging work you are passionate about
Ability to work with some amazingly talented people


Job Description

GliaCell is seeking a Junior DevOps Engineer on one of our subcontracts. This is a full-time position offering the opportunity to support a U.S. Government customer. The mission is to provide technical expertise that assists in sustaining critical mission-related software and systems to a large government contract.

Responsibilities


Establishing a test framework and automated tests utilizing Cucumber and Cypru
Knowledgeable in Microservices design & architecture, CI/CD, Test frameworks and automation, Agile Methodology.
Execute load and performance testing, chaos testing, functional testing and end-to-end testin
Agile development and delivery of software
Communication and collaboration: Software Development is a team-oriented discipline. Engineers need to be able to communicate and collaborate effectively with other team members, as well as with stakeholders.


Required Skills


Python and Cucumber


Desired Skills:


AWS services such as Lambdas, Step Functions, EC2 and S3


Key Requirements

To be considered for this position you must have the following:


Possess an active or rein-statable TS/SCI with Polygraph security clearance.
U.S. Citizenship.
Works well independently as well as on a team.
6+ years experience as a Developer in programs and contracts of similar scope, type, and complexity is required. A bachelor‚Äôs degree in a technical discipline from an accredited college or university is required. Five (4) years of development experience may be substituted for a bachelor‚Äôs degree.


Location: Annapolis Junction, MD

Salary Range: The salary range for this full-time position is $50,000 to $120,000. Our salary ranges are determined by position, level, skills, professional experience, relevant education and certifications. The range displayed on each job posting reflects the minimum and maximum target salaries for this position across our projects. Within the range, your salary is determined by your individual benefits package selection. Your recruiter can share more about the specific salary range for your preferred position during the hiring process.

Benefits


Medical, Dental, and Vision Coverage for Employee and Dependents
Up to 25 Days of Paid Time Off
Up to 40 hours of PTO Carryover
11 Federal Government Holidays
Work From Home Opportunities
401K Company Contribution, Fully Vested Day 1
Discretionary, Certification, and Sign-On Bonus Potential
Employee Referral Bonus Program
Annual Professional Development
100% Premium Covered for Life & Disability Insurances
Additional Voluntary Life Insurance Coverage Available
Employee Assistance Program
Travel Protection Program
Financial Planning Assistance
Bereavement and Jury Duty Leave
Monthly Team and Family Events
Technology Budget
Global Entry
Annual Swag Budget


Learn more about GliaCell Technologies: https://gliacelltechnologies.applytojob.com/apply/

GliaCell Technologies, LLC is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status."
"DevOps Cloud Engineer Based in U.S.A","Advancio","United States","https://www.linkedin.com/jobs/view/devops-cloud-engineer-based-in-u-s-a-at-advancio-4324442139?position=6&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=CgsJD6qhtwkrem4%2FidgvnQ%3D%3D","This is a remote position.

Who We Are:


At Advancio, we are passionate about technology and its ability to transform the world. We are rapidly expanding and building a company where we serve exceptional businesses, hire top talent, and have a lot of fun doing what we love!


Job Summary:

We are seeking a skilled DevOps Cloud Engineer to design, implement, and manage scalable cloud-based infrastructure and DevOps processes. The ideal candidate will have extensive experience with cloud platforms, CI/CD pipelines, and automation tools, ensuring the efficient deployment and operation of applications.


What will you do:


Design, deploy, and manage cloud infrastructure on platforms such as AWS, Azure, or Google Cloud Platform (GCP).

Build and maintain CI/CD pipelines to streamline development and deployment processes.

Automate infrastructure provisioning, configuration, and monitoring using tools like Terraform, Ansible, or similar.

Ensure system reliability, availability, and performance through robust monitoring and alerting.

Collaborate with development teams to optimize the delivery and scalability of applications.

Manage containerized workloads using Docker and orchestration platforms such as Kubernetes.

Implement security best practices for cloud environments, including identity management, encryption, and compliance adherence.

Stay updated with the latest DevOps tools and methodologies to enhance team efficiency.




Requirements






5+ years of experience in DevOps, cloud engineering, or related roles.

Advanced English communication skills, both verbal and written.

Proficiency in at least one major cloud platform (AWS, Azure, or GCP).

Hands-on experience with CI/CD tools (e.g., Jenkins, GitLab CI/CD, CircleCI).

Strong scripting skills in Python, Bash, or similar languages.

Solid knowledge of infrastructure-as-code (IaC) tools like Terraform or CloudFormation.

Experience with containerization (Docker) and orchestration (Kubernetes).

Familiarity with monitoring and logging tools like Prometheus, Grafana, or ELK Stack.

Strong understanding of networking, security, and system architecture."
"DeVops Engineer","Pittsburgh Robotics Network","Pittsburgh, PA","https://www.linkedin.com/jobs/view/devops-engineer-at-pittsburgh-robotics-network-4347073200?position=7&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=bYxoP5cUDQ41zaK2mzAdOg%3D%3D","DevOps Engineer

TDK SensEI

Pittsburgh, PA

This position is for our Pittsburgh, PA office - only apply if you are based there or willing to relocate.

At TDK SensEI, we are transforming how industrial customers utilize and interact with sensor data. We specialize in developing advanced AI solutions capable of running directly on edge devices. By processing data locally, TDK SensEI enhances real-time decision-making, privacy, security, and cost efficiency. Our offerings include automated machine learning tools, AI-powered condition-based monitoring systems, and various sensor devices optimized for low latency and power consumption. Collaborating with leading global companies, we empower teams to effortlessly devise and implement machine learning solutions for industrial applications, all without the need for coding.

We are seeking a Dev Ops engineer to join our team. In this position, the candidate will be responsible for managing, operating, and provisioning cloud environments such as AWS, Azure, Google cloud. You will work with development, security, and operations teams to deploy, scale, and operate dev environments. You are also responsible for improving and automating the dev environment. You will establish configuration management, automate our infrastructure, implement continuous integration, and train the team in DevOps best practices.

As a Dev Ops Engineer, Your Responsibilities Will Include


Designing, implementing, and maintaining tools and processes for continuous integration, delivery, and deployment of software
Working with developers to deploy and manage code changes
Working with operations staff to ensure that systems are up and running smoothly
Automating, monitoring, testing, configuring, networking, and Infrastructure as Code (IaC)
Streamlining and automating processes while troubleshooting existing development procedures
Managing the creation, release, and configuration of production systems
Architecting and optimizing several service components running on AWS environment


Skills & Requirements


Bachelor‚Äôs degree or equivalent experience
Minimum 2 years of experience in DevOps, infrastructure automation or similar role
Knowledge of Linux/UNIX administration
Proficiency in Python, JavaScript and other script environments (e.g. bash)
Experience with containerization technologies, Docker and associated tooling
Experience designing and implementing CI/CD pipelines
Experience operating databases such as PostgreSQL or MySQL, especially in cloud-native services like RDS
Awareness of critical concepts in DevOps and Agile principles
US work authorization


Nice To Have


AWS certifications (e.g., AWS Certified DevOps Engineer, AWS Certified Solutions Architect).
Familiarity with other cloud providers (Azure, Google Cloud).
Experience with container orchestration systems such as Kubernetes/EKS"
"DevOps Engineer","Princeton IT Services, Inc","Englewood Cliffs, NJ","https://www.linkedin.com/jobs/view/devops-engineer-at-princeton-it-services-inc-4338714288?position=8&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=Pgf9nt5Gw2GVC2ESZ9thmg%3D%3D","Job Title: DevOps Engineer

Location: Englewood Cliffs, NJ

Employment Type: W2 Only

Job Summary

We are seeking a DevOps Engineer with strong hands-on experience in Linux, Docker, and Kubernetes to support and optimize our deployment environment in Englewood Cliffs, NJ. This is a W2-only role requiring solid skills in automation, CI/CD, and container orchestration. The ideal candidate will ensure smooth application releases, maintain system stability, and collaborate closely with development teams.

Key Responsibilities


Manage and support Linux-based systems in production and staging environments.
Build, maintain, and optimize CI/CD pipelines for automated deployments.
Create, manage, and troubleshoot Docker containers and images.
Deploy, monitor, and tune Kubernetes clusters and workloads.
Automate infrastructure tasks using Shell or Python scripts.
Implement and manage monitoring and logging tools (Prometheus, Grafana, ELK, etc.).
Troubleshoot system, container, and cluster-level issues end-to-end.
Work cross-functionally with development and QA teams to ensure smooth releases.


Required Skills


8+ years of DevOps or related experience.
Strong hands-on experience with Linux administration.
Solid experience working with Docker for containerization.
Strong working knowledge of Kubernetes (deployments, scaling, troubleshooting).
Experience building CI/CD pipelines (Jenkins, GitLab CI, GitHub Actions).
Strong scripting skills in Shell/Bash/Python.
Experience with monitoring and logging tools."
"DevOps Engineer","Lean TECHniques","Johnston, IA","https://www.linkedin.com/jobs/view/devops-engineer-at-lean-techniques-4336685413?position=9&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=Tc9n3v6%2Bgp8MBxrJNOShUA%3D%3D","Maybe you‚Äôre bored and need a new challenge. Or you‚Äôre sick of all the bureaucracy and just want to focus on designing kick-ass software.

Whatever the reason, we want you to know that LT is different. And not just air quotes ‚Äúdifferent,‚Äù but more like ‚Äúbreathing easy for the first time in a long time‚Äù different.

It‚Äôs a place where you can write your own story and make a difference along the way. At LT, you‚Äôll have the freedom and flexibility to do what you think needs to be done, and you‚Äôll get to do it while working alongside a team of other curious individuals who love a good challenge too.

We‚Äôre currently looking to add a DevOps Engineer to our crew of nerds. If you‚Äôre someone who has 5+ years of DevOps experience, we'd love to chat!"
"DevOps Engineer","LifeMD","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-lifemd-4337132819?position=10&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=BUU%2FyXgcs7x1IVS82WmFIg%3D%3D","About us:

LifeMD is a leading digital healthcare company committed to expanding access to virtual care, pharmacy services, and diagnostics by making them more affordable and convenient for all.¬†Focused on both treatment and prevention, our unique care model is designed to optimize the patient experience and improve outcomes across more than 200 health concerns.¬†

To support our expanding patient base, LifeMD leverages a vertically-integrated, proprietary digital care platform, a 50-state affiliated medical group, a 22,500-square-foot affiliated pharmacy, and a U.S.-based patient care center.¬†Our company ‚Äî with offices in New York City; Greenville, SC; and Huntington Beach, CA ‚Äî is powered by a dynamic team of passionate professionals. From clinicians and technologists to creatives and analysts, we're united by a shared mission to revolutionize healthcare.¬†Employees enjoy a collaborative and inclusive work environment, hybrid work culture, and numerous opportunities for growth. Want your work to matter? Join us in building a future of accessible, innovative, and compassionate care.


About the role:

LifeMD is seeking a highly motivated and experienced DevOps Engineer to join our dynamic Technology team. This individual will serve as a critical link between software development and IT operations, playing a pivotal role in designing, implementing, and maintaining automated processes for software delivery, infrastructure management, and system monitoring. The primary objective is to accelerate our release cycles, enhance system stability, and improve overall operational efficiency across our diverse cloud infrastructure, all while strictly adhering to stringent healthcare industry compliance standards, including HIPAA and SOX.


Responsibilities:


Design, implement, and manage scalable, secure, and cost-effective cloud infrastructure primarily on AWS using Terraform
Develop and version control Terraform modules for automated provisioning, updating, and de-provisioning of cloud resources (e.g., EC2, S3, RDS, VPC, Lambda in AWS)
Design, build, and optimize automated CI/CD pipelines using GitHub Actions for various applications and microservices
Integrate automated testing, static code analysis, security scanning, and deployment steps into CI/CD workflows for high quality and secure releases
Implement, configure, and maintain comprehensive monitoring, logging, and alerting solutions (e.g., AWS CloudWatch, Datadog) for all environments
Develop custom dashboards, metrics, and alerts for real-time visibility into system health, performance, and security events
Proactively analyze logs and metrics to identify potential bottlenecks and issues
Participate in on-call rotations to swiftly respond to and resolve critical incidents, ensuring high service availability
Automate repetitive operational tasks, system configurations, and deployment processes using Python and Bash to enhance efficiency



Requirements



Basic Qualifications:

Bachelor's degree in Computer Science, Information Technology, Engineering, or a related technical field, or equivalent work experience
3+ years of progressive experience as a DevOps Engineer, Site Reliability Engineer (SRE), or similar role in a cloud-native environment
Expert-level proficiency in AWS services (EC2, S3, RDS, VPC, Lambda, IAM, CloudWatch, etc.). Solid understanding and working knowledge of GCP, Digital Ocean, and Azure concepts and services
Expertise in Terraform for multi-cloud infrastructure provisioning and management, including experience with state management, modules, and workspaces
Highly skilled in using Git and GitHub for source code management, branching strategies, and pull request workflows
Hands-on experience with implementing and managing monitoring and logging solutions (e.g., AWS CloudWatch, Datadog, ELK stack)
Solid understanding of cloud networking concepts, including VPCs, subnets, routing tables, load balancers, DNS, and VPNs
Strong understanding of cloud security best practices, identity and access management (IAM), security groups, network ACLs, and data protection principles
Working knowledge of database concepts and experience with various database types (e.g., MongoDB, PostgreSQL, MySQL)
Strong understanding and implementation of Ansible for cloud workload automations
Hands-on experience with Linux (Ubuntu) and update/patching mechanisms



Preferred Qualifications:

Experience in the healthcare industry or a highly regulated environment, with a demonstrable understanding of compliance requirements (e.g., HIPAA, SOC2)
Relevant cloud certifications (e.g., AWS Certified DevOps Engineer - Professional, AWS Certified Solutions Architect - Associate/Professional)
In-depth experience with GitHub Actions for designing, implementing, and maintaining automated build, test, and deployment pipelines. Familiarity with other CI/CD tools
Strong proficiency in Python and Bash scripting for automation, system administration, and tool development.
Knowledge of Node.js or PHP
Experience with Docker for containerizing applications. Familiarity with container orchestration platforms (e.g., Kubernetes, AWS ECS)
Exceptional problem-solving and analytical skills with a proactive approach to identifying and resolving complex technical issues
Excellent communication and interpersonal skills, capable of effectively collaborating with diverse cross-functional teams (developers, QA, product, security)
Strong sense of ownership, accountability, and ability to work independently while also being a strong team player
A continuous learning mindset, staying updated with emerging technologies, industry trends, and best practices in the DevOps space
Meticulous attention to detail and strong documentation skills



Benefits


Salary Range: $130,000-$140,000
Health Care Plan (Medical, Dental & Vision)
Retirement Plan (401k, IRA)
Life Insurance (Basic, Voluntary & AD&D)
Unlimited PTO Policy
Paid Holidays
Short Term & Long Term Disability
Training & Development"
"DevOps Engineer (35 LPA - 55 LPA)","CodeRound AI","Greater Bloomington Area","https://www.linkedin.com/jobs/view/devops-engineer-35-lpa-55-lpa-at-coderound-ai-4308183910?position=11&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=Dbj6zWXcRF%2BVQbO8nMNiZA%3D%3D","üöÄ What We‚Äôre Building


CodeRound AI matches top 5% tech talent to fastest growing VC funded AI startups.
Candidates apply once and get UPTO 10 remote as well as onsite interview opportunities IF selected!
Top-tier product startups in US, UAE & India have hired top engineers & ML folk using CodeRound


üß© What You‚Äôll Do


Build and optimize our cloud infrastructure ‚Äî scalable, secure, and cost-effective (mostly AWS).
Set up and manage CI/CD pipelines to ensure smooth deployment across backend, AI services, and mobile.
Containerize backend services (FastAPI, Rails) and optimize them for performance.
Implement monitoring, alerting, and logging to catch issues before users do.
Optimize database performance (Postgres, Redis) and manage backups and scaling.
Collaborate with backend, AI, and product teams to deploy new features safely and quickly.
Champion infra-as-code and automation wherever possible.


üí• Why this is exciting


You'll own DevOps for a high-usage, real-world AI platform ‚Äî not just internal tools.
You‚Äôll work on real-time, high-stakes flows ‚Äî interviews, scoring, hiring decisions.
You‚Äôll work closely with founders, ship weekly, and see the direct impact of your work.


‚úÖ You‚Äôll Be Great At This If You


Have 4+ years of experience as a DevOps engineer, SRE, or infrastructure engineer.
Are strong with AWS services (EC2, RDS, ECS/EKS, S3, CloudWatch).
Can write clean, reusable Terraform or CloudFormation code.
Have experience setting up CI/CD pipelines and optimizing build/release flows.
Are comfortable with Docker, Linux servers, and basic networking (VPCs, security groups).
Understand application and database scaling (horizontal/vertical).


‚ö° Bonus If You


Have experience supporting AI/ML pipelines in production (fine-tuning infra, vector DBs, etc.).
Know cost optimization tricks for cloud infra (spot instances, autoscaling groups, etc.).
Are excited to eventually build a small infra team"
"Devops Engineer","The Dignify Solutions, LLC","Brooklyn, OH","https://www.linkedin.com/jobs/view/devops-engineer-at-the-dignify-solutions-llc-4341915759?position=12&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=etA5ALEog9gY82FJmAUS%2FA%3D%3D","Job Description:


Serve as a subject matter expert to develop and support DevOps Web Access Management solutions
Install, configure, and maintain automation solutions, in support of KeyBank infrastructure
Develop Standard Operating Procedures, maintenance plans and provide status reports as required
Perform daily operational tasks as required for the Web Access Management team


Qualifications:


General technical capabilities across all portions of the infrastructure stacks
Independent thinker and self-starter
Generates ideas, innovative
Experienced with automation frameworks using an automation first approach
Proficient in one or more programming/scripting languages (Python, Ansible, etc.)
Proficient with one or more cloud orchestration tools (Terraform, Cloud Formation, etc.)
Conduct performance analysis and optimization
Experienced with public cloud providers such as GCP, Azure and AWS
Comfortable operating in a Linux environment


Preferred Skills:


Public and Private Cloud automation experience in production & non-production environments
Knowledge of web access management technologies and deployments
Knowledge of web access management technologies and deployments
Knowledge of routing & switching technologies and configurations
Knowledge of compute and storage solutions in data center environments
Experience with Service Now change management and problem management platform
Ability to balance workload amidst competing deadlines
Ability to perform knowledge transfers with peer engineers
Contribute to the reliability, performance, supportability, and security of web access management infrastructure
Review procedures for change and configuration management in all environments"
"DevOps Engineer","LifeMD","Huntington Beach, CA","https://www.linkedin.com/jobs/view/devops-engineer-at-lifemd-4337182535?position=13&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=pd53zZ4Rl7%2Bh4hAeLCQixg%3D%3D","About us:

LifeMD is a leading digital healthcare company committed to expanding access to virtual care, pharmacy services, and diagnostics by making them more affordable and convenient for all.¬†Focused on both treatment and prevention, our unique care model is designed to optimize the patient experience and improve outcomes across more than 200 health concerns.¬†

To support our expanding patient base, LifeMD leverages a vertically-integrated, proprietary digital care platform, a 50-state affiliated medical group, a 22,500-square-foot affiliated pharmacy, and a U.S.-based patient care center.¬†Our company ‚Äî with offices in New York City; Greenville, SC; and Huntington Beach, CA ‚Äî is powered by a dynamic team of passionate professionals. From clinicians and technologists to creatives and analysts, we're united by a shared mission to revolutionize healthcare.¬†Employees enjoy a collaborative and inclusive work environment, hybrid work culture, and numerous opportunities for growth. Want your work to matter? Join us in building a future of accessible, innovative, and compassionate care.


About the role:

LifeMD is seeking a highly motivated and experienced DevOps Engineer to join our dynamic Technology team. This individual will serve as a critical link between software development and IT operations, playing a pivotal role in designing, implementing, and maintaining automated processes for software delivery, infrastructure management, and system monitoring. The primary objective is to accelerate our release cycles, enhance system stability, and improve overall operational efficiency across our diverse cloud infrastructure, all while strictly adhering to stringent healthcare industry compliance standards, including HIPAA and SOX.


Responsibilities:


Design, implement, and manage scalable, secure, and cost-effective cloud infrastructure primarily on AWS using Terraform
Develop and version control Terraform modules for automated provisioning, updating, and de-provisioning of cloud resources (e.g., EC2, S3, RDS, VPC, Lambda in AWS)
Design, build, and optimize automated CI/CD pipelines using GitHub Actions for various applications and microservices
Integrate automated testing, static code analysis, security scanning, and deployment steps into CI/CD workflows for high quality and secure releases
Implement, configure, and maintain comprehensive monitoring, logging, and alerting solutions (e.g., AWS CloudWatch, Datadog) for all environments
Develop custom dashboards, metrics, and alerts for real-time visibility into system health, performance, and security events
Proactively analyze logs and metrics to identify potential bottlenecks and issues
Participate in on-call rotations to swiftly respond to and resolve critical incidents, ensuring high service availability
Automate repetitive operational tasks, system configurations, and deployment processes using Python and Bash to enhance efficiency



Requirements



Basic Qualifications:

Bachelor's degree in Computer Science, Information Technology, Engineering, or a related technical field, or equivalent work experience
3+ years of progressive experience as a DevOps Engineer, Site Reliability Engineer (SRE), or similar role in a cloud-native environment
Expert-level proficiency in AWS services (EC2, S3, RDS, VPC, Lambda, IAM, CloudWatch, etc.). Solid understanding and working knowledge of GCP, Digital Ocean, and Azure concepts and services
Expertise in Terraform for multi-cloud infrastructure provisioning and management, including experience with state management, modules, and workspaces
Highly skilled in using Git and GitHub for source code management, branching strategies, and pull request workflows
Hands-on experience with implementing and managing monitoring and logging solutions (e.g., AWS CloudWatch, Datadog, ELK stack)
Solid understanding of cloud networking concepts, including VPCs, subnets, routing tables, load balancers, DNS, and VPNs
Strong understanding of cloud security best practices, identity and access management (IAM), security groups, network ACLs, and data protection principles
Working knowledge of database concepts and experience with various database types (e.g., MongoDB, PostgreSQL, MySQL)
Strong understanding and implementation of Ansible for cloud workload automations
Hands-on experience with Linux (Ubuntu) and update/patching mechanisms



Preferred Qualifications:

Experience in the healthcare industry or a highly regulated environment, with a demonstrable understanding of compliance requirements (e.g., HIPAA, SOC2)
Relevant cloud certifications (e.g., AWS Certified DevOps Engineer - Professional, AWS Certified Solutions Architect - Associate/Professional)
In-depth experience with GitHub Actions for designing, implementing, and maintaining automated build, test, and deployment pipelines. Familiarity with other CI/CD tools
Strong proficiency in Python and Bash scripting for automation, system administration, and tool development.
Knowledge of Node.js or PHP
Experience with Docker for containerizing applications. Familiarity with container orchestration platforms (e.g., Kubernetes, AWS ECS)
Exceptional problem-solving and analytical skills with a proactive approach to identifying and resolving complex technical issues
Excellent communication and interpersonal skills, capable of effectively collaborating with diverse cross-functional teams (developers, QA, product, security)
Strong sense of ownership, accountability, and ability to work independently while also being a strong team player
A continuous learning mindset, staying updated with emerging technologies, industry trends, and best practices in the DevOps space
Meticulous attention to detail and strong documentation skills



Benefits


Salary Range: $130,000-$140,000
Health Care Plan (Medical, Dental & Vision)
Retirement Plan (401k, IRA)
Life Insurance (Basic, Voluntary & AD&D)
Unlimited PTO Policy
Paid Holidays
Short Term & Long Term Disability
Training & Development"
"Devops Engineer","Hoplite Solutions LLC","Bethesda, MD","https://www.linkedin.com/jobs/view/devops-engineer-at-hoplite-solutions-llc-4336082750?position=14&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=eL5ya7JZmHeZwk8tk9HKHw%3D%3D","Hoplite Solutions is hiring DevOps Engineers at all experience levels to join our team in Bethesda, MD. In this mission-critical role, you will provide essential system support to our customer while collaborating closely with software development teams and other key technology stakeholders. You will help maintain, enhance, and support a range of IC enterprise products‚Äîboth legacy systems and new solutions‚Äîwithin an Agile SAFe environment.

As a DevOps Engineer, you will work hand-in-hand with software engineering teams to deploy and operate systems, automate and optimize processes, and build and maintain tools that support deployment, monitoring, and ongoing operations. You will also troubleshoot and resolve issues across development, test, and production environments, ensuring reliability, efficiency, and continuous improvement across the enterprise.

Primary Responsibilities:


Supports software deployments, cloud infrastructure baselines, and operational availability of production systems
Managing, building, configuring, administering, operating and maintaining all components that comprise the DevOps environment
Defining enterprise Continuous Integration/Continuous Deployment processes and best practices
Codifying DevOps best practices across the enterprise
Developing and maintaining scripts to automate tool deployment to an AWS cloud environment and other tasks
Scripting and maintaining build environments
Working with project teams to integrate their products into the DevOps environment


Basic Qualifications


Demonstrated experience setting up one or more of the following tools: GitHub, Jira, Confluence, Jenkins, and Katalon Studio
Demonstrated experience troubleshooting issues with two or more of the following tools: GitHub, Jira, Confluence, Jenkins, and Katalon Studio
Demonstrated experience working within a software development team and supporting developers and developer activities
Bachelors degree with 4 or more years of prior relevant work experience or Masters with 2 or more years of prior relevant work experience. Will consider additional work experience in lieu of a degree
To be considered must have an active TS/SCI with polygraph security clearance


Preferred Qualifications


AWS Associate Certification (Developer, Solution Architect, or Sys Ops Administrator)
AWS Professional Certification (DevOps Engineer or Solutions Architect)
Demonstrated experience in container orchestration using Docker, Vagrant, Kubernetes, or AWS ECS/ECR
Demonstrated experience with Languages including Java, Python, JavaScript, Ruby, PHP, and Unix shell Scripting
Demonstrated experience with Ansible, or Puppet


Hoplite Solutions offers very competitive salaries and an excellent benefits package, to include a 7% employer 401k contribution, fully paid healthcare for our employees, outstanding training benefits, company funded life insurance and short-term disability insurance, and many more.

Powered by JazzHR

wwBe8pS8mn"
"DevOps Engineer","The Dignify Solutions, LLC","Brooklyn, OH","https://www.linkedin.com/jobs/view/devops-engineer-at-the-dignify-solutions-llc-4341985652?position=15&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=Tnp%2FEDp%2BS0Rt%2BnPb%2FrCSHA%3D%3D","Qualifications:


General technical capabilities across all portions of the infrastructure stacks
Independent thinker and self-starter
Generates ideas, innovative
Experienced with automation frameworks using an automation first approach
Proficient in one or more programming/scripting languages (Python, Ansible, etc.)
Proficient with one or more cloud orchestration tools (Terraform, Cloud Formation, etc.)
Conduct performance analysis and optimization
Experienced with public cloud providers such as GCP, Azure and AWS
Comfortable operating in a Linux environment


Preferred Skills:


Public and Private Cloud automation experience in production & non-production environments
Knowledge of web access management technologies and deployments
Knowledge of web access management technologies and deployments
Knowledge of routing & switching technologies and configurations
Knowledge of compute and storage solutions in data center environments
Experience with Service Now change management and problem management platform
Ability to balance workload amidst competing deadlines
Ability to perform knowledge transfers with peer engineers
Contribute to the reliability, performance, supportability, and security of web access management infrastructure
Review procedures for change and configuration management in all environments."
"DevOps Engineer","Verra Mobility","Indianapolis, IN","https://www.linkedin.com/jobs/view/devops-engineer-at-verra-mobility-4339356296?position=16&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=2N2C7lNmqhwwpqh3aSTUtw%3D%3D","Who we are‚Ä¶

Verra Mobility is a global leader in smart mobility. We develop technology-enabled solutions that help the world move safely and easily. We are fostering the development of safe cities, working with police departments and municipalities to install over 4,000 red-light, speed, and school bus stop arm safety cameras across North America. We are also creating smart roadways, serving the world's largest commercial fleets and rental car companies to manage tolling transactions and violations for over 8.5 million vehicles. And we are a leading provider of connected systems, processing nearly 165 million transactions each year across 50+ individual tolling authorities.

Culture

Verra Mobility Corporation is a rapidly-growing, entrepreneurial company that operates with a people-first philosophy and approach. The company lives by its core values‚ÄîDo What's Right, Lead with Grace, Win Together, and Own It‚Äîin everything it does for its customers and team members. The company seeks to grow aggressively, both organically and through acquisition, to continue to be the undisputed market leader with these five core competencies: bias for action, customer focus, teamwork, drive for results, and commitment to excellence.

Position Overview:

We are seeking an experienced and detail oriented Devops Engineer to join our team. In this role, you will be responsible for creating, maintaining, and securing our Devops pipelines and deployment systems to ensure high levels of performance and availability. This position is ideal for someone with a strong background in CI/CD methodologies particularly in cloud environments.

Essential Responsibilities:


Spend 50% writing automation scripts in Python and Bash.
Write various CI/CD pipelines for code releases.
Ensure that pipelines meet both operations and security requirements.
Partner with developers to identify areas of improvement in the developer experience.
Design and implement innovations that improve software velocity, infrastructure resiliency, security and data availability.
Work with Software and Engineering to ensure new pipelines are created in parallel to code build.
Work with Architecture on setting the path forward and gathering changes to the technology stack.
Ability to respond to system issues, drive and participate in high - priority incident calls and emergency activities outside of standard office hours as needed.
Collaborate with internal and external application, business partners to gain understanding of their business needs and adapt departmental roadmap plans and priorities to address operational challenges.
Work with QE to ensure all automated testing is run during the deployment of the code.
Ability to participate in an on-call rotation as needed.


Qualifications:


Must have 5 years of Devops Engineering experience.
Familiarity with a wide range of systems engineering tools, including source code repository hubs, continuous integration services, issue tracking, test automation, deployment automation, development team collaboration, project management.
Need to have strong scripting skills to create automation in Python preferred or Bash.
Experience with Cloudformation or Terraform for infrastructure as code.
Used continuous integration and continuous development (CI/CD) tools such as Jenkins, Gitlab, or Github Actions, preferred.
Knowledge of DevOps tools such as, GitHub Actions, CloudFormation, GIT, SVN, Jenkins, JIRA, Rally, Greenhopper, Puppet/Chef Vagrant, Selenium, Azure DevOps (for sprint planning).
Understanding of enterprise GIT repositories including branching and forking.
Hands-on Familiarity with AWS CloudWatch, AWS CloudTrail, AWS X-Ray, Grafana, and Prometheus.
Hands-on experience with Veracode and SonarQube are a plus.
Must be located in Phoenix, AZ, Indianapolis, IN, or NY and be willing to commute into office 3 days a week.


This position is not eligible for sponsorship now or in the future and is only considering local Arizona, New York, or Indiana talent.



Verra Mobility Values



An ideal candidate for this role naturally works in alignment with the Verra Mobility Core Values:


Own It. We focus on high performance and drive toward breakthrough outcomes. Our employees ensure accountability, optimize and align work, focus on the customer, and cultivate innovation.
Do What's Right. We champion integrity and good character. Our team members model ethical behavior, demonstrate good judgment and are courageous.
Lead with Grace. We express humility and compassion, and we are authentic and candid. Our employees demonstrate self-awareness, care for others, instill trust, and communicate effectively.
Win Together. We believe in growing and inspiring people together. We seek people who collaborate, value differences, think and act globally, foster an engaging work environment, and recognize and develop others.




With your explicit consent which you provided as part of the application process, we will retain candidate personal data solely for the business purpose for which it was collected. In no event will we retain such data more than two (2) years following the closure of the recruitment process relating to the role for which you applied or in the event other related job opportunities arise within the company. Verra Mobility Applicant Privacy Notice

Verra Mobility is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status."
"DevOps Engineer","Protege","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-protege-4331315574?position=17&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=0%2BlzXAWYrHhy0UF78FIOPQ%3D%3D","Company Overview:

We are building Protege to solve the biggest unmet need in AI ‚Äî getting access to the right training data. The process today is time intensive, incredibly expensive, and often ends in failure. The Protege platform facilitates the secure, efficient, and privacy-centric exchange of AI training data.

Solving AI‚Äôs data problem is a generational opportunity. We‚Äôre backed by world-class investors and already powering partnerships with some of the most ambitious teams in AI. The company that succeeds will be one of the largest in AI ‚Äî and in tech.

We‚Äôre a lean, fast-moving, high-trust team of builders who are obsessed with velocity and impact. Our culture is built for people who thrive on ambiguity, own outcomes, and want to shape the future of data and AI.

Key Responsibilities and Scope:


As a DevOps Engineer, you will be a critical part of our engineering team, responsible for safeguarding our AI/ML platforms, data pipelines, and cloud infrastructure
You will implement and develop monitoring strategies, and drive controls to protect our most valuable assets


Qualifications:


4+ years of hands-on experience in a DevOps, Architecture, SecOps or Engineering role
Strong experience with major cloud platforms and building cloud-native services including containerization, threat detection, vulnerability, governance, compliance, etc. with AWS preferred
Proficient in scripting languages like Python, SQL, Typescript or similar
Strong experience with infra‚Äëas‚Äëcode, monitoring, and reliability for pipelines; contributing to platform guardrails, governance, compliance, etc
Experience working with cross-functional partners to develop tools and playbooks for best-practices related to Operations


About You:


You are curious, tenacious, and proactive
You are not bothered by ambiguity but embrace finding patterns in complex environments
Excellent problem-solving skills and adaptability in a dynamic and evolving tech landscape
Excited to work in a company that deals with moving and transforming large volumes of data


Bonus if you have these attributes:


Experience with cloud providers like GCP and Azure
Prior startup experience
Security operations and automation experience"
"Devops Engineer","PDG Consulting","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-pdg-consulting-4321885957?position=18&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=8Pne6OGN%2FvlpHrb4GKj2VQ%3D%3D","Overview

We are seeking a DevOps Engineer to set up, manage, and automate software development operations and processes. The ideal candidate will have strong experience in CI/CD pipelines, cloud service management, and infrastructure monitoring to support efficient, secure, and scalable software delivery.

Responsibilities


Design, implement, and manage CI/CD pipelines to streamline software deployment and integration.
Oversee cloud-based systems and infrastructure management, ensuring reliability and performance.
Automate workflows for system administration, documentation, and monitoring.
Support the development and deployment of AI chatbot infrastructures and related frameworks.
Collaborate with developers, QA engineers, and IT teams to optimize the software lifecycle.


Requirements


Minimum 4 years of experience in ICT systems support, including system administration, documentation, and monitoring.
Hands-on experience with cloud platforms, especially Amazon Web Services (AWS).
Proven experience creating and maintaining AI chatbot infrastructures or similar automation frameworks.
Previous experience working within the UN system is an advantage.
Excellent command of English (required).
Knowledge of French and Arabic is considered an advantage.


Powered by JazzHR"
"DevOps Engineer - 100% Remote","The Dignify Solutions, LLC","Newtown Square, PA","https://www.linkedin.com/jobs/view/devops-engineer-100%25-remote-at-the-dignify-solutions-llc-4347005722?position=19&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=SWwzN6AGVXkNPHMoZ%2BPtpw%3D%3D","Summary: The main function of a DevOps Engineer is to design, develop, implement, test, and maintain business and computer applications software or specialized utility programs including mainframe and client/server applications, and major enhancement of existing systems

Job Responsibilities: Fine-tune and improve a variety of sophisticated software implementation projects Gather and analyze system requirements, document specifications, and develop software solutions to meet client needs and data Analyze and review enhancement requests and specifications Implement system software and customize to client requirements Prepare the detailed software specifications and test plans Code new programs to client's specifications and create test data for testing Modify existing programs to new standards and conduct unit testing of developed programs Create migration packages for system testing, user testing, and implementation Provide quality assurance reviews Perform post-implementation validation of software and resolve any bugs found during testing


A solid foundation in computer science, with strong competencies in data structures, algorithms, and software design.
Large systems software design and development experience.
Experience performing in-depth troubleshooting and unit testing with both new and legacy production systems.
Experience in programming and experience with problem diagnosis and resolution.
SAC Experience (1-2 YOE)
Ariba ATHENA Report generation (Some experience)"
"CloudOps Engineer","Protera","United States","https://www.linkedin.com/jobs/view/cloudops-engineer-at-protera-4336621571?position=20&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=IY7YKpgqiYPGJ%2BpBnSNOrQ%3D%3D","Summary

As a CloudOps Engineer at Protera, you will play a crucial role in maintaining and optimizing our cloud infrastructure. You will be responsible for monitoring and managing cloud services, ensuring the performance and reliability of our cloud applications, and automating processes to enhance operational efficiency. You will work closely with development teams to improve deployment practices and manage incidents in a fast-paced environment.

Key Responsibilities


Monitor cloud infrastructure performance and reliability to ensure optimal service delivery
Automate deployment processes using Infrastructure as Code (IaC) tools like Terraform
Implement and manage CI/CD pipelines to streamline application releases
Collaborate with development teams to integrate DevOps practices into application lifecycles
Troubleshoot cloud architecture and application issues to ensure minimal downtime
Conduct security assessments and implement best practices to secure cloud environments
Document processes and maintain configurations and operational standards


Requirements

Skills & Qualifications

Experience:


3+ years of experience in cloud operations, DevOps, or system administration


Technical Skills:


Proficient with AWS services and cloud architecture
Experience with Infrastructure as Code (IaC) tools, particularly Terraform
Strong understanding of containerization technologies like Docker and orchestration tools such as Kubernetes
Familiarity with CI/CD tools such as Jenkins, GitLab CI, or similar
Knowledge of monitoring tools and log management solutions
Solid troubleshooting skills across cloud-based systems


Education:


Bachelor's degree in Computer Science, Information Technology, or a related field is preferred


Certifications (Preferred):


AWS Certified Solutions Architect or related cloud certification
DevOps or Kubernetes certifications are a plus


Personal Attributes:


Strong analytical and problem-solving skills
Excellent communication and collaboration skills
Ability to work in a fast-paced environment and handle multiple tasks


About Protera

Protera Technologies (www.protera.com) is a leading provider of total IT outsourcing solutions for SAP-centric organizations. Founded in the mid-1990s, we are pioneers in providing SAP services on the cloud, managing thousands of workloads across various cloud platforms. With headquarters in Chicago and offices in Greece and India, we are committed to delivering exceptional cloud hosting, application management, and professional services globally.

Benefits

Protera offers a variety of health and wellbeing programs. Benefit options include two PPO Medical plans, Dental, Vision, Health Savings Account, Flexible Spending Accounts, Dependent Care FSA, 401k retirement savings plan, company paid Life Insurance, Flexible PTO policy, Paid Holidays."
"DevOps Systems Engineer","TensorWave","Las Vegas, NV","https://www.linkedin.com/jobs/view/devops-systems-engineer-at-tensorwave-4338727303?position=21&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=0qqLrHrqBz5IX0E%2FWO%2BqwA%3D%3D","At TensorWave, we‚Äôre leading the charge in AI compute, building a versatile cloud platform that‚Äôs driving the next generation of AI innovation. We‚Äôre focused on creating a foundation that empowers cutting-edge advancements in intelligent computing, pushing the boundaries of what‚Äôs possible in the AI landscape.

About The Role

We are seeking a highly skilled DevOps & Infrastructure Management Engineer to join our growing infrastructure team. This role is ideal for someone who thrives in hardware-centric environments, enjoys hands-on datacenter and system administration work, and can build reliable automation around large-scale infrastructure. You will be responsible for managing enterprise hardware, monitoring systems, network operations, infrastructure automation, and supporting our compute clusters across multiple data centers.

This role touches every layer of modern infrastructure‚Äîfrom bare metal provisioning, to OS and Kubernetes management, to monitoring and troubleshooting hardware. If you are detail-oriented, resourceful, and comfortable working with both low-level hardware systems and higher-level DevOps tooling, we‚Äôd love to talk.

Key Responsibilities

Hardware & Infrastructure Management


Manage and maintain enterprise-grade server hardware and infrastructure components.
Utilize out-of-band management systems (iLO, iDRAC, IPMI, Redfish, etc.) for remote operations.
Use automated hardware management tools (BMC/Redfish-based) to streamline provisioning and maintenance.
Perform hardware diagnostics and troubleshooting (CPU, memory, disks, PSUs, NICs, etc.).
Handle vendor interactions, including RMAs, part replacements, and inventory tracking.
Oversee datacenter hardware operations, including racking, cabling, PDU installation, and physical layout.


Datacenter & DCIM


Use Data Center Infrastructure Management (DCIM) tools for inventory, capacity planning, and environmental tracking.
Manage power delivery and consumption across racks and nodes.
Configure and monitor managed PDU systems for power cycling, monitoring, and alerts.
Collaborate with colocation providers on connectivity, power, security, and maintenance tasks.


Monitoring & Observability


Build and maintain infrastructure monitoring and alerting using tools such as Prometheus/Grafana, SNMP, Nagios, CheckMK, or similar platforms.
Implement automated alerting for hardware health, network status, power issues, and service-level metrics.
Create dashboards to give internal teams visibility into system performance and reliability.


Network Operations


Manage and configure firewalls, routing, and network segmentation.
Configure and troubleshoot VPN technologies (IPsec, OpenVPN, WireGuard).
Oversee subnetting, IP address allocation, and network architecture planning.
Configure managed switches, VLANs, port settings, and trunking.
Manage NAT, port forwarding, and related gateway/edge network configurations.


System Administration (Linux)


Install, configure, and manage Linux servers (Ubuntu/Debian preferred).
Perform system-level troubleshooting (boot issues, login problems, service failures).
Manage networking configuration (static IPs, DHCP).
Configure and maintain filesystems: partitioning, MD RAID, ext4/XFS, LVM, resizing/growing volumes.
Implement secure access using public key authentication and proper SSH hardening.
Manage certificates for internal systems, including issuance, revocation, HTTPS installation, and rotation.
Handle basic BIOS configuration relevant to bare metal provisioning or system bring-up.


Bare Metal Provisioning


Deploy and manage hardware provisioning tools such as MAAS, Foreman, or similar systems.
Configure and troubleshoot network boot mechanisms (PXE, UEFI Boot, HTTP Boot).
Automate provisioning pipelines to rapidly bring new nodes online.


Containerization & Orchestration


Work with Kubernetes clusters at a foundational level (cluster access, basic resource troubleshooting).
Deploy workloads using Helm charts and maintain cluster application lifecycle.
Assist with cluster scaling, node replacements, and security hardening.


Automation & Scripting


Write shell scripts (bash) for automation of system tasks, monitoring, or provisioning.
Use CLI tooling such as jq, sed, awk, grep, and rsync.
Optionally automate workflows using languages like Python, Go, PHP, or Perl.


Required Qualifications


Proven experience managing enterprise-grade hardware at scale.
Strong understanding of out-of-band management systems (IPMI/BMC/Redfish).
Hands-on expertise with monitoring systems (Prometheus, Grafana, SNMP, Nagios, CheckMK, or similar).
Solid knowledge of network administration, including firewalls, routing, VPNs, NAT, and managed switches.
Linux system administration experience (installation, configuration, troubleshooting).
Experience with filesystems, RAID, partitioning, and general storage management.
Familiarity with certificate management, key-based auth, and basic cryptographic functions.
Experience with bare metal provisioning (MAAS, Foreman, or similar).
Understanding of PXE/UEFI/HTTP boot systems.
Ability to write functional, maintainable bash scripts for automation.


Nice to Have


Experience with Kubernetes beyond the basics (operators, cluster scaling, CRDs).
Experience with Helm chart customization.
Familiarity with automation languages such as Python, Go, PHP, or Perl.
Previous datacenter operations or colocation management experience.
Exposure to high-availability or distributed compute environments.
Knowledge of infrastructure security and hardening practices.


What We Bring


Stock Options
100% paid Medical, Dental, and Vision insurance
Life and Voluntary Supplemental Insurance
Short Term Disability Insurance
Flexible Spending Account
401(k)
Flexible PTO
Paid Holidays
Parental Leave
Mental Health Benefits through Spring Health"
"DevOps Administrator","The Amatriot Group","Dallas, TX","https://www.linkedin.com/jobs/view/devops-administrator-at-the-amatriot-group-4310974393?position=22&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=u%2FPYBucx35YLABr1kxDQ9Q%3D%3D","DevOps Administrator

Salary: $135,000 ‚Äì 170,000

Contract Length: 12-month SOW

Location: Dallas, TX - in-office presence requirement 3 days weekly or more as needed


This represents the potential salary range for this position depending on education level, years of experience and/or certifications in addition to other position specific requirements which may impact salary


We‚Äôre seeking an experienced Administrator to join our Code Management team. The right candidate for this role will lead and execute strategic migrations, optimize CI/CD workflows, and drive infrastructure modernization. They will be critical in moving our automation ecosystem from legacy tools (Jenkins, Bitbucket, Automic) to GitLab, Ansible Automation Platform and Terraform, ensuring robust, scalable, and secure pipelines.

Required Skills And Experience


8+ years of experience in Administering different & complex applications and tools used in the Enterprise
Experience administering GitLab, Artifactory, Xray, & SonarQube
Experience with infrastructure-as-code tools (Terraform, Ansible, etc.)
Solid understanding of containerization (Docker) and orchestration (Kubernetes)
Familiarity with cloud platforms (AWS, Azure, IBM Cloud) and cloud-native tooling
Strong communication skills and a track record of cross-team collaboration
Knowledge of JFrog Artifactory, BitBucket / GIT, SVN and other SCM tools
Working knowledge of different Software Development Lifecycle Methodologies
Knowledge of desired state configuration, automated deployment, continuous integration, and release engineering tools like Puppet, Chef, Jenkins, Bamboo, Maven, Ant etc
Configure and manage GitLab Runners, Groups, Projects, and Permissions at scale
Harden GitLab for enterprise usage (SAML/SSO, LDAP, RBAC, backup/restore)
Design, implement, and optimize complex GitLab CI/CD pipelines using YAML best practices
Leverage Terraform, Ansible, or similar to provision and manage self-hosted GitLab and runners
Implement GitOps practices to manage infrastructure and environment configurations
Automate operational tasks and incident remediation via pipelines and scripts
Partner with application teams to onboard them onto GitLab workflows and best practices
Develop and maintain clear runbooks, wiki pages, and pipeline templates
Integrate monitoring (Prometheus/Grafana, ELK) for GitLab health and pipeline performance
Implement policies and guardrails to ensure code quality, compliance, and security posture
Troubleshoot and resolve CI/CD or migration-related incidents in a timely manner
Available for 24/7 On-call support


Preferred


A BS in Computer Science or equivalent work experience with good scripting/programming skills
GitLab Certified Administrator
Prior software experience with build management, configuration management and/or quality testing
Experience with SCM practices including Agile, continuous integration (CI) and continuous deployment (CD)


Team Culture

Our team is fast paced, fun, highly energetic, motivated and hardworking. We expect our candidates to be integrated into our results-driven and solution-oriented culture from the get-go. Our team attains high-quality results on challenging projects; the belief that outcomes are linked to one's effort rather than chance and the tendency to personally set challenging yet realistic goals."
"DevOps Engineer","Arize AI","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-arize-ai-4332964631?position=23&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=8vVampvuUEzsnC7p2JJFsQ%3D%3D","About Arize

AI is rapidly transforming the world. As generative AI reshapes industries, teams need powerful ways to monitor, troubleshoot, and optimize their AI systems. That‚Äôs where we come in. Arize AI is the leading AI & Agent Engineering observability and evaluation platform, empowering AI engineers to ship high-performing, reliable agents and applications. From first prototype to production scale, Arize AX unifies build, test, and run in a single workspace‚Äîso teams can ship faster with confidence.

We‚Äôre a Series C company backed by top-tier investors, with over $135M in funding and a rapidly growing customer base of 150+ leading enterprises and Fortune 500 companies. Customers like Booking.com, Uber, Siemens, and PepsiCo leverage Arize to deliver AI that works.

The Team

Our On-Prem engineering team is responsible for the deployment of Arize in customer environments. In addition to working with customers in defining infrastructure requirements, the team designs and develops software and tooling that enables the management of these systems at large scale. The On-Prem team has grown to be expert in Kubernetes and cloud deployment on GCP, Azure, and AWS as well as dealing with networking and security aspects of on-premise deployments. The team is dynamic and relies on few talented individuals with a high degree of autonomy and initiative.

What You‚Äôll Do


Work hands-on with the infrastructure that supports our distributed & highly scalable services in both SaaS and on-prem offerings
Gather requirements from customers and adapt manifests and software to support new environments
Use and augment monitoring tools to observe platform health, ensure performance and reliability
Interact with the product team to test new features and package new on-prem releases
Automate and optimize the release pipeline to make it as frictionless as possible
Exhibit continuous curiosity for emerging technology that could solve our challenges


What will set you apart:


3+ years of experience as a DevOps Engineer, Cloud Engineer, Infrastructure Engineer or similar
Excellent communication skills and ability to work directly with customers to understand and address their infrastructure needs
Experience and fluency in Kubernetes
A self starter with an ability to thrived in a fast paced environment
Experience working with multiple cloud providers (AWS, GCP, Azure) and understanding how to adapt cloud-native architectures for on-premises environments
Strong troubleshooting skills


The estimated annual salary for this role is between $100,000 - $185,000, plus a competitive equity package. Actual compensation is determined based upon a variety of job related factors that may include: transferable work experience, skill sets, and qualifications. Total compensation also includes a comprehensive benefit package, including: medical, dental, vision, 401(k) plan, unlimited paid time off, generous parental leave plan, and others for mental and wellness support.

While we are a remote-first company, we have opened offices in New York City and the San Francisco Bay Area, as an option for those in those cities who wish to work in-person. For all other employees, there is a WFH monthly stipend to pay for co-working spaces.

More About Arize

Arize‚Äôs mission is to make the world‚Äôs AI work‚Äîand work for people.

Our founders came together through a shared frustration: while investments in AI are growing rapidly across every industry, organizations face a critical challenge‚Äîunderstanding whether AI is performing and how to improve it at scale.

Learn more about what we're doing here:

https://techcrunch.com/2025/02/20/arize-ai-hopes-it-has-first-mover-advantage-in-ai-observability/

https://arize.com/blog/arize-ai-raises-70m-series-c-to-build-the-gold-standard-for-ai-evaluation-observability/

Diversity & Inclusion @ Arize

Our company's mission is to make AI work and make AI work for the people, we hope to make an impact in bias industry-wide and that's a big motivator for people who work here. We actively hope that individuals contribute to a good culture


Regularly have chats with industry experts, researchers, and ethicists across the ecosystem to advance the use of responsible AI
Culturally conscious events such as LGBTQ trivia during pride month
We have an active Lady Arizers subgroup"
"DevOps Engineer","Sustainment","Austin, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-sustainment-4335637240?position=24&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=w59fhbeTgmPDAivGVhenfQ%3D%3D","Company Overview: Sustainment is an AI-native software platform that helps US-based manufacturers easily find and work with the critical suppliers they need to build and manage their supply chains. Our vision is to reimagine American manufacturing as a hyperconnected, secure, and resilient ecosystem of local and regional suppliers who can more easily connect, interact, and do business with the industry and government customers that rely on them. We are a dual-use technology platform that supports both DoD and commercial customers in pursuit of our vision.

Job Overview: We are looking for a DevOps/MLOps Engineer to drive the reliability, scalability, and performance of our AI-native procurement platform. The primary focus of the role is to build and maintain robust infrastructure, automate ML model deployment pipelines, and ensure database performance and reliability. You will be responsible for high-quality, secure deliverables that meet stringent compliance requirements (SOC 2, FedRAMP, CMMC Level 2) and for helping to create, evangelize, and enforce the standards necessary to meet team and company goals for operational excellence and mission-critical uptime.

Responsibilities:


Build partnerships and work collaboratively with engineering, AI, and product teams to meet shared objectives
Operate effectively in ambiguous situations, especially when scaling AI workloads and managing complex infrastructure transitions
Build and optimize DevOps pipelines including ML model training, versioning, deployment, monitoring, and retraining workflows
Administer and optimize PostgreSQL databases including performance tuning, query optimization, backup/recovery, and high availability configurations
Troubleshoot and resolve infrastructure, database, and pipeline issues in a resilient, performant manner
Implement and maintain infrastructure as code using tools like Terraform or Cloudformation
Monitor system health, performance, and database metrics using observability tools and respond to alerts proactively
Ensure security best practices and compliance requirements are met across all infrastructure and database layers
Participate in multi-resource projects in an agile environment
Evaluate and recommend industry standards, tools, and methods for DevOps, MLOps, and database management
Document infrastructure architecture, runbooks, and contribute to architecture reviews


Qualifications:


Bachelor's degree (computer science, engineering, or related) or equivalent work experience
2+ years of experience with cloud infrastructure (AWS preferred), container orchestration (Kubernetes), and CI/CD tools
2+ years of database administration experience with PostgreSQL or similar relational databases
Experience with ML model deployment, monitoring, and lifecycle management (MLOps)
Strong understanding of infrastructure as code (Terraform), GitOps practices, and declarative configuration management
Experience with security compliance frameworks (SOC 2, FedRAMP, or CMMC is a plus)
Product-driven mindset with deep empathy for internal developer experience and system reliability
Strong desire to work in a startup with interest to take on projects from zero to one with collaboration with the rest of the team
Love working hard and enjoy a fast-paced, ambiguous environment
Experience with distributed systems, microservices architecture, and reactive systems
Open mindset to exploring new tools and frameworks in the rapidly evolving DevOps/MLOps landscape
Passion for operational excellence and automation
Experience supporting cross-team efforts to roll out new infrastructure capabilities or ML features
Passion for learning and continuous improvement
Strong written and verbal communication skills, and ability to explain complex technical concepts
Experience working in a Scrum/agile environment
Experience with AWS GovCloud, defense/government sector compliance, or working in an early startup environment on SaaS products is a plus


Core Technologies:


AWS (including GovCloud), Kubernetes, Docker, Terraform
PostgreSQL
GitLab CI/CD, ArgoCD, Tilt
Model versioning, experiment tracking, ML pipeline orchestration
Datadog, CloudWatch
Python, Bash, experience with .NET ecosystem a plus
IAM, secrets management, encryption, audit logging, compliance automation


Sustainment offers a competitive benefits package for full time employees including medical, dental, vision, paid time off, company holidays, and 401K matching.

Sustainment is proud to be an equal opportunity employer. We provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, veteran status, or any other protected class.

Applicants must be authorized to work for ANY employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time.

Sustainment participates in E-Verify."
"Devops","The Dignify Solutions, LLC","Phoenix, AZ","https://www.linkedin.com/jobs/view/devops-at-the-dignify-solutions-llc-4347025595?position=25&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=q4Rw4c9l8LicRPyDg2ohgg%3D%3D","Must have is


Associate should be in Phoenix from day 1 of the project
At least 5 years of experience in Devops area.
Strong skill in CI/CD pipeline, Jenkins, Github
Additional knowledge on any build related tools is an added advantage.


Java 8 knowledge

Docker

Kaffka

Kibana"
"DevOps Engineer I","Trustwell","Portland, OR","https://www.linkedin.com/jobs/view/devops-engineer-i-at-trustwell-4321600458?position=26&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=%2F3o7FP0nMNdz8JS9k5SbgQ%3D%3D","Role{{:}} DevOps Engineer I

FLSA{{:}} Full Time | Exempt | Salaried | Remote

Reports to{{:}} Director of DevOps

Note{{:}} Candidate preferred to reside in PST. If not, candidate will be required to support PST working hours.

Trustwell is looking for ambitious, energetic problem-solvers who enjoy a fast-paced team environment filled with challenges and career growth opportunities in a rapidly growing tech firm. Trustwell is on a mission to change the food industry. Combining FoodLogiQ's supply chain management software with Genesis' nutritional analysis and label development solution, the Trustwell Connect platform creates the food industry's only full-scale solution connecting product development and regulatory-compliant labeling with supplier compliance, enhanced traceability, and automated recall management. From food and supplement manufacturers to retail grocers and restaurant chains, more than 2,500 food companies around the world use Trustwell software as their trusted source for compliance and quality solutions in the food industry. For more information, visit www.trustwell.com.

Scope of Position{{:}} The DevOps Engineer I will be part of a dynamic and agile team responsible for building and maintaining the platforms, systems, and services that power our customer-facing products. Working closely with Software Engineers and Engineering Leadership, you'll help shape architecture, implement best practices, and stay ahead of the curve in DevOps principles. You'll champion operational excellence and continuous improvement across the team.

Essential Duties & Responsibilities include but not limited to{{:}}


Contribute actively to an Agile delivery team, ensuring consistent, high-quality, and reliable software releases.
Collaborate closely with developers and cross-functional partners to design, build, and deploy best-in-class, scalable software solutions.
Champion an automation-first, code-centric mindset, driving efficiency and consistency across deployment, monitoring, and maintenance processes.
Support production operations through participation in incident response, troubleshooting, and on-call rotations to maintain system reliability and uptime.
Develop, implement, and maintain monitoring and alerting tools to ensure optimal application performance, health, and availability.
Design infrastructure and deployment solutions with scalability, resilience, and long-term maintainability as core principles‚Äîavoiding short-term workarounds.
Proactively identify and eliminate operational bottlenecks and unnecessary complexity, contributing to continuous improvement initiatives.
Engage in architectural reviews and solution design discussions, providing input that enhances performance, reliability, and security.
Perform other related duties as assigned, contributing to the overall success of the DevOps function and technology organization.


Education/Experience{{:}}


Bachelor's degree in Computer Science, Engineering, or a related field required. Will consider relevant experience/certifications in lieu of degree.
2+ years of experience in an SRE (Site Reliability Engineer) or equivalent engineering role
2+ years of experience as a DevOps Engineer or in a similar capacity
3+ years of hands-on experience managing and supporting production cloud environments (AWS, Azure, or GCP)
Extensive experience with DataDog, including APM, RUM, Synthetic Monitoring, Infrastructure Monitoring, and Dashboard development


Required Skills/Abilities{{:}}


Strong, hands-on experience with Infrastructure-as-Code (IaC) and configuration management tools such as Terraform, CloudFormation, and/or Ansible
Proven experience designing and managing cloud architectures in AWS and Microsoft Azure, with expertise in containerization and orchestration (Docker, Kubernetes, etc.)
Demonstrated experience building, maintaining, and optimizing CI/CD pipelines using tools such as CircleCI, TeamCity, GitHub Actions, or Jenkins
Background in delivering infrastructure initiatives within an Agile development environment
Collaborative mindset with the ability to partner effectively across cross-functional teams to achieve shared goals
Strong ""automation-first"" mindset with a focus on scalability, reliability, and efficiency


Total Rewards Package{{:}}


Full healthcare benefits, including medical, dental, and vision.
Supplemental benefits, including STD, LTD, HSA, 401k, etc.
Responsible Time Off (PTO) + Holiday Pay
Excellent culture, growth opportunities, plus much more...


What to expect - the Hiring Process!


Interview with Human Resources
Interview with Hiring Manager
Peer Panel Interview(s)
Offer of Employment (Background Screening/References)


Hiring Eligibility{{:}} This is a fully remote position open to candidates located anywhere within the United States. Eligibility to work remotely is subject to company policy and applicable state laws. Candidates must have work authorization to work for any U.S. based employer. Please note that certain benefits, taxes, or employment terms may vary by state.

Compensation{{:}} The compensation for this position starts at $80,000 per annum, with the potential for higher placement based on a candidate's experience, education, and overall qualifications. In addition to base salary, this role is bonus eligible‚Äîup to 10% annually, contingent on company performance and achievement of organizational objectives.

Trustwell is an equal employment opportunity employer committed to hiring and retaining a diverse workforce. Applicants receive fair and impartial consideration without regard to race, sex, sexual orientation, gender identity, color, religion, national origin, age, disability, veteran status, religion, or other legally protected class. If you need accommodation for any part of the employment process due to a medical condition, or any disability, please contact a member of our human resources team.

Acceptable Background and References Required; Upon any conditional offers made by Trustwell.

Equal Opportunity Employer/ DFWP/ Affirmative Action"
"DevOps Engineer","OVA.Work","Alpharetta, GA","https://www.linkedin.com/jobs/view/devops-engineer-at-ova-work-4338475165?position=27&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=fKh6rwkEgdcRHSxUWRR1bw%3D%3D","Job Title: DevOps Engineer

Location: Remote

Employment Type: Full-Time

Job Summary

We are looking for a skilled DevOps Engineer to join our technology team. The ideal candidate will design, implement, and manage CI/CD pipelines, automate infrastructure, and ensure smooth deployment processes across development and production environments. This role requires strong knowledge of cloud platforms, containerization, and scripting.

Key Responsibilities


Design, build, and maintain CI/CD pipelines for application deployment.
Automate infrastructure provisioning using tools like Terraform or Ansible.
Manage containerized environments using Docker and Kubernetes.
Monitor system performance and implement proactive solutions for scalability and reliability.
Collaborate with development and operations teams to streamline workflows.
Ensure security and compliance in cloud and on-prem environments.
Troubleshoot and resolve issues in production and staging environments.


Qualifications


Bachelor's degree in Computer Science, Engineering, or related field.
25 years of experience in DevOps or related roles.
Proficiency in cloud platforms (AWS, Azure, GCP).
Hands-on experience with CI/CD tools (Jenkins, GitLab CI, GitHub Actions).
Strong knowledge of containerization (Docker, Kubernetes).
Familiarity with Infrastructure as Code (Terraform, Ansible).
Scripting skills in Python, Bash, or similar languages.


Preferred Skills


Experience with monitoring tools (Prometheus, Grafana).
Knowledge of security best practices in DevOps.
Familiarity with microservices architecture.


Benefits


Competitive salary and performance bonuses.
Health insurance and retirement plans.
Flexible work options and professional development opportunities."
"DevOps Engineer (JIRA)","Rubix Solutions","Washington, DC","https://www.linkedin.com/jobs/view/devops-engineer-jira-at-rubix-solutions-4335995983?position=28&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=D7zCwi59KqXK1oLdGUld9w%3D%3D","The DevOps Engineer (specifically Jira Platform Engineer) will serve as the technical owner of our Jira SaaS in government cloud, and is responsible for administering, configuring, and integrating the application within our enterprise technology ecosystem. This position plays a pivotal role in consolidating our collaborative planning tools‚Äîtransitioning from Azure DevOps (on-prem) and GitLab (on-prem) to Jira‚Äîwhile enabling and scaling Agile practices across the organization.

The ideal candidate is both technically proficient and strategically minded, with a strong understanding of Agile methodologies, DevSecOps workflows, and enterprise system

integration.

Responsibilities


Administer, configure, and optimize Jira SaaS to meet enterprise project management and Agile delivery needs.
Design and maintain custom workflows, issue types, screens, fields, and automation rules aligned with organizational Agile frameworks and guidelines.
Manage user permissions, group roles, and security schemes to ensure governance and compliance.
Monitor Jira license utilization, user growth, and application usage to ensure efficient use of subscriptions.
Collaborate with procurement teams to support renewal, optimization, and budget decisions.
Design, implement, and maintain seamless integrations between Jira with other enterprise systems, such as GitLab (source control & CI/CD), and ServiceNow (ITSM), using Okta,REST APIs, webhooks, middleware, and scripting.
Automate data synchronization across platforms to support traceability from planning to release.
Troubleshoot and optimize integration pipelines to ensure performance, security, and Scalability.
Partner with infrastructure and cybersecurity teams to align integrations with enterprise security and compliance standards.
Develop and maintain technical documentation, standards, and best practices.
Partner with the Agile Transformation Office to translate Agile practices into effective Jira configurations and usage patterns.
Provide technical guidance and mentoring to Scrum Masters, Product Owners, and teams on best-practice tool utilization.
Support reporting and analytics initiatives, ensuring reliable Agile metrics (velocity, burndown, cycle time, etc.).


Requirements


Must be able to obtain and maintain Moderate Risk Public Trust (MRPT) facility credentials/authorization. Note: US Citizenship is required for MRPT facility credentials/authorization at this work location.
Bachelor‚Äôs degree in Computer Science, Information Systems, or a related field (or equivalent experience).
3+ years of hands-on experience administering and/or engineering Jira (Self-hosting or SaaS).
Proven, hands-on experience developing custom integrations with enterprise platforms, especially GitLab and ServiceNow.
Proficiency in scripting (Python, PowerShell, or JavaScript) and REST API integration.
Strong understanding of Agile methodologies (Scrum, Kanban, SAFe) and DevSecOps principles.
Experience in enterprise migrations from Azure DevOps or similar tools to Jira.
Familiarity with Atlassian ecosystem (Confluence, Bitbucket) and marketplace apps.
Experience working in a DevSecOps or Platform Engineering environment.
Experience with information security, privacy, and risk assessment standards including FISMA, SOX, FedRAMP, etc. is preferred.
Federal government experience is preferred.
Atlassian Certified Professional (ACP-620, ACP-120, or equivalent) preferred."
"DevOps Engineer","Chartmetric","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-chartmetric-4291046434?position=29&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=Vh%2FkXp%2BkyoTdqG9ayhvJbw%3D%3D","About Chartmetric

Chartmetric, Inc. is a 10-year-old startup specializing in music data analytics. We are trusted by Universal MusicGroup, Sony, Warner, and Apple Music, as well as hundreds of other music companies and industry professionals. Our team has created a self-service data dashboard for the music industry to better understand the activity happening around artists. Together, we combine hundreds of thousands of real-time data points across iTunes, Spotify, YouTube, Google, Amazon, X, and others through our beautifully designed tool in order to make sense of the increasingly complex landscape of the music industry.

About The Role


We are seeking a talented DevOps / Developer Experience Engineer to join our team and play a pivotal role in enhancing our development infrastructure and streamlining the developer workflow. This position combines traditional DevOps responsibilities with a focus on creating exceptional developer experiences through tooling, automation, and process optimization.


What You'll Do


Infrastructure & Operations
Design, implement, and maintain scalable cloud infrastructure using Infrastructure as Code (IaC) principles
Manage CI/CD pipelines and deployment processes across multiple environments
Monitor system performance, reliability, and security, implementing proactive solutions
Automate operational tasks and eliminate manual toil through scripting and tooling
Ensure high availability and disaster recovery capabilities


Developer Experience
Build and maintain internal developer tools and platforms that improve productivity
Streamline onboarding processes for new developers and reduce time-to-first-commit
Design and implement developer-friendly APIs, SDKs, and documentation
Create self-service capabilities that reduce dependencies and waiting times
Gather feedback from development teams and iterate on tooling based on pain points


Collaboration & Process Improvement
Work closely with engineering teams to understand workflow challenges and requirements
Champion best practices for code deployment, testing, and monitoring
Lead initiatives to improve development velocity and reduce friction
Participate in incident response and post-mortem analysis
Mentor team members on DevOps practices and tooling

What We're Looking For


Technical Skills
3+ years of experience in DevOps, SRE, or Platform Engineering roles
Strong proficiency with cloud platforms (AWS, GCP, or Azure)
Experience with Infrastructure as Code tools (Terraform, CloudFormation, or Pulumi)
Hands-on experience with containerization (Docker) and orchestration (Kubernetes)
Proficiency in CI/CD tools (Jenkins, GitLab CI, GitHub Actions, or similar)
Strong scripting skills in Python, Bash, or Go
Experience with monitoring and observability tools (Prometheus, Grafana, ELK stack, or similar)


Developer Experience Focus
Experience building internal tools and platforms for development teams
Understanding of software development lifecycle and common developer pain points
Familiarity with API design and developer-facing documentation
Experience with version control systems and Git workflows
Knowledge of testing frameworks and quality assurance processes


Soft Skills
Strong problem-solving abilities and analytical thinking
Excellent communication skills and ability to work with cross-functional teams
Customer-focused mindset with emphasis on developer productivity
Proactive approach to identifying and resolving issues
Ability to balance technical debt with feature delivery


Preferred Qualifications
Knowledge of security best practices and compliance frameworks
Background in software development or engineering
Familiarity with cost optimization strategies for cloud infrastructure
Previous experience in a high-growth or scaling environment

What We Offer


Competitive salary and equity package
Comprehensive health, dental, and vision insurance
Opportunity to shape developer experience across the organization
Access to cutting-edge tools and technologies


Team Culture


We believe that great developer experiences lead to better products and happier teams. Our DevOps/DX team operates as enablers and force multipliers, working collaboratively to remove friction from the development process. We value automation, measurement, and continuous improvement, always asking ""how can we make this better for our developers?""


The Pay Range For This Role Is

135,000 - 165,000 USD per year(San Mateo)

120,000 - 150,000 USD per year(New York)"
"DevOps Engineer","Broad Reach Partners","Alpharetta, GA","https://www.linkedin.com/jobs/view/devops-engineer-at-broad-reach-partners-4303987210?position=30&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=UGEmD%2Fmb2TkDdKzHYhrqLg%3D%3D","We are seeking a Senior DevOps Engineer to join our team and play a critical role in designing, building, and optimizing the CI/CD pipelines that power our software delivery across on-prem and cloud environments.

In this role, you will work hand-in-hand with our development, operations, and security teams worldwide to implement best practices, automate deployments, and ensure our platforms are reliable, secure, and scalable. If you thrive on solving complex technical challenges, have a passion for automation, and want to influence how enterprise platforms evolve and modernize, this is an ideal opportunity for you.

As a Senior DevOps Engineer, your expertise will drive the continuous integration, delivery, and deployment (CI/CD) pipelines delivering software to both on-prem and cloud (AWS primarily) environments. You will work closely with our development, operations, and security teams distributed across the globe. This role requires a deep understanding of DevSecOps best practices and a strong ability to troubleshoot complex issues.

Your Responsibilities In This Role Will Include


Design, Develop and Maintain automated build and deployment pipelines using GitLab/GitHub/Jenkins to enhance software delivery.
Identify opportunities for automation and ensure continuous security, quality in application development by automating security checks, test executions in build and deployment pipelines.
Deploy and manage Kubernetes workloads to AWS EKS(A) using Helm, ArgoCD
Collaborate with development, operations and security team to build secure, optimized and efficient pipelines.
Create comprehensive documentation on pipeline functionality and provide training to required members.
Proactively monitor system performance and identify potential issues before they become critical.
Participate in on-call rotation.
Engage in continuous learning and actively advocate for Dev(Sec)Ops, GitOps best practices and standards across the team.


We are looking for you to have the following skills and experience:


8+ years of experience as a DevOps Engineer, Site Reliability Engineer, or equivalent
Strong knowledge of DevOps practices, continuous integration, continuous delivery, and related tools.
3+ years of experience with Amazon Web Services (AWS) or Microsoft Azure
3+ years of experience with Kubernetes clusters
Proficiency with public cloud environments (AWS preferred)
Experience with tools like New Relic and Graylog
Advanced proficiency working with CI/CD pipelines such as GitHub Actions/GitLab/Jenkins
Expert in containerization technologies such as Docker and orchestration tools like Kubernetes.
Proficiency in scripting language, like Bash, Groovy, Python
Excellent debugging and troubleshooting skills.
Ability to prioritize tasks efficiently and independently under minimal supervision.


Nice to Have


AWS Cloud certification
Familiar with .NET applications.
Knowledge in Terraform, Ansible, monitoring tools


We are located in the Alpharetta/Cumming area of Atlanta and are working in the office several days each week so YOU MUST LIVE WITHIN COMMUTING DISTANCE OF ALPHARETTA, GA to be considered for this role. We cannot sponsor at this time.

If this opportunity is a good match for your skills, experience and interest, please apply now so we can follow up with you with more details."
"AWS DevOps Specialist","Focus School Software","St. Petersburg, FL","https://www.linkedin.com/jobs/view/aws-devops-specialist-at-focus-school-software-4333597594?position=31&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=2Ep3XIthQ5ZQ3Iq%2BRnL5cw%3D%3D","Focus School Software is a fast-growing school management software company. We thrive on creating some of the most innovative features on the market today, helping educators to meet their evolving needs in classrooms, district management, state reporting compliance, and other facets of student-centered education and technology.

We are seeking an experienced and proactive AWS DevOps Specialist to join our growing infrastructure team. This role is ideal for someone passionate about automation, cloud infrastructure, and scalable, secure systems. The ideal candidate brings expertise in AWS services, infrastructure as code, cost reduction strategies and DevOps best practices. You will play a key role in improving system performance, reliability, and security, while contributing to CI/CD pipelines and participating in an on-call rotation. This is a great opportunity for anyone who has a multitude of skills in DevOps and System Administration and can wear many hats and loves problem solving.

Key Responsibilities


Automation & Configuration Management
Design, develop, and maintain automation using Ansible and Ansible Tower.
Deploy and configure RHEL based systems.
Database maintenance and performance, routing, pooling and role management.


Cloud Infrastructure (AWS)


Architect and manage services including RDS (PostgreSQL), EC2, EKS, CloudFormation, CloudFront, GuardDuty, AWS VPN, AWS AD, and more.
Implement Autoscaling strategies and container orchestration with EC2 Autoscaling or EKS. Continuously monitor performance and feedback on systems.
Monitor and improve database performance, sharding strategies, and health metrics.
Monitor backups and maintain recovery point objectives for disaster recovery.


Security & Compliance


Support SOC II compliance initiatives through infrastructure hardening, monitoring, and alerting.
Leverage AWS security tools and best practices to ensure compliance and threat mitigation.


Networking & Connectivity


Manage VPCs, subnets, security groups, VPNs, and endpoint connectivity for both internal and external integrations.
Managing routes, DNS and VPN connectivity. Help internal users maintain their VPN connections.
Cost Optimization
Analyze AWS billing, usage reports, and recommend cost-saving strategies.


DevOps & CI/CD


Build and maintain CI/CD pipelines, enabling delivery of automation code from development to production.
Ensure high availability and zero-downtime deployments through automation and best practices.
Develop and maintain local dev environments for developers.


Collaboration & Culture


Work cooperatively in cross-functional teams, embracing a culture where the best ideas win.
Proactively identify infrastructure problems and lead with creative, scalable solutions.


Endpoint & Systems Management


Oversee and manage end-user systems and infrastructure endpoints to maintain security and stability.
Patch management and remediation, ensure established timelines and policies are followed.


On-Call Participation


Participate in an on-call rotation to respond to production incidents and infrastructure issues.


Requirements


Ansible, Ansible Tower, working in RHEL based environments.
Linux/RHEL expert, be able to design, deploy and fix everything from a systemd service to managing SFTP.
Ability to manage a Git repository, and perform peer review on automation code.
Monitoring tools such as Splunk, Grafana or similar.
Working knowledge of NGINX, basic webserver stacks.
Understanding of AWS, particularly RDS (PostgreSQL), CloudFormation, EC2, EKS
Kubernetes and containerization
Experience with database sharding and performance tuning
CI/CD pipeline design and implementation
Familiarity with SOC II compliance frameworks
Experience managing AWS networking, VPNs, and AWS AD
Security-first mindset with experience using AWS Org, AWS Tower, CloudFront, and related tools to ensure compliance.
Strong interpersonal skills with a collaborative mindset.


Nice-to-Have


LAMP/LNPP Stack experience
SVN Familiarity
Active Directory experience, basic Windows management
Experience with endpoint management platforms
Background in proactive monitoring/observability tooling
Prior involvement in security audits or compliance initiatives


Focus School Software‚Äôs compensation package offers the following benefits:


Medical Insurance
Dental/Vision Insurance
Life Insurance
Short and Long Term Disability Insurance
401(k) after 6 months
Paid Holidays
Paid Vacation and Sick Time
Remote Position"
"DevOps Engineer","Rain","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-rain-4318510257?position=32&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=NSVwZMZsEqJm8zoQYJWUbw%3D%3D","Rain is empowering the next generation of money and financial products globally. We‚Äôre a lean and mighty team of passionate builders and veteran founders. We are looking for a DevOps engineer to join us in building a cutting edge platform at the intersection of real-world payments and digital money. You will have the opportunity to deliver massive impact at a small and quickly growing company that is funded by some of the top investors in fintech and crypto. Rain is backed by great investors including Lightspeed, Norwest, Khosla, along with great companies like Coinbase, Circle, and Uniswap.

Many of our engineers are based in NYC but we are open to fully remote candidates.

Our Ethos

We believe in an open and flat structure. You will be able to grow into the role that most aligns with your goals. Our team members at all levels have the freedom to explore ideas and impact the roadmap and vision of our company.

What You'll Do


Be a critical part of the technical infrastructure roadmap
Manage our cloud environments across GCP and AWS
Scale our infrastructure to millions of end users globally
Help drive the architectural decisions of a rapidly evolving product
Lead the creation and maintenance of our CI/CD pipelines to enable rapid, reliable deployments
Collaborate with the engineering team to improve infrastructure performance
Build infrastructure to interact with millions of smart contracts across dozens of blockchains
Automate security controls and compliance processes to protect sensitive financial data


What We're Looking For


Strong experience with Infrastructure as Code, particularly Terraform, for managing cloud resources at scale
Proven track record designing and implementing CI/CD pipelines and automation workflows
Experience managing production environments in cloud providers
Experience with monitoring, logging, and observability tools


Nice to haves, but not mandatory


Experience in fintech (neobank or card issuing experience gets extra brownie points)
Experience with blockchain infrastructure


Our perks enable working at Rain to be a fulfilling, healthy and happy experience.

Unlimited time off üõº Unlimited vacation can be daunting, so at Rain we require our teammates to take 10 days minimum for themselves.

Flexible working ‚òï We support a flexible workplace, if you feel comfortable at home please work from home. If you‚Äôd like to work with others in an office feel free to come in. We want everyone to be able to work in the environment in which they are their most confident and productive selves.

Flexible Benefits üß† Easy-to-access benefits, for all employees based in the US, Rain pays a percentage of your benefits for the employee and for your dependents. We offer comprehensive health, dental and vision plans as well as a 100% company-subsidized life insurance plan.

Equity plan üì¶ On top of a competitive salary, we offer every Rain employee an equity option plan so we can all can benefit from our success.

Rain Cards üåßÔ∏è We want our teammates to be knowledgeable about our core products and services and to support this mission we issue a card for our team to utilize the card for testing.

Health and Wellness üìö High performance begins from within. Our members are welcome to use their company card for eligible health and wellness spending like gym memberships, fitness classes and other wellness items.

Team summits ‚ú® Summits play an important role at Rain! Time spent together helps us get to know each other, strengthen our relationships, and build a common destiny. Stay tuned for upcoming destinations!"
"DevOps Engineer","Jasper","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-jasper-4318500931?position=33&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=sQ4ga8%2FZC2D2RhG5qvGnmQ%3D%3D","Jasper is the leading AI marketing platform, enabling the world's most innovative companies to reimagine their end-to-end marketing workflows and drive higher ROI through increased brand consistency, efficiency, and personalization at scale.

Jasper has been recognized as ""one of the Top 15 Most Innovative AI Companies of 2024"" by Fast Company and is trusted by nearly 20% of the Fortune 500 ‚Äì including Prudential, Ulta Beauty, and Wayfair. Founded in 2021, Jasper is a remote-first organization with team members across the US, France, and Australia.

About The Role

We're looking for an experienced DevOps Engineer to join our Platform team. This is a highly autonomous, high-impact role that blends Ops practices, infrastructure engineering, and delivery pipeline optimization. You'll work with a focused, collaborative, and fast-moving team where your contributions will directly impact system reliability, developer velocity, and our ability to safely deliver AI-powered products at scale. Candidates should also have a solid background in Cloud, IaC, and Kubernetes, and a drive to produce excellent solutions for a variety of challenges.

This fully remote role reports to the Staff Dev Ops Engineer and is open to candidates located anywhere in the continental US.

What You‚Äôll Do


Design, implement, and operate cloud-native infrastructure that scales efficiently, fails gracefully, and optimizes for performance and cost.
Build and refine software delivery pipelines to enable safe, fast, and frequent deployments with robust testing, rollback, and progressive release mechanisms.
Develop infrastructure-as-code solutions using Terraform and Helm to create self-healing, automated, and observable systems.
Collaborate with ML and product teams to support AI model training and inference through scalable compute and storage infrastructure.
Identify and eliminate single points of failure, performance bottlenecks, and scalability limits through proactive monitoring and reliability engineering practices.
Implement and enforce security best practices, including secrets management, access control, and compliance across all infrastructure layers.


What You‚Äôll Bring


Deep experience running Kubernetes in production (cluster management, networking, storage, security).
Expertise with Terraform, Helm, and configuration management to build reproducible, version-controlled infrastructure.
Proven success designing and maintaining CI/CD pipelines (GitHub Actions, Argo CD, Jenkins, etc.) balancing speed and safety.
Strong background in observability (especially Datadog) ‚Äî skilled at instrumentation, dashboard creation, and intelligent alerting.
Solid scripting skills in Python, Go, or Bash, with a focus on automation and operational efficiency.
Practical knowledge of Google Cloud Platform and cloud-native architectures.
Experience supporting multi-language environments (TypeScript, Python, Go) and AI/ML workloads, including GPU-based compute.
Familiarity with container security, secrets management, and policy enforcement.
(Bonus) History of open source contributions in infrastructure, CI/CD, or observability projects.


Compensation Range

At Jasper, we believe in pay transparency and are committed to providing our employees and candidates with access to information about our compensation practices. The expected base salary range offered for this role is $170,000 - $200,000. Compensation may vary based on relevant experience, skills, competencies, and certifications.

Benefits & Perks


Comprehensive Health, Dental, and Vision coverage beginning on the first day for employees and their families
401(k) program with up to 2% company matching
Equity grant participation
Flexible PTO with a FlexExperience budget ($900 annually) to help you make the most of your time away from work
FlexWellness program ($1,800 annually) to help support your personal health goals
Generous budget for home office set up
$1,500 annual learning and development stipend
16 weeks of paid parental leave


Our goal is to be a diverse workforce that is representative at all job levels as we know the more inclusive we are, the better our product will be. We are committed to celebrating and supporting our differences and that diversity is essential to innovation and makes us better able to serve our customers. We hire people of all levels and backgrounds who are excited to learn and develop their skills.

We are an equal opportunity employer. Applicants will not be discriminated against because of race, color, creed, sex, sexual orientation, gender identity or expression, age, religion, national origin, citizenship status, disability, ancestry, marital status, veteran status, medical condition, or any protected category prohibited by local, state or federal laws.

By submitting this application, you acknowledge that you have reviewed and agree to Jasper's CCPA Notice to Candidates, available at legal.jasper.ai/#ccpa."
"DevOps / Systems Engineer","Collate","San Francisco, CA","https://www.linkedin.com/jobs/view/devops-systems-engineer-at-collate-4302854141?position=34&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=5tNGYWWDGn%2FPBd2%2Fgr1z2w%3D%3D","About Collate

Collate is an AI document generation platform for life sciences. We automate paperwork with AI, helping our customers get life-saving innovations to patients years faster. Collate is an end-to-end solution, powering every step of drug, diagnostic, and medical device development‚Äîfrom concept to market.

Our CEO Surbhi Sarna is a former General Partner at Y Combinator. Surbhi founded nVision Medical, which developed a new method to detect ovarian cancer and was acquired by Boston Scientific. Our CTO Nate Smith is a former Visiting Partner at Y Combinator and founder of Lever. Our AI researchers, engineers, and designers have worked at Google, Nvidia, Meta, Netflix, Amazon, AirBnB, Hippocratic AI, and Grail, and 40% of our team are former founders.

We‚Äôre a small, elite team, with over $30M in seed funding from top investors (Redpoint, First Round Capital, Conviction, and Y Combinator) and leaders in healthcare and AI. This is a rare chance to join at the ground floor of a company with world-changing potential, experienced founders, and resources to execute at scale.

About The Role

We‚Äôre looking for a DevOps / Systems Engineer to own the infrastructure that powers Collate‚Äôs products. You‚Äôll build the systems and tooling that keep our platform reliable, secure, and fast as we scale.

This role is broad by design ‚Äî from managing CI/CD pipelines and cloud infrastructure to handling light security responsibilities like certificate management. You‚Äôll partner closely with backend, AI, and product engineers to ensure our systems are both easy to develop on and safe to deploy at scale.

At Collate, infrastructure isn‚Äôt just about uptime ‚Äî it‚Äôs about trust. The work you do will help ensure that the AI we build for healthcare runs with reliability and security in mind.

What You‚Äôll Do


Design and maintain cloud infrastructure to support Collate‚Äôs products as we grow from prototypes to production scale
Develop CI/CD pipelines and automation that accelerate developer velocity and reduce operational friction
Manage core system reliability, including monitoring, logging, and incident response
Take on light security responsibilities, such as handling certificates, secrets management, and supporting compliance needs
Collaborate closely with engineering teams to design infrastructure that balances speed, safety, and scale
Continuously improve internal tooling and workflows, helping the team move faster with confidence
Leverage tooling including AWS, Terraform, Kubernetes, Helm, ArgoCD, Grafana, and Github Actions



What We‚Äôre Looking For


Hands-on experience with cloud infrastructure (AWS, GCP, or similar) and modern DevOps practices
Proficiency with infrastructure-as-code and CI/CD tooling
Familiarity with monitoring, observability, and incident management
Interest or experience in light security work, including certificates, secrets management, or compliance support
A pragmatic approach: able to balance iteration speed with building for long-term reliability
Motivation to work in an early-stage startup where your infrastructure decisions shape the foundation of the company



Why Join Collate?

Impact: Build systems and experiences that touch real patients and providers, improving healthcare outcomes.

Ownership: Shape both our product experience and our engineering culture from the start.

Learning: Collaborate with a uniquely interdisciplinary team‚ÄîAI researchers, healthcare leaders, and experienced startup builders.

Upside: Join a company early enough to have meaningful equity and career-defining impact.

The base salary range for this role is $150,000‚Äì$300,000 USD annually, depending on experience and level (Tier 1, San Francisco)

We may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us."
"DevOps Engineer","Chartmetric","San Mateo, CA","https://www.linkedin.com/jobs/view/devops-engineer-at-chartmetric-4304688090?position=35&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=d1qAUHt%2FpgYsD%2FDXSFpJCA%3D%3D","N/A"
"Cloud DevOps With Azure Experience -100%Remote","The Dignify Solutions, LLC","New Jersey, United States","https://www.linkedin.com/jobs/view/cloud-devops-with-azure-experience-100%25remote-at-the-dignify-solutions-llc-4341845867?position=36&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=JiMtF1is0D3S3JSUH9%2BVpQ%3D%3D","N/A"
"DevOps Engineer - All Levels","CodeRabbit","San Francisco, CA","https://www.linkedin.com/jobs/view/devops-engineer-all-levels-at-coderabbit-4318518267?position=37&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=aDVYWbGuwPRTkYCR6m15uA%3D%3D","N/A"
"DevOps Engineer","Uffizio","Michigan, United States","https://www.linkedin.com/jobs/view/devops-engineer-at-uffizio-4324397378?position=38&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=h5GF7WpeSDM98EpMkI1V0g%3D%3D","N/A"
"DevOps Assistant (Entry-Level)","45PRESS","Canfield, OH","https://www.linkedin.com/jobs/view/devops-assistant-entry-level-at-45press-4301017192?position=39&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=ibkJuX%2BlJomxXk%2FoYN0otA%3D%3D","N/A"
"Senior DevOps Engineer","CEIPAL","Charlotte, NC","https://www.linkedin.com/jobs/view/senior-devops-engineer-at-ceipal-4305453358?position=40&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=pNh4GDOlzR9Nf%2Bx97GkdxQ%3D%3D","N/A"
"DevOps engineer","OVA.Work","Alpharetta, GA","https://www.linkedin.com/jobs/view/devops-engineer-at-ova-work-4310657957?position=41&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=UWtIJiwj4kEuJBQxRUWDXQ%3D%3D","N/A"
"DevOps Engineer","Hudu","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-hudu-4323191230?position=42&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=G5DAdhE4T0ub1J2ceS5RBg%3D%3D","N/A"
"DevOps Engineer","Verra Mobility","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-verra-mobility-4335667666?position=43&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=YwJAEU0LZIQX5OAcB65ahg%3D%3D","N/A"
"Staff Engineer: DevOps","Dispel","Austin, TX","https://www.linkedin.com/jobs/view/staff-engineer-devops-at-dispel-4339045806?position=44&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=IQYx16VKEJ34dd0qmsP1Aw%3D%3D","N/A"
"DevOps Engineer","IT Automation LLC","Cary, NC","https://www.linkedin.com/jobs/view/devops-engineer-at-it-automation-llc-4324192032?position=45&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=tr9QBOrtMWgmmH2g0ODI2A%3D%3D","N/A"
"DevOps Engineer","CHEQUESPREAD PLC","Valley Forge, PA","https://www.linkedin.com/jobs/view/devops-engineer-at-chequespread-plc-4288904252?position=46&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=9cKzcsNRAHFfA7VwsIujjg%3D%3D","N/A"
"Junior DevOps Engineer","eSimplicity","Columbia, MD","https://www.linkedin.com/jobs/view/junior-devops-engineer-at-esimplicity-4315888714?position=47&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=nkLaIDoXZRNA%2BhWW4RPjuA%3D%3D","N/A"
"Cloud/DevOps Engineer","Tagup, Inc.","New York, NY","https://www.linkedin.com/jobs/view/cloud-devops-engineer-at-tagup-inc-4333051833?position=48&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=N%2BmXkuHZmLx5RW5dk8lpeg%3D%3D","N/A"
"DevOps Engineer","Mark43","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-mark43-4309062970?position=49&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=FayPW506ncK%2BfiLQnXecaQ%3D%3D","N/A"
"DevOps Engineer","CMG (Capital Markets Gateway)","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-cmg-capital-markets-gateway-4338419750?position=50&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=y2AsIcVknVztZIKalzz8Eg%3D%3D","N/A"
"DevOps Engineer","Mintlify","San Francisco, CA","https://www.linkedin.com/jobs/view/devops-engineer-at-mintlify-4318506680?position=51&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=2Y9X1gJn4l7tsgd73kAuAw%3D%3D","N/A"
"DevOps Support Engineer","Porter","New York, NY","https://www.linkedin.com/jobs/view/devops-support-engineer-at-porter-4295124575?position=52&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=R%2Fk%2FJ7fjJ8xRsUn0t55Ypw%3D%3D","N/A"
"DevOps Engineer","Northstrat Incorporated","Columbia, MD","https://www.linkedin.com/jobs/view/devops-engineer-at-northstrat-incorporated-4304125676?position=53&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=jjRJVdeAcuc2ZN3kP3cDoQ%3D%3D","N/A"
"DevOps Engineer","Paramount","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-paramount-4335876548?position=54&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=2hAyBKZq34rXa%2Fl7X2Kb0Q%3D%3D","N/A"
"DevOps Engineer","SmartVault","Houston, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-smartvault-4297941616?position=55&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=lrowBtEfvKtI8PYtLrDkNQ%3D%3D","N/A"
"DevOps Engineer","RSC2, Inc.","Hanover, MD","https://www.linkedin.com/jobs/view/devops-engineer-at-rsc2-inc-4311252822?position=56&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=WVM7n66pfEu%2FkhbMR%2F%2FwKA%3D%3D","N/A"
"Cloud DevOps Support Engineer","Nihon Kohden Digital Health Solutions","Irvine, CA","https://www.linkedin.com/jobs/view/cloud-devops-support-engineer-at-nihon-kohden-digital-health-solutions-4295710052?position=57&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=7zUVTEq4rNcCLi4qi2wpMg%3D%3D","N/A"
"DevOps Engineer","PingWind","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-pingwind-4316019938?position=58&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=Uk9C47GhKQQBe8aFzW2kUw%3D%3D","N/A"
"DevOps Engineer","Cymertek Corporation","San Antonio, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-cymertek-corporation-4336305401?position=59&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=ctJAt8aQPy9cSXvURMWOyA%3D%3D","N/A"
"DevOps Engineer","Ryan","Dallas, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-ryan-4284462825?position=60&pageNum=0&refId=a6vM9FZU54yRH5LeMf3gmg%3D%3D&trackingId=RTaVMNvWcMWGQ6waVwtTpQ%3D%3D","N/A"
"Mid-Junior DevOps Engineer - USA","HERE","New York, NY","https://www.linkedin.com/jobs/view/mid-junior-devops-engineer-usa-at-here-4347377348?position=1&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=xHaOhXPaHGOIJI2%2Fe%2BoFtA%3D%3D","Mid-Junior DevOps Engineer

Location: New York, NY / Hybrid Remote / Remote within USA (EST / CST time zone)

We have an office in New York City and this position can either be based in the office, hybrid remote, or remote within the EST/CST time zones (subject to your existing legal right to work in the jurisdiction).

About HERE

Everything works right here‚Ñ¢.

Traditional browsers weren't built for work. In today's enterprise environment‚Äîwhere security threats are constant and productivity is critical‚Äîlegacy browsers fall short. That's why we built HERE, the browser purpose-built for work.

Powered by Chromium, HERE Enterprise Browser combines enterprise-grade security, seamless productivity, and native AI integration in one secure, intelligent workspace. Designed for regulated industries, HERE offers deep policy controls, identity-based access, secure workspace isolation, and full interoperability across SaaS, legacy, and virtualized environments. Our platform enables teams to work faster, more securely, and more intelligently‚Äîwithout compromise.

HERE technology is trusted by 90% of global banks and also used within the U.S. Intelligence Community and other sectors. We're backed by some of the world's most respected financial institutions and venture firms, including Bain Capital Ventures, Bank of America, J.P. Morgan, Wells Fargo and IQT, the not-for-profit strategic investor that accelerates the introduction of groundbreaking technologies to enhance the national security of America and its allies.

About the Role

HERE is seeking a mid-junior DevOps Engineer to join our infrastructure team! The primary responsibilities for this role will span CI/CD pipeline engineering and cloud operations, maintaining and improving our GitHub and GitLab CI/CD pipelines, and supporting our AWS cloud infrastructure. In this role, you will gain hands-on experience with real production build systems and cloud platforms- while having the opportunity to work on practical projects that directly impact both our development velocity and operational reliability.

We're actively evolving toward a cloud-agnostic, multi-cloud architecture and migrating to Kubernetes for container orchestration. While current AWS and ECS experience is essential, having exposure to Azure, GCP, and Kubernetes will position you well for our infrastructure roadmap.

This role offers the opportunity to collaborate with senior engineers who will provide guidance and mentorship, whilst giving you ownership of projects across the DevOps lifecycle. This is an excellent platform for building practical experience with modern build engineering (CI/CD automation, cloud infrastructure, and deployment practices) within a production environment.

Responsibilities


CI/CD Pipeline Development:
Build, maintain, and optimize GitLab CI/CD pipelines for multi-platform builds (Windows, macOS, Linux).
Work with YAML configurations, pipeline stages, artifacts, and deployment workflows.
Cloud Infrastructure Operations:
Help maintain and improve AWS infrastructure including ECS/Fargate deployments, RDS databases, Route53 DNS, VPC networking, and IAM policies.
Support multi-tenant and multi-region architecture.
Container & Deployment Management:
Work with Docker containers, ECS task definitions, and ECR registries.
Deploy and manage containerized Node.js applications in production environments.
Release Management:
Help manage release processes including version promotion, release channels (canary, beta, stable), and automated deployment to staging and production environments.
Database Operations:
Support PostgreSQL on AWS RDS‚Äîbackups, SSH tunneling through bastion hosts, read-only user management, and database configuration for multi-tenant environments.
Automation & Scripting:
Write and maintain automation scripts in Bash, PowerShell, Python, and Node.js.
Build tools to improve infrastructure reliability and developer experience.
Internal Tools Support:
Help maintain web-based DevOps tools built with Express.js, React, and TypeScript‚Äîtools for cloud settings management, tenant provisioning, and deployment monitoring.

What We're Looking For

Ideally 2 to 4 years of experience with the following core requirements:


GitLab CI/CD: Experience with GitLab CI/CD pipelines‚ÄîYAML configuration, stages, jobs, artifacts, rules, dependencies.
Understanding of CI/CD best practices and pipeline optimization.
AWS Cloud Fundamentals: Practical experience with core AWS services‚ÄîEC2, ECS/Fargate, RDS, Route53, VPC, IAM, Secrets Manager, CloudWatch. Comfortable navigating the AWS Console and CLI.
Multi-Platform Scripting: Solid scripting skills in Bash (Linux) and PowerShell (Windows). Ability to write maintainable automation scripts for both platforms.
Containerization: Hands-on Docker experience‚Äîbuilding images, writing Dockerfiles, docker-compose, understanding container networking, and working with ECS/ECR.
Build Systems: Experience with build tools and package managers‚Äînpm/Node.js, .NET/NuGet, Python packaging. Understanding of dependency management and build artifacts.
Version Control: Strong Git fundamentals‚Äîbranching strategies, merge requests, tagging. Experience with GitHub (or GitLab) workflows and code review practices.
Linux/Unix & Windows: Comfortable in both environments‚ÄîSSH, file permissions, package managers, systemd, PowerShell. Understanding of cross-platform operational challenges.
Node.js/JavaScript: Comfortable reading and writing JavaScript/Node.js code. Experience with npm, package.json, and basic Express.js applications for tooling.


Nice to Have


Kubernetes experience (EKS, GKE, AKS) or willingness to learn, we're migrating from ECS to K8s
Multi-cloud experience (Azure, GCP) or cloud-agnostic architecture knowledge
GitLab Runner administration and configuration
AWS CDK or CloudFormation for Infrastructure as Code
Terraform for multi-cloud infrastructure management
TypeScript development experience
PostgreSQL database administration and optimization
.NET build systems and NuGet package management
React or frontend framework experience
Airflow or workflow orchestration tools
Helm charts and Kubernetes manifest management


What We're Offering

Benefits -


Generous Paid Time Off, Paid Holidays & Sick Time
Competitive & Comprehensive Health Insurance
Thoughtfully-Planned Paid Parental Leave
Financial Well-Being Plans (FSA) (401k) (Life Insurance)
Stock Options
Professional Development Courses
Employee Resource Groups


Additional Perks -


One Medical - Free Membership
Talkspace - Mental Health Therapy 24/7
Team Lunches
Casual dress code
Commuter Benefits (NYC employees only)
Citibike (NYC employees only)


Life at HERE

At HERE, we pride ourselves on fostering a friendly, collaborative, and supportive culture that truly respects the diversity of thought. Our goal is to create a space where employees can learn and innovate, and overall, have a good time doing it. We value and appreciate that our employees have a wide set of interests and experiences and put importance on taking the time to get to know one another and form relationships. From virtual socials and in-person events, to informal meetings and employee resource groups, we make it easy to engage and connect. Our environment promotes a productive, enjoyable learning experience - aligned together, working to create compelling solutions for our clients. Everything works right here.‚Ñ¢

We are HERE - Read about our recent rebrand from OpenFin to HERE

Recent Awards


Voted ""Enterprise Browser of the Year"" by CIO Review (2025)
Voted ""100 Best Midsize Companies to Work For in NYC"" by BuiltIn (2025)
Voted ""Top 10 Contact Center Technologies & Capabilities of 2024"" by CX Today (2024)
Voted ""Best Enterprise Environment for Interoperability"" by TradingTech Insight Awards Europe (2024)
Voted ""Top 50 Best Startups to Work for in the US"" & ""Top 50 Best Startups to Work for in New York"" by BuiltIn (2024)
Voted as a ""Best Employer Award"" finalist at the UK FinTech Awards (2023)
Voted ""Best FinTech Company CEO"" at the FinTech Breakthrough Awards (2023)
Voted ""Best Internal Talent Team"" by Financial Technologist (2023)
Voted ""Best Solution for Workflow Automation"" at the Trading Tech Insight Awards (2023)
Voted ""Top Innovator Across Financial Markets"" in TabbFORUM NOVA Awards (2023)
Voted ""Best User Interface Innovation"" in the Risk Markets Technology Awards (2023)
Voted ""Top 100 Most Promising Private FinTech Companies"" by CB Insights (2023)
Voted ""Most Influential Financial Technology Firm"" by Harrington Starr (2023)


RECRUITERS NOTICE: Recruiters - if you wish to reach out to us regarding this job posting, you may reach out to externalrecruitment@here.io in order for your communication to be reviewed. HERE will review these communications if external help is needed for a position. Agencies may not contact individuals within our organization with solicitations. Firms that do not follow these guidelines risk having all communication from their firm being blocked. We thank you in advance for your cooperation in following our process.

Sponsorship - While we highly value all of our candidates, we are not offering sponsorship for this role.

Salary Range: $70k - $120k

Salary Range Disclaimer: This base salary range represents the low and high end salary range for this particular position; not all encompassing of the total compensation package. Actual salaries may vary depending upon but not limited to experience, special skill set, education and location. This range represents only one aspect of HERE's total compensation package offered to employees. Other forms of compensation may be stock options, commissions, paid time off and other variable benefits. Learn more about additional HERE compensation benefits above."
"junior devops engineer","OVA.Work","Alpharetta, GA","https://www.linkedin.com/jobs/view/junior-devops-engineer-at-ova-work-4309344701?position=2&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=DY89pQYc6%2B%2FaeJ1xyvDHlA%3D%3D","Job Title: Junior DevOps Engineer

Location: Remote

Job Type: Full-time

Experience Level: Entry-Level (0-2 years)

Department: IT / Engineering / DevOps

Job Summary

We are looking for a motivated and detail-oriented Junior DevOps Engineer to join our growing DevOps team. This role is ideal for someone with a foundational understanding of DevOps practices and a passion for automation, cloud technologies, and continuous integration/deployment. You will assist in maintaining and improving our infrastructure, deployment pipelines, and monitoring systems.

Key Responsibilities


Assist in the setup, maintenance, and monitoring of CI/CD pipelines.
Support cloud infrastructure (AWS, Azure, GCP) and help manage deployments.
Collaborate with development and operations teams to ensure reliable software delivery.
Write scripts and automation tools to streamline operations and deployments.
Monitor system performance and troubleshoot issues in development and production environments.
Maintain documentation for infrastructure and deployment processes.
Learn and apply best practices in security, scalability, and reliability.


Required Qualifications


Bachelor's degree in Computer Science, Information Technology, or related field.
Basic understanding of DevOps principles and software development lifecycle.
Familiarity with Linux/Unix systems and shell scripting.
Exposure to cloud platforms (AWS, Azure, or GCP).
Experience with version control systems (e.g., Git).
Knowledge of CI/CD tools (e.g., Jenkins, GitLab CI, GitHub Actions).
Strong problem-solving and communication skills.
Eagerness to learn and grow in a fast-paced environment.


Preferred Qualifications


Internship or project experience in DevOps or system administration.
Familiarity with containerization tools (Docker) and orchestration (Kubernetes).
Experience with Infrastructure as Code (Terraform, Ansible).
Basic knowledge of monitoring tools (Prometheus, Grafana, ELK Stack).


Benefits


Competitive salary and growth opportunities.
Mentorship from senior engineers.
Health and wellness benefits.
Flexible work hours and remote work options.
Access to training and certification programs."
"DevOps Engineer - Remote","The Dignify Solutions, LLC","Newtown Square, PA","https://www.linkedin.com/jobs/view/devops-engineer-remote-at-the-dignify-solutions-llc-4341955705?position=3&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=wSeowlAg3U9jd%2BOARVllBg%3D%3D","Over 12 -15 years of overall expereince needed.
A solid foundation in computer science, with strong competencies in data structures, algorithms, and software design.
Large systems software design and development experience.
Experience performing in-depth troubleshooting and unit testing with both new and legacy production systems.
Experience in programming and experience with problem diagnosis and resolution.
Kubernetes (3-4 YOE) and Fieldglass Experience (1-2 YOE)"
"DevOps Engineer - Remote","The Dignify Solutions, LLC","Newtown Square, PA","https://www.linkedin.com/jobs/view/devops-engineer-remote-at-the-dignify-solutions-llc-4347005704?position=4&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=xoXW%2BJGzyU889cXegsu2tw%3D%3D","Bachelor's degree in a technical field such as computer science, computer engineering or related field required 0-2 years experience required.
1-2 years of experience with Kubernetes.
ISBN experience preferred.
A solid foundation in computer science , with strong competencies in data structures, algorithms, and software design large systems software design and development experience.
Experience performing in-depth troubleshooting and unit testing with both new and legacy production systems experience in programming and experience with problem diagnosis and resolution."
"Junior DevOps Engineer","GliaCell Technologies","Hanover, MD","https://www.linkedin.com/jobs/view/junior-devops-engineer-at-gliacell-technologies-4338894490?position=5&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=nuAwBPVqxsdtYM3iL8GQ0g%3D%3D","An active or rein-statable TS/SCI with Polygraph security clearance is REQUIRED. Please do not apply if you currently do not possess this level of clearance.***


Are you a Junior DevOps Engineer who is ready for a new challenge that will launch your career to the next level?


Tired of being treated like a company drone?
Tired of promised adventures during the hiring phase, then being dropped off on a remote contract and never seen or heard from the mothership again?
Our engineers were certainly tired of the same.


At GliaCell our slogan is ‚ÄúWe make It happen‚Äù.


We will immerse you in the latest technologies.
We will develop and support your own personalized training program to continue your individual growth.
We will provide you with work that matters with our mission-focused customers, and surround you with a family of brilliant engineers.


Culture isn‚Äôt something you need to talk about‚Ä¶if it just exists.

If this sounds interesting to you, then we‚Äôd like to have a discussion regarding your next adventure! If you want to be a drone, this isn‚Äôt the place for you.

We Make It Happen!

GliaCell Technologies focuses on Software & System Engineering in Enterprise and Cyber Security solution spaces. We excel at delivering stable and reliable software solutions using Agile Software Development principles. These provide us the capability to deliver a quick turn-around using interactive applications and the integration of industry standard software stacks.

GliaCell‚Äôs Enterprise capabilities include Full-Stack Application Development, Big Data, Cloud Technologies, Analytics, Machine Learning, AI, and DevOps Containerization. We also provide customer solutions in the areas of CND, CNE, and CNO by providing our customers with assessments and solutions in Threat Mitigation, Vulnerability Exposure, Penetration Testing, Threat Hunting, and Preventing Advanced Persistent Threat.

We Offer


Long term job security
Competitive salaries & bonus opportunities
Challenging work you are passionate about
Ability to work with some amazingly talented people


Job Description

GliaCell is seeking a Junior DevOps Engineer on one of our subcontracts. This is a full-time position offering the opportunity to support a U.S. Government customer. The mission is to provide technical expertise that assists in sustaining critical mission-related software and systems to a large government contract.

Responsibilities


Establishing a test framework and automated tests utilizing Cucumber and Cypru
Knowledgeable in Microservices design & architecture, CI/CD, Test frameworks and automation, Agile Methodology.
Execute load and performance testing, chaos testing, functional testing and end-to-end testin
Agile development and delivery of software
Communication and collaboration: Software Development is a team-oriented discipline. Engineers need to be able to communicate and collaborate effectively with other team members, as well as with stakeholders.


Required Skills


Python and Cucumber


Desired Skills:


AWS services such as Lambdas, Step Functions, EC2 and S3


Key Requirements

To be considered for this position you must have the following:


Possess an active or rein-statable TS/SCI with Polygraph security clearance.
U.S. Citizenship.
Works well independently as well as on a team.
6+ years experience as a Developer in programs and contracts of similar scope, type, and complexity is required. A bachelor‚Äôs degree in a technical discipline from an accredited college or university is required. Five (4) years of development experience may be substituted for a bachelor‚Äôs degree.


Location: Annapolis Junction, MD

Salary Range: The salary range for this full-time position is $50,000 to $120,000. Our salary ranges are determined by position, level, skills, professional experience, relevant education and certifications. The range displayed on each job posting reflects the minimum and maximum target salaries for this position across our projects. Within the range, your salary is determined by your individual benefits package selection. Your recruiter can share more about the specific salary range for your preferred position during the hiring process.

Benefits


Medical, Dental, and Vision Coverage for Employee and Dependents
Up to 25 Days of Paid Time Off
Up to 40 hours of PTO Carryover
11 Federal Government Holidays
Work From Home Opportunities
401K Company Contribution, Fully Vested Day 1
Discretionary, Certification, and Sign-On Bonus Potential
Employee Referral Bonus Program
Annual Professional Development
100% Premium Covered for Life & Disability Insurances
Additional Voluntary Life Insurance Coverage Available
Employee Assistance Program
Travel Protection Program
Financial Planning Assistance
Bereavement and Jury Duty Leave
Monthly Team and Family Events
Technology Budget
Global Entry
Annual Swag Budget


Learn more about GliaCell Technologies: https://gliacelltechnologies.applytojob.com/apply/

GliaCell Technologies, LLC is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status."
"DevOps Cloud Engineer Based in U.S.A","Advancio","United States","https://www.linkedin.com/jobs/view/devops-cloud-engineer-based-in-u-s-a-at-advancio-4324442139?position=6&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=uLqSGjoKo22trA1SVgOuMw%3D%3D","This is a remote position.

Who We Are:


At Advancio, we are passionate about technology and its ability to transform the world. We are rapidly expanding and building a company where we serve exceptional businesses, hire top talent, and have a lot of fun doing what we love!


Job Summary:

We are seeking a skilled DevOps Cloud Engineer to design, implement, and manage scalable cloud-based infrastructure and DevOps processes. The ideal candidate will have extensive experience with cloud platforms, CI/CD pipelines, and automation tools, ensuring the efficient deployment and operation of applications.


What will you do:


Design, deploy, and manage cloud infrastructure on platforms such as AWS, Azure, or Google Cloud Platform (GCP).

Build and maintain CI/CD pipelines to streamline development and deployment processes.

Automate infrastructure provisioning, configuration, and monitoring using tools like Terraform, Ansible, or similar.

Ensure system reliability, availability, and performance through robust monitoring and alerting.

Collaborate with development teams to optimize the delivery and scalability of applications.

Manage containerized workloads using Docker and orchestration platforms such as Kubernetes.

Implement security best practices for cloud environments, including identity management, encryption, and compliance adherence.

Stay updated with the latest DevOps tools and methodologies to enhance team efficiency.




Requirements






5+ years of experience in DevOps, cloud engineering, or related roles.

Advanced English communication skills, both verbal and written.

Proficiency in at least one major cloud platform (AWS, Azure, or GCP).

Hands-on experience with CI/CD tools (e.g., Jenkins, GitLab CI/CD, CircleCI).

Strong scripting skills in Python, Bash, or similar languages.

Solid knowledge of infrastructure-as-code (IaC) tools like Terraform or CloudFormation.

Experience with containerization (Docker) and orchestration (Kubernetes).

Familiarity with monitoring and logging tools like Prometheus, Grafana, or ELK Stack.

Strong understanding of networking, security, and system architecture."
"DeVops Engineer","Pittsburgh Robotics Network","Pittsburgh, PA","https://www.linkedin.com/jobs/view/devops-engineer-at-pittsburgh-robotics-network-4347073200?position=7&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=woNVKIYyC5ACM9jNZfAVEg%3D%3D","DevOps Engineer

TDK SensEI

Pittsburgh, PA

This position is for our Pittsburgh, PA office - only apply if you are based there or willing to relocate.

At TDK SensEI, we are transforming how industrial customers utilize and interact with sensor data. We specialize in developing advanced AI solutions capable of running directly on edge devices. By processing data locally, TDK SensEI enhances real-time decision-making, privacy, security, and cost efficiency. Our offerings include automated machine learning tools, AI-powered condition-based monitoring systems, and various sensor devices optimized for low latency and power consumption. Collaborating with leading global companies, we empower teams to effortlessly devise and implement machine learning solutions for industrial applications, all without the need for coding.

We are seeking a Dev Ops engineer to join our team. In this position, the candidate will be responsible for managing, operating, and provisioning cloud environments such as AWS, Azure, Google cloud. You will work with development, security, and operations teams to deploy, scale, and operate dev environments. You are also responsible for improving and automating the dev environment. You will establish configuration management, automate our infrastructure, implement continuous integration, and train the team in DevOps best practices.

As a Dev Ops Engineer, Your Responsibilities Will Include


Designing, implementing, and maintaining tools and processes for continuous integration, delivery, and deployment of software
Working with developers to deploy and manage code changes
Working with operations staff to ensure that systems are up and running smoothly
Automating, monitoring, testing, configuring, networking, and Infrastructure as Code (IaC)
Streamlining and automating processes while troubleshooting existing development procedures
Managing the creation, release, and configuration of production systems
Architecting and optimizing several service components running on AWS environment


Skills & Requirements


Bachelor‚Äôs degree or equivalent experience
Minimum 2 years of experience in DevOps, infrastructure automation or similar role
Knowledge of Linux/UNIX administration
Proficiency in Python, JavaScript and other script environments (e.g. bash)
Experience with containerization technologies, Docker and associated tooling
Experience designing and implementing CI/CD pipelines
Experience operating databases such as PostgreSQL or MySQL, especially in cloud-native services like RDS
Awareness of critical concepts in DevOps and Agile principles
US work authorization


Nice To Have


AWS certifications (e.g., AWS Certified DevOps Engineer, AWS Certified Solutions Architect).
Familiarity with other cloud providers (Azure, Google Cloud).
Experience with container orchestration systems such as Kubernetes/EKS"
"DevOps Engineer","Princeton IT Services, Inc","Englewood Cliffs, NJ","https://www.linkedin.com/jobs/view/devops-engineer-at-princeton-it-services-inc-4338714288?position=8&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=k%2Fa4ecHaA7u8zQRszZwicA%3D%3D","Job Title: DevOps Engineer

Location: Englewood Cliffs, NJ

Employment Type: W2 Only

Job Summary

We are seeking a DevOps Engineer with strong hands-on experience in Linux, Docker, and Kubernetes to support and optimize our deployment environment in Englewood Cliffs, NJ. This is a W2-only role requiring solid skills in automation, CI/CD, and container orchestration. The ideal candidate will ensure smooth application releases, maintain system stability, and collaborate closely with development teams.

Key Responsibilities


Manage and support Linux-based systems in production and staging environments.
Build, maintain, and optimize CI/CD pipelines for automated deployments.
Create, manage, and troubleshoot Docker containers and images.
Deploy, monitor, and tune Kubernetes clusters and workloads.
Automate infrastructure tasks using Shell or Python scripts.
Implement and manage monitoring and logging tools (Prometheus, Grafana, ELK, etc.).
Troubleshoot system, container, and cluster-level issues end-to-end.
Work cross-functionally with development and QA teams to ensure smooth releases.


Required Skills


8+ years of DevOps or related experience.
Strong hands-on experience with Linux administration.
Solid experience working with Docker for containerization.
Strong working knowledge of Kubernetes (deployments, scaling, troubleshooting).
Experience building CI/CD pipelines (Jenkins, GitLab CI, GitHub Actions).
Strong scripting skills in Shell/Bash/Python.
Experience with monitoring and logging tools."
"DevOps Engineer","Lean TECHniques","Johnston, IA","https://www.linkedin.com/jobs/view/devops-engineer-at-lean-techniques-4336685413?position=9&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=YJJMdiOubtmtb%2FCA6zw03g%3D%3D","Maybe you‚Äôre bored and need a new challenge. Or you‚Äôre sick of all the bureaucracy and just want to focus on designing kick-ass software.

Whatever the reason, we want you to know that LT is different. And not just air quotes ‚Äúdifferent,‚Äù but more like ‚Äúbreathing easy for the first time in a long time‚Äù different.

It‚Äôs a place where you can write your own story and make a difference along the way. At LT, you‚Äôll have the freedom and flexibility to do what you think needs to be done, and you‚Äôll get to do it while working alongside a team of other curious individuals who love a good challenge too.

We‚Äôre currently looking to add a DevOps Engineer to our crew of nerds. If you‚Äôre someone who has 5+ years of DevOps experience, we'd love to chat!"
"DevOps Engineer","LifeMD","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-lifemd-4337132819?position=10&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=IDhA1Yg1Rxg0CC5up6SJmw%3D%3D","About us:

LifeMD is a leading digital healthcare company committed to expanding access to virtual care, pharmacy services, and diagnostics by making them more affordable and convenient for all.¬†Focused on both treatment and prevention, our unique care model is designed to optimize the patient experience and improve outcomes across more than 200 health concerns.¬†

To support our expanding patient base, LifeMD leverages a vertically-integrated, proprietary digital care platform, a 50-state affiliated medical group, a 22,500-square-foot affiliated pharmacy, and a U.S.-based patient care center.¬†Our company ‚Äî with offices in New York City; Greenville, SC; and Huntington Beach, CA ‚Äî is powered by a dynamic team of passionate professionals. From clinicians and technologists to creatives and analysts, we're united by a shared mission to revolutionize healthcare.¬†Employees enjoy a collaborative and inclusive work environment, hybrid work culture, and numerous opportunities for growth. Want your work to matter? Join us in building a future of accessible, innovative, and compassionate care.


About the role:

LifeMD is seeking a highly motivated and experienced DevOps Engineer to join our dynamic Technology team. This individual will serve as a critical link between software development and IT operations, playing a pivotal role in designing, implementing, and maintaining automated processes for software delivery, infrastructure management, and system monitoring. The primary objective is to accelerate our release cycles, enhance system stability, and improve overall operational efficiency across our diverse cloud infrastructure, all while strictly adhering to stringent healthcare industry compliance standards, including HIPAA and SOX.


Responsibilities:


Design, implement, and manage scalable, secure, and cost-effective cloud infrastructure primarily on AWS using Terraform
Develop and version control Terraform modules for automated provisioning, updating, and de-provisioning of cloud resources (e.g., EC2, S3, RDS, VPC, Lambda in AWS)
Design, build, and optimize automated CI/CD pipelines using GitHub Actions for various applications and microservices
Integrate automated testing, static code analysis, security scanning, and deployment steps into CI/CD workflows for high quality and secure releases
Implement, configure, and maintain comprehensive monitoring, logging, and alerting solutions (e.g., AWS CloudWatch, Datadog) for all environments
Develop custom dashboards, metrics, and alerts for real-time visibility into system health, performance, and security events
Proactively analyze logs and metrics to identify potential bottlenecks and issues
Participate in on-call rotations to swiftly respond to and resolve critical incidents, ensuring high service availability
Automate repetitive operational tasks, system configurations, and deployment processes using Python and Bash to enhance efficiency



Requirements



Basic Qualifications:

Bachelor's degree in Computer Science, Information Technology, Engineering, or a related technical field, or equivalent work experience
3+ years of progressive experience as a DevOps Engineer, Site Reliability Engineer (SRE), or similar role in a cloud-native environment
Expert-level proficiency in AWS services (EC2, S3, RDS, VPC, Lambda, IAM, CloudWatch, etc.). Solid understanding and working knowledge of GCP, Digital Ocean, and Azure concepts and services
Expertise in Terraform for multi-cloud infrastructure provisioning and management, including experience with state management, modules, and workspaces
Highly skilled in using Git and GitHub for source code management, branching strategies, and pull request workflows
Hands-on experience with implementing and managing monitoring and logging solutions (e.g., AWS CloudWatch, Datadog, ELK stack)
Solid understanding of cloud networking concepts, including VPCs, subnets, routing tables, load balancers, DNS, and VPNs
Strong understanding of cloud security best practices, identity and access management (IAM), security groups, network ACLs, and data protection principles
Working knowledge of database concepts and experience with various database types (e.g., MongoDB, PostgreSQL, MySQL)
Strong understanding and implementation of Ansible for cloud workload automations
Hands-on experience with Linux (Ubuntu) and update/patching mechanisms



Preferred Qualifications:

Experience in the healthcare industry or a highly regulated environment, with a demonstrable understanding of compliance requirements (e.g., HIPAA, SOC2)
Relevant cloud certifications (e.g., AWS Certified DevOps Engineer - Professional, AWS Certified Solutions Architect - Associate/Professional)
In-depth experience with GitHub Actions for designing, implementing, and maintaining automated build, test, and deployment pipelines. Familiarity with other CI/CD tools
Strong proficiency in Python and Bash scripting for automation, system administration, and tool development.
Knowledge of Node.js or PHP
Experience with Docker for containerizing applications. Familiarity with container orchestration platforms (e.g., Kubernetes, AWS ECS)
Exceptional problem-solving and analytical skills with a proactive approach to identifying and resolving complex technical issues
Excellent communication and interpersonal skills, capable of effectively collaborating with diverse cross-functional teams (developers, QA, product, security)
Strong sense of ownership, accountability, and ability to work independently while also being a strong team player
A continuous learning mindset, staying updated with emerging technologies, industry trends, and best practices in the DevOps space
Meticulous attention to detail and strong documentation skills



Benefits


Salary Range: $130,000-$140,000
Health Care Plan (Medical, Dental & Vision)
Retirement Plan (401k, IRA)
Life Insurance (Basic, Voluntary & AD&D)
Unlimited PTO Policy
Paid Holidays
Short Term & Long Term Disability
Training & Development"
"DevOps Engineer (35 LPA - 55 LPA)","CodeRound AI","Greater Bloomington Area","https://www.linkedin.com/jobs/view/devops-engineer-35-lpa-55-lpa-at-coderound-ai-4308183910?position=11&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=hpkjwgTlAEYKBTppU8xHzA%3D%3D","üöÄ What We‚Äôre Building


CodeRound AI matches top 5% tech talent to fastest growing VC funded AI startups.
Candidates apply once and get UPTO 10 remote as well as onsite interview opportunities IF selected!
Top-tier product startups in US, UAE & India have hired top engineers & ML folk using CodeRound


üß© What You‚Äôll Do


Build and optimize our cloud infrastructure ‚Äî scalable, secure, and cost-effective (mostly AWS).
Set up and manage CI/CD pipelines to ensure smooth deployment across backend, AI services, and mobile.
Containerize backend services (FastAPI, Rails) and optimize them for performance.
Implement monitoring, alerting, and logging to catch issues before users do.
Optimize database performance (Postgres, Redis) and manage backups and scaling.
Collaborate with backend, AI, and product teams to deploy new features safely and quickly.
Champion infra-as-code and automation wherever possible.


üí• Why this is exciting


You'll own DevOps for a high-usage, real-world AI platform ‚Äî not just internal tools.
You‚Äôll work on real-time, high-stakes flows ‚Äî interviews, scoring, hiring decisions.
You‚Äôll work closely with founders, ship weekly, and see the direct impact of your work.


‚úÖ You‚Äôll Be Great At This If You


Have 4+ years of experience as a DevOps engineer, SRE, or infrastructure engineer.
Are strong with AWS services (EC2, RDS, ECS/EKS, S3, CloudWatch).
Can write clean, reusable Terraform or CloudFormation code.
Have experience setting up CI/CD pipelines and optimizing build/release flows.
Are comfortable with Docker, Linux servers, and basic networking (VPCs, security groups).
Understand application and database scaling (horizontal/vertical).


‚ö° Bonus If You


Have experience supporting AI/ML pipelines in production (fine-tuning infra, vector DBs, etc.).
Know cost optimization tricks for cloud infra (spot instances, autoscaling groups, etc.).
Are excited to eventually build a small infra team"
"Devops Engineer","The Dignify Solutions, LLC","Brooklyn, OH","https://www.linkedin.com/jobs/view/devops-engineer-at-the-dignify-solutions-llc-4341915759?position=12&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=LjLS%2FYPh4IcJm0dQGUyyTQ%3D%3D","Job Description:


Serve as a subject matter expert to develop and support DevOps Web Access Management solutions
Install, configure, and maintain automation solutions, in support of KeyBank infrastructure
Develop Standard Operating Procedures, maintenance plans and provide status reports as required
Perform daily operational tasks as required for the Web Access Management team


Qualifications:


General technical capabilities across all portions of the infrastructure stacks
Independent thinker and self-starter
Generates ideas, innovative
Experienced with automation frameworks using an automation first approach
Proficient in one or more programming/scripting languages (Python, Ansible, etc.)
Proficient with one or more cloud orchestration tools (Terraform, Cloud Formation, etc.)
Conduct performance analysis and optimization
Experienced with public cloud providers such as GCP, Azure and AWS
Comfortable operating in a Linux environment


Preferred Skills:


Public and Private Cloud automation experience in production & non-production environments
Knowledge of web access management technologies and deployments
Knowledge of web access management technologies and deployments
Knowledge of routing & switching technologies and configurations
Knowledge of compute and storage solutions in data center environments
Experience with Service Now change management and problem management platform
Ability to balance workload amidst competing deadlines
Ability to perform knowledge transfers with peer engineers
Contribute to the reliability, performance, supportability, and security of web access management infrastructure
Review procedures for change and configuration management in all environments"
"DevOps Engineer","LifeMD","Huntington Beach, CA","https://www.linkedin.com/jobs/view/devops-engineer-at-lifemd-4337182535?position=13&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=GdEMG4W3PVOCpXvkjhoVYA%3D%3D","About us:

LifeMD is a leading digital healthcare company committed to expanding access to virtual care, pharmacy services, and diagnostics by making them more affordable and convenient for all.¬†Focused on both treatment and prevention, our unique care model is designed to optimize the patient experience and improve outcomes across more than 200 health concerns.¬†

To support our expanding patient base, LifeMD leverages a vertically-integrated, proprietary digital care platform, a 50-state affiliated medical group, a 22,500-square-foot affiliated pharmacy, and a U.S.-based patient care center.¬†Our company ‚Äî with offices in New York City; Greenville, SC; and Huntington Beach, CA ‚Äî is powered by a dynamic team of passionate professionals. From clinicians and technologists to creatives and analysts, we're united by a shared mission to revolutionize healthcare.¬†Employees enjoy a collaborative and inclusive work environment, hybrid work culture, and numerous opportunities for growth. Want your work to matter? Join us in building a future of accessible, innovative, and compassionate care.


About the role:

LifeMD is seeking a highly motivated and experienced DevOps Engineer to join our dynamic Technology team. This individual will serve as a critical link between software development and IT operations, playing a pivotal role in designing, implementing, and maintaining automated processes for software delivery, infrastructure management, and system monitoring. The primary objective is to accelerate our release cycles, enhance system stability, and improve overall operational efficiency across our diverse cloud infrastructure, all while strictly adhering to stringent healthcare industry compliance standards, including HIPAA and SOX.


Responsibilities:


Design, implement, and manage scalable, secure, and cost-effective cloud infrastructure primarily on AWS using Terraform
Develop and version control Terraform modules for automated provisioning, updating, and de-provisioning of cloud resources (e.g., EC2, S3, RDS, VPC, Lambda in AWS)
Design, build, and optimize automated CI/CD pipelines using GitHub Actions for various applications and microservices
Integrate automated testing, static code analysis, security scanning, and deployment steps into CI/CD workflows for high quality and secure releases
Implement, configure, and maintain comprehensive monitoring, logging, and alerting solutions (e.g., AWS CloudWatch, Datadog) for all environments
Develop custom dashboards, metrics, and alerts for real-time visibility into system health, performance, and security events
Proactively analyze logs and metrics to identify potential bottlenecks and issues
Participate in on-call rotations to swiftly respond to and resolve critical incidents, ensuring high service availability
Automate repetitive operational tasks, system configurations, and deployment processes using Python and Bash to enhance efficiency



Requirements



Basic Qualifications:

Bachelor's degree in Computer Science, Information Technology, Engineering, or a related technical field, or equivalent work experience
3+ years of progressive experience as a DevOps Engineer, Site Reliability Engineer (SRE), or similar role in a cloud-native environment
Expert-level proficiency in AWS services (EC2, S3, RDS, VPC, Lambda, IAM, CloudWatch, etc.). Solid understanding and working knowledge of GCP, Digital Ocean, and Azure concepts and services
Expertise in Terraform for multi-cloud infrastructure provisioning and management, including experience with state management, modules, and workspaces
Highly skilled in using Git and GitHub for source code management, branching strategies, and pull request workflows
Hands-on experience with implementing and managing monitoring and logging solutions (e.g., AWS CloudWatch, Datadog, ELK stack)
Solid understanding of cloud networking concepts, including VPCs, subnets, routing tables, load balancers, DNS, and VPNs
Strong understanding of cloud security best practices, identity and access management (IAM), security groups, network ACLs, and data protection principles
Working knowledge of database concepts and experience with various database types (e.g., MongoDB, PostgreSQL, MySQL)
Strong understanding and implementation of Ansible for cloud workload automations
Hands-on experience with Linux (Ubuntu) and update/patching mechanisms



Preferred Qualifications:

Experience in the healthcare industry or a highly regulated environment, with a demonstrable understanding of compliance requirements (e.g., HIPAA, SOC2)
Relevant cloud certifications (e.g., AWS Certified DevOps Engineer - Professional, AWS Certified Solutions Architect - Associate/Professional)
In-depth experience with GitHub Actions for designing, implementing, and maintaining automated build, test, and deployment pipelines. Familiarity with other CI/CD tools
Strong proficiency in Python and Bash scripting for automation, system administration, and tool development.
Knowledge of Node.js or PHP
Experience with Docker for containerizing applications. Familiarity with container orchestration platforms (e.g., Kubernetes, AWS ECS)
Exceptional problem-solving and analytical skills with a proactive approach to identifying and resolving complex technical issues
Excellent communication and interpersonal skills, capable of effectively collaborating with diverse cross-functional teams (developers, QA, product, security)
Strong sense of ownership, accountability, and ability to work independently while also being a strong team player
A continuous learning mindset, staying updated with emerging technologies, industry trends, and best practices in the DevOps space
Meticulous attention to detail and strong documentation skills



Benefits


Salary Range: $130,000-$140,000
Health Care Plan (Medical, Dental & Vision)
Retirement Plan (401k, IRA)
Life Insurance (Basic, Voluntary & AD&D)
Unlimited PTO Policy
Paid Holidays
Short Term & Long Term Disability
Training & Development"
"Devops Engineer","Hoplite Solutions LLC","Bethesda, MD","https://www.linkedin.com/jobs/view/devops-engineer-at-hoplite-solutions-llc-4336082750?position=14&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=yHvqvTLgNvsoaDmAvu4mFQ%3D%3D","Hoplite Solutions is hiring DevOps Engineers at all experience levels to join our team in Bethesda, MD. In this mission-critical role, you will provide essential system support to our customer while collaborating closely with software development teams and other key technology stakeholders. You will help maintain, enhance, and support a range of IC enterprise products‚Äîboth legacy systems and new solutions‚Äîwithin an Agile SAFe environment.

As a DevOps Engineer, you will work hand-in-hand with software engineering teams to deploy and operate systems, automate and optimize processes, and build and maintain tools that support deployment, monitoring, and ongoing operations. You will also troubleshoot and resolve issues across development, test, and production environments, ensuring reliability, efficiency, and continuous improvement across the enterprise.

Primary Responsibilities:


Supports software deployments, cloud infrastructure baselines, and operational availability of production systems
Managing, building, configuring, administering, operating and maintaining all components that comprise the DevOps environment
Defining enterprise Continuous Integration/Continuous Deployment processes and best practices
Codifying DevOps best practices across the enterprise
Developing and maintaining scripts to automate tool deployment to an AWS cloud environment and other tasks
Scripting and maintaining build environments
Working with project teams to integrate their products into the DevOps environment


Basic Qualifications


Demonstrated experience setting up one or more of the following tools: GitHub, Jira, Confluence, Jenkins, and Katalon Studio
Demonstrated experience troubleshooting issues with two or more of the following tools: GitHub, Jira, Confluence, Jenkins, and Katalon Studio
Demonstrated experience working within a software development team and supporting developers and developer activities
Bachelors degree with 4 or more years of prior relevant work experience or Masters with 2 or more years of prior relevant work experience. Will consider additional work experience in lieu of a degree
To be considered must have an active TS/SCI with polygraph security clearance


Preferred Qualifications


AWS Associate Certification (Developer, Solution Architect, or Sys Ops Administrator)
AWS Professional Certification (DevOps Engineer or Solutions Architect)
Demonstrated experience in container orchestration using Docker, Vagrant, Kubernetes, or AWS ECS/ECR
Demonstrated experience with Languages including Java, Python, JavaScript, Ruby, PHP, and Unix shell Scripting
Demonstrated experience with Ansible, or Puppet


Hoplite Solutions offers very competitive salaries and an excellent benefits package, to include a 7% employer 401k contribution, fully paid healthcare for our employees, outstanding training benefits, company funded life insurance and short-term disability insurance, and many more.

Powered by JazzHR

wwBe8pS8mn"
"DevOps Engineer","The Dignify Solutions, LLC","Brooklyn, OH","https://www.linkedin.com/jobs/view/devops-engineer-at-the-dignify-solutions-llc-4341985652?position=15&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=AWXQz9EELpZu36y0cpMgSg%3D%3D","Qualifications:


General technical capabilities across all portions of the infrastructure stacks
Independent thinker and self-starter
Generates ideas, innovative
Experienced with automation frameworks using an automation first approach
Proficient in one or more programming/scripting languages (Python, Ansible, etc.)
Proficient with one or more cloud orchestration tools (Terraform, Cloud Formation, etc.)
Conduct performance analysis and optimization
Experienced with public cloud providers such as GCP, Azure and AWS
Comfortable operating in a Linux environment


Preferred Skills:


Public and Private Cloud automation experience in production & non-production environments
Knowledge of web access management technologies and deployments
Knowledge of web access management technologies and deployments
Knowledge of routing & switching technologies and configurations
Knowledge of compute and storage solutions in data center environments
Experience with Service Now change management and problem management platform
Ability to balance workload amidst competing deadlines
Ability to perform knowledge transfers with peer engineers
Contribute to the reliability, performance, supportability, and security of web access management infrastructure
Review procedures for change and configuration management in all environments."
"DevOps Engineer","Verra Mobility","Indianapolis, IN","https://www.linkedin.com/jobs/view/devops-engineer-at-verra-mobility-4339356296?position=16&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=NyL7ZjoApv6V%2Fk5Ozm1kSw%3D%3D","Who we are‚Ä¶

Verra Mobility is a global leader in smart mobility. We develop technology-enabled solutions that help the world move safely and easily. We are fostering the development of safe cities, working with police departments and municipalities to install over 4,000 red-light, speed, and school bus stop arm safety cameras across North America. We are also creating smart roadways, serving the world's largest commercial fleets and rental car companies to manage tolling transactions and violations for over 8.5 million vehicles. And we are a leading provider of connected systems, processing nearly 165 million transactions each year across 50+ individual tolling authorities.

Culture

Verra Mobility Corporation is a rapidly-growing, entrepreneurial company that operates with a people-first philosophy and approach. The company lives by its core values‚ÄîDo What's Right, Lead with Grace, Win Together, and Own It‚Äîin everything it does for its customers and team members. The company seeks to grow aggressively, both organically and through acquisition, to continue to be the undisputed market leader with these five core competencies: bias for action, customer focus, teamwork, drive for results, and commitment to excellence.

Position Overview:

We are seeking an experienced and detail oriented Devops Engineer to join our team. In this role, you will be responsible for creating, maintaining, and securing our Devops pipelines and deployment systems to ensure high levels of performance and availability. This position is ideal for someone with a strong background in CI/CD methodologies particularly in cloud environments.

Essential Responsibilities:


Spend 50% writing automation scripts in Python and Bash.
Write various CI/CD pipelines for code releases.
Ensure that pipelines meet both operations and security requirements.
Partner with developers to identify areas of improvement in the developer experience.
Design and implement innovations that improve software velocity, infrastructure resiliency, security and data availability.
Work with Software and Engineering to ensure new pipelines are created in parallel to code build.
Work with Architecture on setting the path forward and gathering changes to the technology stack.
Ability to respond to system issues, drive and participate in high - priority incident calls and emergency activities outside of standard office hours as needed.
Collaborate with internal and external application, business partners to gain understanding of their business needs and adapt departmental roadmap plans and priorities to address operational challenges.
Work with QE to ensure all automated testing is run during the deployment of the code.
Ability to participate in an on-call rotation as needed.


Qualifications:


Must have 5 years of Devops Engineering experience.
Familiarity with a wide range of systems engineering tools, including source code repository hubs, continuous integration services, issue tracking, test automation, deployment automation, development team collaboration, project management.
Need to have strong scripting skills to create automation in Python preferred or Bash.
Experience with Cloudformation or Terraform for infrastructure as code.
Used continuous integration and continuous development (CI/CD) tools such as Jenkins, Gitlab, or Github Actions, preferred.
Knowledge of DevOps tools such as, GitHub Actions, CloudFormation, GIT, SVN, Jenkins, JIRA, Rally, Greenhopper, Puppet/Chef Vagrant, Selenium, Azure DevOps (for sprint planning).
Understanding of enterprise GIT repositories including branching and forking.
Hands-on Familiarity with AWS CloudWatch, AWS CloudTrail, AWS X-Ray, Grafana, and Prometheus.
Hands-on experience with Veracode and SonarQube are a plus.
Must be located in Phoenix, AZ, Indianapolis, IN, or NY and be willing to commute into office 3 days a week.


This position is not eligible for sponsorship now or in the future and is only considering local Arizona, New York, or Indiana talent.



Verra Mobility Values



An ideal candidate for this role naturally works in alignment with the Verra Mobility Core Values:


Own It. We focus on high performance and drive toward breakthrough outcomes. Our employees ensure accountability, optimize and align work, focus on the customer, and cultivate innovation.
Do What's Right. We champion integrity and good character. Our team members model ethical behavior, demonstrate good judgment and are courageous.
Lead with Grace. We express humility and compassion, and we are authentic and candid. Our employees demonstrate self-awareness, care for others, instill trust, and communicate effectively.
Win Together. We believe in growing and inspiring people together. We seek people who collaborate, value differences, think and act globally, foster an engaging work environment, and recognize and develop others.




With your explicit consent which you provided as part of the application process, we will retain candidate personal data solely for the business purpose for which it was collected. In no event will we retain such data more than two (2) years following the closure of the recruitment process relating to the role for which you applied or in the event other related job opportunities arise within the company. Verra Mobility Applicant Privacy Notice

Verra Mobility is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status."
"DevOps Engineer","Protege","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-protege-4331315574?position=17&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=F%2BXW79xICFlj%2B5PnCwsL7g%3D%3D","Company Overview:

We are building Protege to solve the biggest unmet need in AI ‚Äî getting access to the right training data. The process today is time intensive, incredibly expensive, and often ends in failure. The Protege platform facilitates the secure, efficient, and privacy-centric exchange of AI training data.

Solving AI‚Äôs data problem is a generational opportunity. We‚Äôre backed by world-class investors and already powering partnerships with some of the most ambitious teams in AI. The company that succeeds will be one of the largest in AI ‚Äî and in tech.

We‚Äôre a lean, fast-moving, high-trust team of builders who are obsessed with velocity and impact. Our culture is built for people who thrive on ambiguity, own outcomes, and want to shape the future of data and AI.

Key Responsibilities and Scope:


As a DevOps Engineer, you will be a critical part of our engineering team, responsible for safeguarding our AI/ML platforms, data pipelines, and cloud infrastructure
You will implement and develop monitoring strategies, and drive controls to protect our most valuable assets


Qualifications:


4+ years of hands-on experience in a DevOps, Architecture, SecOps or Engineering role
Strong experience with major cloud platforms and building cloud-native services including containerization, threat detection, vulnerability, governance, compliance, etc. with AWS preferred
Proficient in scripting languages like Python, SQL, Typescript or similar
Strong experience with infra‚Äëas‚Äëcode, monitoring, and reliability for pipelines; contributing to platform guardrails, governance, compliance, etc
Experience working with cross-functional partners to develop tools and playbooks for best-practices related to Operations


About You:


You are curious, tenacious, and proactive
You are not bothered by ambiguity but embrace finding patterns in complex environments
Excellent problem-solving skills and adaptability in a dynamic and evolving tech landscape
Excited to work in a company that deals with moving and transforming large volumes of data


Bonus if you have these attributes:


Experience with cloud providers like GCP and Azure
Prior startup experience
Security operations and automation experience"
"Devops Engineer","PDG Consulting","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-pdg-consulting-4321885957?position=18&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=1MGktynIGYq7IYavpSgrrQ%3D%3D","Overview

We are seeking a DevOps Engineer to set up, manage, and automate software development operations and processes. The ideal candidate will have strong experience in CI/CD pipelines, cloud service management, and infrastructure monitoring to support efficient, secure, and scalable software delivery.

Responsibilities


Design, implement, and manage CI/CD pipelines to streamline software deployment and integration.
Oversee cloud-based systems and infrastructure management, ensuring reliability and performance.
Automate workflows for system administration, documentation, and monitoring.
Support the development and deployment of AI chatbot infrastructures and related frameworks.
Collaborate with developers, QA engineers, and IT teams to optimize the software lifecycle.


Requirements


Minimum 4 years of experience in ICT systems support, including system administration, documentation, and monitoring.
Hands-on experience with cloud platforms, especially Amazon Web Services (AWS).
Proven experience creating and maintaining AI chatbot infrastructures or similar automation frameworks.
Previous experience working within the UN system is an advantage.
Excellent command of English (required).
Knowledge of French and Arabic is considered an advantage.


Powered by JazzHR"
"DevOps Engineer - 100% Remote","The Dignify Solutions, LLC","Newtown Square, PA","https://www.linkedin.com/jobs/view/devops-engineer-100%25-remote-at-the-dignify-solutions-llc-4347005722?position=19&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=AlC1S4uqiKVApgZzevrgPQ%3D%3D","Summary: The main function of a DevOps Engineer is to design, develop, implement, test, and maintain business and computer applications software or specialized utility programs including mainframe and client/server applications, and major enhancement of existing systems

Job Responsibilities: Fine-tune and improve a variety of sophisticated software implementation projects Gather and analyze system requirements, document specifications, and develop software solutions to meet client needs and data Analyze and review enhancement requests and specifications Implement system software and customize to client requirements Prepare the detailed software specifications and test plans Code new programs to client's specifications and create test data for testing Modify existing programs to new standards and conduct unit testing of developed programs Create migration packages for system testing, user testing, and implementation Provide quality assurance reviews Perform post-implementation validation of software and resolve any bugs found during testing


A solid foundation in computer science, with strong competencies in data structures, algorithms, and software design.
Large systems software design and development experience.
Experience performing in-depth troubleshooting and unit testing with both new and legacy production systems.
Experience in programming and experience with problem diagnosis and resolution.
SAC Experience (1-2 YOE)
Ariba ATHENA Report generation (Some experience)"
"CloudOps Engineer","Protera","United States","https://www.linkedin.com/jobs/view/cloudops-engineer-at-protera-4336621571?position=20&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=Lt7VQbc%2F3SHqEcoNuS%2Buxg%3D%3D","Summary

As a CloudOps Engineer at Protera, you will play a crucial role in maintaining and optimizing our cloud infrastructure. You will be responsible for monitoring and managing cloud services, ensuring the performance and reliability of our cloud applications, and automating processes to enhance operational efficiency. You will work closely with development teams to improve deployment practices and manage incidents in a fast-paced environment.

Key Responsibilities


Monitor cloud infrastructure performance and reliability to ensure optimal service delivery
Automate deployment processes using Infrastructure as Code (IaC) tools like Terraform
Implement and manage CI/CD pipelines to streamline application releases
Collaborate with development teams to integrate DevOps practices into application lifecycles
Troubleshoot cloud architecture and application issues to ensure minimal downtime
Conduct security assessments and implement best practices to secure cloud environments
Document processes and maintain configurations and operational standards


Requirements

Skills & Qualifications

Experience:


3+ years of experience in cloud operations, DevOps, or system administration


Technical Skills:


Proficient with AWS services and cloud architecture
Experience with Infrastructure as Code (IaC) tools, particularly Terraform
Strong understanding of containerization technologies like Docker and orchestration tools such as Kubernetes
Familiarity with CI/CD tools such as Jenkins, GitLab CI, or similar
Knowledge of monitoring tools and log management solutions
Solid troubleshooting skills across cloud-based systems


Education:


Bachelor's degree in Computer Science, Information Technology, or a related field is preferred


Certifications (Preferred):


AWS Certified Solutions Architect or related cloud certification
DevOps or Kubernetes certifications are a plus


Personal Attributes:


Strong analytical and problem-solving skills
Excellent communication and collaboration skills
Ability to work in a fast-paced environment and handle multiple tasks


About Protera

Protera Technologies (www.protera.com) is a leading provider of total IT outsourcing solutions for SAP-centric organizations. Founded in the mid-1990s, we are pioneers in providing SAP services on the cloud, managing thousands of workloads across various cloud platforms. With headquarters in Chicago and offices in Greece and India, we are committed to delivering exceptional cloud hosting, application management, and professional services globally.

Benefits

Protera offers a variety of health and wellbeing programs. Benefit options include two PPO Medical plans, Dental, Vision, Health Savings Account, Flexible Spending Accounts, Dependent Care FSA, 401k retirement savings plan, company paid Life Insurance, Flexible PTO policy, Paid Holidays."
"DevOps Systems Engineer","TensorWave","Las Vegas, NV","https://www.linkedin.com/jobs/view/devops-systems-engineer-at-tensorwave-4338727303?position=21&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=JFjgIHhpYOy2%2FmwGLi1rPw%3D%3D","At TensorWave, we‚Äôre leading the charge in AI compute, building a versatile cloud platform that‚Äôs driving the next generation of AI innovation. We‚Äôre focused on creating a foundation that empowers cutting-edge advancements in intelligent computing, pushing the boundaries of what‚Äôs possible in the AI landscape.

About The Role

We are seeking a highly skilled DevOps & Infrastructure Management Engineer to join our growing infrastructure team. This role is ideal for someone who thrives in hardware-centric environments, enjoys hands-on datacenter and system administration work, and can build reliable automation around large-scale infrastructure. You will be responsible for managing enterprise hardware, monitoring systems, network operations, infrastructure automation, and supporting our compute clusters across multiple data centers.

This role touches every layer of modern infrastructure‚Äîfrom bare metal provisioning, to OS and Kubernetes management, to monitoring and troubleshooting hardware. If you are detail-oriented, resourceful, and comfortable working with both low-level hardware systems and higher-level DevOps tooling, we‚Äôd love to talk.

Key Responsibilities

Hardware & Infrastructure Management


Manage and maintain enterprise-grade server hardware and infrastructure components.
Utilize out-of-band management systems (iLO, iDRAC, IPMI, Redfish, etc.) for remote operations.
Use automated hardware management tools (BMC/Redfish-based) to streamline provisioning and maintenance.
Perform hardware diagnostics and troubleshooting (CPU, memory, disks, PSUs, NICs, etc.).
Handle vendor interactions, including RMAs, part replacements, and inventory tracking.
Oversee datacenter hardware operations, including racking, cabling, PDU installation, and physical layout.


Datacenter & DCIM


Use Data Center Infrastructure Management (DCIM) tools for inventory, capacity planning, and environmental tracking.
Manage power delivery and consumption across racks and nodes.
Configure and monitor managed PDU systems for power cycling, monitoring, and alerts.
Collaborate with colocation providers on connectivity, power, security, and maintenance tasks.


Monitoring & Observability


Build and maintain infrastructure monitoring and alerting using tools such as Prometheus/Grafana, SNMP, Nagios, CheckMK, or similar platforms.
Implement automated alerting for hardware health, network status, power issues, and service-level metrics.
Create dashboards to give internal teams visibility into system performance and reliability.


Network Operations


Manage and configure firewalls, routing, and network segmentation.
Configure and troubleshoot VPN technologies (IPsec, OpenVPN, WireGuard).
Oversee subnetting, IP address allocation, and network architecture planning.
Configure managed switches, VLANs, port settings, and trunking.
Manage NAT, port forwarding, and related gateway/edge network configurations.


System Administration (Linux)


Install, configure, and manage Linux servers (Ubuntu/Debian preferred).
Perform system-level troubleshooting (boot issues, login problems, service failures).
Manage networking configuration (static IPs, DHCP).
Configure and maintain filesystems: partitioning, MD RAID, ext4/XFS, LVM, resizing/growing volumes.
Implement secure access using public key authentication and proper SSH hardening.
Manage certificates for internal systems, including issuance, revocation, HTTPS installation, and rotation.
Handle basic BIOS configuration relevant to bare metal provisioning or system bring-up.


Bare Metal Provisioning


Deploy and manage hardware provisioning tools such as MAAS, Foreman, or similar systems.
Configure and troubleshoot network boot mechanisms (PXE, UEFI Boot, HTTP Boot).
Automate provisioning pipelines to rapidly bring new nodes online.


Containerization & Orchestration


Work with Kubernetes clusters at a foundational level (cluster access, basic resource troubleshooting).
Deploy workloads using Helm charts and maintain cluster application lifecycle.
Assist with cluster scaling, node replacements, and security hardening.


Automation & Scripting


Write shell scripts (bash) for automation of system tasks, monitoring, or provisioning.
Use CLI tooling such as jq, sed, awk, grep, and rsync.
Optionally automate workflows using languages like Python, Go, PHP, or Perl.


Required Qualifications


Proven experience managing enterprise-grade hardware at scale.
Strong understanding of out-of-band management systems (IPMI/BMC/Redfish).
Hands-on expertise with monitoring systems (Prometheus, Grafana, SNMP, Nagios, CheckMK, or similar).
Solid knowledge of network administration, including firewalls, routing, VPNs, NAT, and managed switches.
Linux system administration experience (installation, configuration, troubleshooting).
Experience with filesystems, RAID, partitioning, and general storage management.
Familiarity with certificate management, key-based auth, and basic cryptographic functions.
Experience with bare metal provisioning (MAAS, Foreman, or similar).
Understanding of PXE/UEFI/HTTP boot systems.
Ability to write functional, maintainable bash scripts for automation.


Nice to Have


Experience with Kubernetes beyond the basics (operators, cluster scaling, CRDs).
Experience with Helm chart customization.
Familiarity with automation languages such as Python, Go, PHP, or Perl.
Previous datacenter operations or colocation management experience.
Exposure to high-availability or distributed compute environments.
Knowledge of infrastructure security and hardening practices.


What We Bring


Stock Options
100% paid Medical, Dental, and Vision insurance
Life and Voluntary Supplemental Insurance
Short Term Disability Insurance
Flexible Spending Account
401(k)
Flexible PTO
Paid Holidays
Parental Leave
Mental Health Benefits through Spring Health"
"DevOps Administrator","The Amatriot Group","Dallas, TX","https://www.linkedin.com/jobs/view/devops-administrator-at-the-amatriot-group-4310974393?position=22&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=rfpXoHTMNKHeWpuG18qkvA%3D%3D","DevOps Administrator

Salary: $135,000 ‚Äì 170,000

Contract Length: 12-month SOW

Location: Dallas, TX - in-office presence requirement 3 days weekly or more as needed


This represents the potential salary range for this position depending on education level, years of experience and/or certifications in addition to other position specific requirements which may impact salary


We‚Äôre seeking an experienced Administrator to join our Code Management team. The right candidate for this role will lead and execute strategic migrations, optimize CI/CD workflows, and drive infrastructure modernization. They will be critical in moving our automation ecosystem from legacy tools (Jenkins, Bitbucket, Automic) to GitLab, Ansible Automation Platform and Terraform, ensuring robust, scalable, and secure pipelines.

Required Skills And Experience


8+ years of experience in Administering different & complex applications and tools used in the Enterprise
Experience administering GitLab, Artifactory, Xray, & SonarQube
Experience with infrastructure-as-code tools (Terraform, Ansible, etc.)
Solid understanding of containerization (Docker) and orchestration (Kubernetes)
Familiarity with cloud platforms (AWS, Azure, IBM Cloud) and cloud-native tooling
Strong communication skills and a track record of cross-team collaboration
Knowledge of JFrog Artifactory, BitBucket / GIT, SVN and other SCM tools
Working knowledge of different Software Development Lifecycle Methodologies
Knowledge of desired state configuration, automated deployment, continuous integration, and release engineering tools like Puppet, Chef, Jenkins, Bamboo, Maven, Ant etc
Configure and manage GitLab Runners, Groups, Projects, and Permissions at scale
Harden GitLab for enterprise usage (SAML/SSO, LDAP, RBAC, backup/restore)
Design, implement, and optimize complex GitLab CI/CD pipelines using YAML best practices
Leverage Terraform, Ansible, or similar to provision and manage self-hosted GitLab and runners
Implement GitOps practices to manage infrastructure and environment configurations
Automate operational tasks and incident remediation via pipelines and scripts
Partner with application teams to onboard them onto GitLab workflows and best practices
Develop and maintain clear runbooks, wiki pages, and pipeline templates
Integrate monitoring (Prometheus/Grafana, ELK) for GitLab health and pipeline performance
Implement policies and guardrails to ensure code quality, compliance, and security posture
Troubleshoot and resolve CI/CD or migration-related incidents in a timely manner
Available for 24/7 On-call support


Preferred


A BS in Computer Science or equivalent work experience with good scripting/programming skills
GitLab Certified Administrator
Prior software experience with build management, configuration management and/or quality testing
Experience with SCM practices including Agile, continuous integration (CI) and continuous deployment (CD)


Team Culture

Our team is fast paced, fun, highly energetic, motivated and hardworking. We expect our candidates to be integrated into our results-driven and solution-oriented culture from the get-go. Our team attains high-quality results on challenging projects; the belief that outcomes are linked to one's effort rather than chance and the tendency to personally set challenging yet realistic goals."
"DevOps Engineer","Arize AI","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-arize-ai-4332964631?position=23&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=MEAUmMh5h3aGjrOZluMQSg%3D%3D","About Arize

AI is rapidly transforming the world. As generative AI reshapes industries, teams need powerful ways to monitor, troubleshoot, and optimize their AI systems. That‚Äôs where we come in. Arize AI is the leading AI & Agent Engineering observability and evaluation platform, empowering AI engineers to ship high-performing, reliable agents and applications. From first prototype to production scale, Arize AX unifies build, test, and run in a single workspace‚Äîso teams can ship faster with confidence.

We‚Äôre a Series C company backed by top-tier investors, with over $135M in funding and a rapidly growing customer base of 150+ leading enterprises and Fortune 500 companies. Customers like Booking.com, Uber, Siemens, and PepsiCo leverage Arize to deliver AI that works.

The Team

Our On-Prem engineering team is responsible for the deployment of Arize in customer environments. In addition to working with customers in defining infrastructure requirements, the team designs and develops software and tooling that enables the management of these systems at large scale. The On-Prem team has grown to be expert in Kubernetes and cloud deployment on GCP, Azure, and AWS as well as dealing with networking and security aspects of on-premise deployments. The team is dynamic and relies on few talented individuals with a high degree of autonomy and initiative.

What You‚Äôll Do


Work hands-on with the infrastructure that supports our distributed & highly scalable services in both SaaS and on-prem offerings
Gather requirements from customers and adapt manifests and software to support new environments
Use and augment monitoring tools to observe platform health, ensure performance and reliability
Interact with the product team to test new features and package new on-prem releases
Automate and optimize the release pipeline to make it as frictionless as possible
Exhibit continuous curiosity for emerging technology that could solve our challenges


What will set you apart:


3+ years of experience as a DevOps Engineer, Cloud Engineer, Infrastructure Engineer or similar
Excellent communication skills and ability to work directly with customers to understand and address their infrastructure needs
Experience and fluency in Kubernetes
A self starter with an ability to thrived in a fast paced environment
Experience working with multiple cloud providers (AWS, GCP, Azure) and understanding how to adapt cloud-native architectures for on-premises environments
Strong troubleshooting skills


The estimated annual salary for this role is between $100,000 - $185,000, plus a competitive equity package. Actual compensation is determined based upon a variety of job related factors that may include: transferable work experience, skill sets, and qualifications. Total compensation also includes a comprehensive benefit package, including: medical, dental, vision, 401(k) plan, unlimited paid time off, generous parental leave plan, and others for mental and wellness support.

While we are a remote-first company, we have opened offices in New York City and the San Francisco Bay Area, as an option for those in those cities who wish to work in-person. For all other employees, there is a WFH monthly stipend to pay for co-working spaces.

More About Arize

Arize‚Äôs mission is to make the world‚Äôs AI work‚Äîand work for people.

Our founders came together through a shared frustration: while investments in AI are growing rapidly across every industry, organizations face a critical challenge‚Äîunderstanding whether AI is performing and how to improve it at scale.

Learn more about what we're doing here:

https://techcrunch.com/2025/02/20/arize-ai-hopes-it-has-first-mover-advantage-in-ai-observability/

https://arize.com/blog/arize-ai-raises-70m-series-c-to-build-the-gold-standard-for-ai-evaluation-observability/

Diversity & Inclusion @ Arize

Our company's mission is to make AI work and make AI work for the people, we hope to make an impact in bias industry-wide and that's a big motivator for people who work here. We actively hope that individuals contribute to a good culture


Regularly have chats with industry experts, researchers, and ethicists across the ecosystem to advance the use of responsible AI
Culturally conscious events such as LGBTQ trivia during pride month
We have an active Lady Arizers subgroup"
"DevOps Engineer","Sustainment","Austin, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-sustainment-4335637240?position=24&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=CBylbeFN0DaQFSQqw1fcvw%3D%3D","Company Overview: Sustainment is an AI-native software platform that helps US-based manufacturers easily find and work with the critical suppliers they need to build and manage their supply chains. Our vision is to reimagine American manufacturing as a hyperconnected, secure, and resilient ecosystem of local and regional suppliers who can more easily connect, interact, and do business with the industry and government customers that rely on them. We are a dual-use technology platform that supports both DoD and commercial customers in pursuit of our vision.

Job Overview: We are looking for a DevOps/MLOps Engineer to drive the reliability, scalability, and performance of our AI-native procurement platform. The primary focus of the role is to build and maintain robust infrastructure, automate ML model deployment pipelines, and ensure database performance and reliability. You will be responsible for high-quality, secure deliverables that meet stringent compliance requirements (SOC 2, FedRAMP, CMMC Level 2) and for helping to create, evangelize, and enforce the standards necessary to meet team and company goals for operational excellence and mission-critical uptime.

Responsibilities:


Build partnerships and work collaboratively with engineering, AI, and product teams to meet shared objectives
Operate effectively in ambiguous situations, especially when scaling AI workloads and managing complex infrastructure transitions
Build and optimize DevOps pipelines including ML model training, versioning, deployment, monitoring, and retraining workflows
Administer and optimize PostgreSQL databases including performance tuning, query optimization, backup/recovery, and high availability configurations
Troubleshoot and resolve infrastructure, database, and pipeline issues in a resilient, performant manner
Implement and maintain infrastructure as code using tools like Terraform or Cloudformation
Monitor system health, performance, and database metrics using observability tools and respond to alerts proactively
Ensure security best practices and compliance requirements are met across all infrastructure and database layers
Participate in multi-resource projects in an agile environment
Evaluate and recommend industry standards, tools, and methods for DevOps, MLOps, and database management
Document infrastructure architecture, runbooks, and contribute to architecture reviews


Qualifications:


Bachelor's degree (computer science, engineering, or related) or equivalent work experience
2+ years of experience with cloud infrastructure (AWS preferred), container orchestration (Kubernetes), and CI/CD tools
2+ years of database administration experience with PostgreSQL or similar relational databases
Experience with ML model deployment, monitoring, and lifecycle management (MLOps)
Strong understanding of infrastructure as code (Terraform), GitOps practices, and declarative configuration management
Experience with security compliance frameworks (SOC 2, FedRAMP, or CMMC is a plus)
Product-driven mindset with deep empathy for internal developer experience and system reliability
Strong desire to work in a startup with interest to take on projects from zero to one with collaboration with the rest of the team
Love working hard and enjoy a fast-paced, ambiguous environment
Experience with distributed systems, microservices architecture, and reactive systems
Open mindset to exploring new tools and frameworks in the rapidly evolving DevOps/MLOps landscape
Passion for operational excellence and automation
Experience supporting cross-team efforts to roll out new infrastructure capabilities or ML features
Passion for learning and continuous improvement
Strong written and verbal communication skills, and ability to explain complex technical concepts
Experience working in a Scrum/agile environment
Experience with AWS GovCloud, defense/government sector compliance, or working in an early startup environment on SaaS products is a plus


Core Technologies:


AWS (including GovCloud), Kubernetes, Docker, Terraform
PostgreSQL
GitLab CI/CD, ArgoCD, Tilt
Model versioning, experiment tracking, ML pipeline orchestration
Datadog, CloudWatch
Python, Bash, experience with .NET ecosystem a plus
IAM, secrets management, encryption, audit logging, compliance automation


Sustainment offers a competitive benefits package for full time employees including medical, dental, vision, paid time off, company holidays, and 401K matching.

Sustainment is proud to be an equal opportunity employer. We provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, veteran status, or any other protected class.

Applicants must be authorized to work for ANY employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time.

Sustainment participates in E-Verify."
"Devops","The Dignify Solutions, LLC","Phoenix, AZ","https://www.linkedin.com/jobs/view/devops-at-the-dignify-solutions-llc-4347025595?position=25&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=jM%2FGCdo9AbcNJ%2F2rOHVVbg%3D%3D","Must have is


Associate should be in Phoenix from day 1 of the project
At least 5 years of experience in Devops area.
Strong skill in CI/CD pipeline, Jenkins, Github
Additional knowledge on any build related tools is an added advantage.


Java 8 knowledge

Docker

Kaffka

Kibana"
"DevOps Engineer I","Trustwell","Portland, OR","https://www.linkedin.com/jobs/view/devops-engineer-i-at-trustwell-4321600458?position=26&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=D%2B0L3krDtsL0ibglUbtdxw%3D%3D","Role{{:}} DevOps Engineer I

FLSA{{:}} Full Time | Exempt | Salaried | Remote

Reports to{{:}} Director of DevOps

Note{{:}} Candidate preferred to reside in PST. If not, candidate will be required to support PST working hours.

Trustwell is looking for ambitious, energetic problem-solvers who enjoy a fast-paced team environment filled with challenges and career growth opportunities in a rapidly growing tech firm. Trustwell is on a mission to change the food industry. Combining FoodLogiQ's supply chain management software with Genesis' nutritional analysis and label development solution, the Trustwell Connect platform creates the food industry's only full-scale solution connecting product development and regulatory-compliant labeling with supplier compliance, enhanced traceability, and automated recall management. From food and supplement manufacturers to retail grocers and restaurant chains, more than 2,500 food companies around the world use Trustwell software as their trusted source for compliance and quality solutions in the food industry. For more information, visit www.trustwell.com.

Scope of Position{{:}} The DevOps Engineer I will be part of a dynamic and agile team responsible for building and maintaining the platforms, systems, and services that power our customer-facing products. Working closely with Software Engineers and Engineering Leadership, you'll help shape architecture, implement best practices, and stay ahead of the curve in DevOps principles. You'll champion operational excellence and continuous improvement across the team.

Essential Duties & Responsibilities include but not limited to{{:}}


Contribute actively to an Agile delivery team, ensuring consistent, high-quality, and reliable software releases.
Collaborate closely with developers and cross-functional partners to design, build, and deploy best-in-class, scalable software solutions.
Champion an automation-first, code-centric mindset, driving efficiency and consistency across deployment, monitoring, and maintenance processes.
Support production operations through participation in incident response, troubleshooting, and on-call rotations to maintain system reliability and uptime.
Develop, implement, and maintain monitoring and alerting tools to ensure optimal application performance, health, and availability.
Design infrastructure and deployment solutions with scalability, resilience, and long-term maintainability as core principles‚Äîavoiding short-term workarounds.
Proactively identify and eliminate operational bottlenecks and unnecessary complexity, contributing to continuous improvement initiatives.
Engage in architectural reviews and solution design discussions, providing input that enhances performance, reliability, and security.
Perform other related duties as assigned, contributing to the overall success of the DevOps function and technology organization.


Education/Experience{{:}}


Bachelor's degree in Computer Science, Engineering, or a related field required. Will consider relevant experience/certifications in lieu of degree.
2+ years of experience in an SRE (Site Reliability Engineer) or equivalent engineering role
2+ years of experience as a DevOps Engineer or in a similar capacity
3+ years of hands-on experience managing and supporting production cloud environments (AWS, Azure, or GCP)
Extensive experience with DataDog, including APM, RUM, Synthetic Monitoring, Infrastructure Monitoring, and Dashboard development


Required Skills/Abilities{{:}}


Strong, hands-on experience with Infrastructure-as-Code (IaC) and configuration management tools such as Terraform, CloudFormation, and/or Ansible
Proven experience designing and managing cloud architectures in AWS and Microsoft Azure, with expertise in containerization and orchestration (Docker, Kubernetes, etc.)
Demonstrated experience building, maintaining, and optimizing CI/CD pipelines using tools such as CircleCI, TeamCity, GitHub Actions, or Jenkins
Background in delivering infrastructure initiatives within an Agile development environment
Collaborative mindset with the ability to partner effectively across cross-functional teams to achieve shared goals
Strong ""automation-first"" mindset with a focus on scalability, reliability, and efficiency


Total Rewards Package{{:}}


Full healthcare benefits, including medical, dental, and vision.
Supplemental benefits, including STD, LTD, HSA, 401k, etc.
Responsible Time Off (PTO) + Holiday Pay
Excellent culture, growth opportunities, plus much more...


What to expect - the Hiring Process!


Interview with Human Resources
Interview with Hiring Manager
Peer Panel Interview(s)
Offer of Employment (Background Screening/References)


Hiring Eligibility{{:}} This is a fully remote position open to candidates located anywhere within the United States. Eligibility to work remotely is subject to company policy and applicable state laws. Candidates must have work authorization to work for any U.S. based employer. Please note that certain benefits, taxes, or employment terms may vary by state.

Compensation{{:}} The compensation for this position starts at $80,000 per annum, with the potential for higher placement based on a candidate's experience, education, and overall qualifications. In addition to base salary, this role is bonus eligible‚Äîup to 10% annually, contingent on company performance and achievement of organizational objectives.

Trustwell is an equal employment opportunity employer committed to hiring and retaining a diverse workforce. Applicants receive fair and impartial consideration without regard to race, sex, sexual orientation, gender identity, color, religion, national origin, age, disability, veteran status, religion, or other legally protected class. If you need accommodation for any part of the employment process due to a medical condition, or any disability, please contact a member of our human resources team.

Acceptable Background and References Required; Upon any conditional offers made by Trustwell.

Equal Opportunity Employer/ DFWP/ Affirmative Action"
"DevOps Engineer","OVA.Work","Alpharetta, GA","https://www.linkedin.com/jobs/view/devops-engineer-at-ova-work-4338475165?position=27&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=4JmDyUsuEYdJArzBGOVeTA%3D%3D","Job Title: DevOps Engineer

Location: Remote

Employment Type: Full-Time

Job Summary

We are looking for a skilled DevOps Engineer to join our technology team. The ideal candidate will design, implement, and manage CI/CD pipelines, automate infrastructure, and ensure smooth deployment processes across development and production environments. This role requires strong knowledge of cloud platforms, containerization, and scripting.

Key Responsibilities


Design, build, and maintain CI/CD pipelines for application deployment.
Automate infrastructure provisioning using tools like Terraform or Ansible.
Manage containerized environments using Docker and Kubernetes.
Monitor system performance and implement proactive solutions for scalability and reliability.
Collaborate with development and operations teams to streamline workflows.
Ensure security and compliance in cloud and on-prem environments.
Troubleshoot and resolve issues in production and staging environments.


Qualifications


Bachelor's degree in Computer Science, Engineering, or related field.
25 years of experience in DevOps or related roles.
Proficiency in cloud platforms (AWS, Azure, GCP).
Hands-on experience with CI/CD tools (Jenkins, GitLab CI, GitHub Actions).
Strong knowledge of containerization (Docker, Kubernetes).
Familiarity with Infrastructure as Code (Terraform, Ansible).
Scripting skills in Python, Bash, or similar languages.


Preferred Skills


Experience with monitoring tools (Prometheus, Grafana).
Knowledge of security best practices in DevOps.
Familiarity with microservices architecture.


Benefits


Competitive salary and performance bonuses.
Health insurance and retirement plans.
Flexible work options and professional development opportunities."
"DevOps Engineer (JIRA)","Rubix Solutions","Washington, DC","https://www.linkedin.com/jobs/view/devops-engineer-jira-at-rubix-solutions-4335995983?position=28&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=Hty9ucbFu%2BW2%2BArnksc9EQ%3D%3D","The DevOps Engineer (specifically Jira Platform Engineer) will serve as the technical owner of our Jira SaaS in government cloud, and is responsible for administering, configuring, and integrating the application within our enterprise technology ecosystem. This position plays a pivotal role in consolidating our collaborative planning tools‚Äîtransitioning from Azure DevOps (on-prem) and GitLab (on-prem) to Jira‚Äîwhile enabling and scaling Agile practices across the organization.

The ideal candidate is both technically proficient and strategically minded, with a strong understanding of Agile methodologies, DevSecOps workflows, and enterprise system

integration.

Responsibilities


Administer, configure, and optimize Jira SaaS to meet enterprise project management and Agile delivery needs.
Design and maintain custom workflows, issue types, screens, fields, and automation rules aligned with organizational Agile frameworks and guidelines.
Manage user permissions, group roles, and security schemes to ensure governance and compliance.
Monitor Jira license utilization, user growth, and application usage to ensure efficient use of subscriptions.
Collaborate with procurement teams to support renewal, optimization, and budget decisions.
Design, implement, and maintain seamless integrations between Jira with other enterprise systems, such as GitLab (source control & CI/CD), and ServiceNow (ITSM), using Okta,REST APIs, webhooks, middleware, and scripting.
Automate data synchronization across platforms to support traceability from planning to release.
Troubleshoot and optimize integration pipelines to ensure performance, security, and Scalability.
Partner with infrastructure and cybersecurity teams to align integrations with enterprise security and compliance standards.
Develop and maintain technical documentation, standards, and best practices.
Partner with the Agile Transformation Office to translate Agile practices into effective Jira configurations and usage patterns.
Provide technical guidance and mentoring to Scrum Masters, Product Owners, and teams on best-practice tool utilization.
Support reporting and analytics initiatives, ensuring reliable Agile metrics (velocity, burndown, cycle time, etc.).


Requirements


Must be able to obtain and maintain Moderate Risk Public Trust (MRPT) facility credentials/authorization. Note: US Citizenship is required for MRPT facility credentials/authorization at this work location.
Bachelor‚Äôs degree in Computer Science, Information Systems, or a related field (or equivalent experience).
3+ years of hands-on experience administering and/or engineering Jira (Self-hosting or SaaS).
Proven, hands-on experience developing custom integrations with enterprise platforms, especially GitLab and ServiceNow.
Proficiency in scripting (Python, PowerShell, or JavaScript) and REST API integration.
Strong understanding of Agile methodologies (Scrum, Kanban, SAFe) and DevSecOps principles.
Experience in enterprise migrations from Azure DevOps or similar tools to Jira.
Familiarity with Atlassian ecosystem (Confluence, Bitbucket) and marketplace apps.
Experience working in a DevSecOps or Platform Engineering environment.
Experience with information security, privacy, and risk assessment standards including FISMA, SOX, FedRAMP, etc. is preferred.
Federal government experience is preferred.
Atlassian Certified Professional (ACP-620, ACP-120, or equivalent) preferred."
"DevOps Engineer","Chartmetric","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-chartmetric-4291046434?position=29&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=my010xvqUkDpG30wys1Mow%3D%3D","About Chartmetric

Chartmetric, Inc. is a 10-year-old startup specializing in music data analytics. We are trusted by Universal MusicGroup, Sony, Warner, and Apple Music, as well as hundreds of other music companies and industry professionals. Our team has created a self-service data dashboard for the music industry to better understand the activity happening around artists. Together, we combine hundreds of thousands of real-time data points across iTunes, Spotify, YouTube, Google, Amazon, X, and others through our beautifully designed tool in order to make sense of the increasingly complex landscape of the music industry.

About The Role


We are seeking a talented DevOps / Developer Experience Engineer to join our team and play a pivotal role in enhancing our development infrastructure and streamlining the developer workflow. This position combines traditional DevOps responsibilities with a focus on creating exceptional developer experiences through tooling, automation, and process optimization.


What You'll Do


Infrastructure & Operations
Design, implement, and maintain scalable cloud infrastructure using Infrastructure as Code (IaC) principles
Manage CI/CD pipelines and deployment processes across multiple environments
Monitor system performance, reliability, and security, implementing proactive solutions
Automate operational tasks and eliminate manual toil through scripting and tooling
Ensure high availability and disaster recovery capabilities


Developer Experience
Build and maintain internal developer tools and platforms that improve productivity
Streamline onboarding processes for new developers and reduce time-to-first-commit
Design and implement developer-friendly APIs, SDKs, and documentation
Create self-service capabilities that reduce dependencies and waiting times
Gather feedback from development teams and iterate on tooling based on pain points


Collaboration & Process Improvement
Work closely with engineering teams to understand workflow challenges and requirements
Champion best practices for code deployment, testing, and monitoring
Lead initiatives to improve development velocity and reduce friction
Participate in incident response and post-mortem analysis
Mentor team members on DevOps practices and tooling

What We're Looking For


Technical Skills
3+ years of experience in DevOps, SRE, or Platform Engineering roles
Strong proficiency with cloud platforms (AWS, GCP, or Azure)
Experience with Infrastructure as Code tools (Terraform, CloudFormation, or Pulumi)
Hands-on experience with containerization (Docker) and orchestration (Kubernetes)
Proficiency in CI/CD tools (Jenkins, GitLab CI, GitHub Actions, or similar)
Strong scripting skills in Python, Bash, or Go
Experience with monitoring and observability tools (Prometheus, Grafana, ELK stack, or similar)


Developer Experience Focus
Experience building internal tools and platforms for development teams
Understanding of software development lifecycle and common developer pain points
Familiarity with API design and developer-facing documentation
Experience with version control systems and Git workflows
Knowledge of testing frameworks and quality assurance processes


Soft Skills
Strong problem-solving abilities and analytical thinking
Excellent communication skills and ability to work with cross-functional teams
Customer-focused mindset with emphasis on developer productivity
Proactive approach to identifying and resolving issues
Ability to balance technical debt with feature delivery


Preferred Qualifications
Knowledge of security best practices and compliance frameworks
Background in software development or engineering
Familiarity with cost optimization strategies for cloud infrastructure
Previous experience in a high-growth or scaling environment

What We Offer


Competitive salary and equity package
Comprehensive health, dental, and vision insurance
Opportunity to shape developer experience across the organization
Access to cutting-edge tools and technologies


Team Culture


We believe that great developer experiences lead to better products and happier teams. Our DevOps/DX team operates as enablers and force multipliers, working collaboratively to remove friction from the development process. We value automation, measurement, and continuous improvement, always asking ""how can we make this better for our developers?""


The Pay Range For This Role Is

135,000 - 165,000 USD per year(San Mateo)

120,000 - 150,000 USD per year(New York)"
"DevOps Engineer","Broad Reach Partners","Alpharetta, GA","https://www.linkedin.com/jobs/view/devops-engineer-at-broad-reach-partners-4303987210?position=30&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=uTp8%2B9FtKMx0r8DAwjC6AQ%3D%3D","We are seeking a Senior DevOps Engineer to join our team and play a critical role in designing, building, and optimizing the CI/CD pipelines that power our software delivery across on-prem and cloud environments.

In this role, you will work hand-in-hand with our development, operations, and security teams worldwide to implement best practices, automate deployments, and ensure our platforms are reliable, secure, and scalable. If you thrive on solving complex technical challenges, have a passion for automation, and want to influence how enterprise platforms evolve and modernize, this is an ideal opportunity for you.

As a Senior DevOps Engineer, your expertise will drive the continuous integration, delivery, and deployment (CI/CD) pipelines delivering software to both on-prem and cloud (AWS primarily) environments. You will work closely with our development, operations, and security teams distributed across the globe. This role requires a deep understanding of DevSecOps best practices and a strong ability to troubleshoot complex issues.

Your Responsibilities In This Role Will Include


Design, Develop and Maintain automated build and deployment pipelines using GitLab/GitHub/Jenkins to enhance software delivery.
Identify opportunities for automation and ensure continuous security, quality in application development by automating security checks, test executions in build and deployment pipelines.
Deploy and manage Kubernetes workloads to AWS EKS(A) using Helm, ArgoCD
Collaborate with development, operations and security team to build secure, optimized and efficient pipelines.
Create comprehensive documentation on pipeline functionality and provide training to required members.
Proactively monitor system performance and identify potential issues before they become critical.
Participate in on-call rotation.
Engage in continuous learning and actively advocate for Dev(Sec)Ops, GitOps best practices and standards across the team.


We are looking for you to have the following skills and experience:


8+ years of experience as a DevOps Engineer, Site Reliability Engineer, or equivalent
Strong knowledge of DevOps practices, continuous integration, continuous delivery, and related tools.
3+ years of experience with Amazon Web Services (AWS) or Microsoft Azure
3+ years of experience with Kubernetes clusters
Proficiency with public cloud environments (AWS preferred)
Experience with tools like New Relic and Graylog
Advanced proficiency working with CI/CD pipelines such as GitHub Actions/GitLab/Jenkins
Expert in containerization technologies such as Docker and orchestration tools like Kubernetes.
Proficiency in scripting language, like Bash, Groovy, Python
Excellent debugging and troubleshooting skills.
Ability to prioritize tasks efficiently and independently under minimal supervision.


Nice to Have


AWS Cloud certification
Familiar with .NET applications.
Knowledge in Terraform, Ansible, monitoring tools


We are located in the Alpharetta/Cumming area of Atlanta and are working in the office several days each week so YOU MUST LIVE WITHIN COMMUTING DISTANCE OF ALPHARETTA, GA to be considered for this role. We cannot sponsor at this time.

If this opportunity is a good match for your skills, experience and interest, please apply now so we can follow up with you with more details."
"AWS DevOps Specialist","Focus School Software","St. Petersburg, FL","https://www.linkedin.com/jobs/view/aws-devops-specialist-at-focus-school-software-4333597594?position=31&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=8d1zYP%2FdPBLOcWlVWgcpKQ%3D%3D","Focus School Software is a fast-growing school management software company. We thrive on creating some of the most innovative features on the market today, helping educators to meet their evolving needs in classrooms, district management, state reporting compliance, and other facets of student-centered education and technology.

We are seeking an experienced and proactive AWS DevOps Specialist to join our growing infrastructure team. This role is ideal for someone passionate about automation, cloud infrastructure, and scalable, secure systems. The ideal candidate brings expertise in AWS services, infrastructure as code, cost reduction strategies and DevOps best practices. You will play a key role in improving system performance, reliability, and security, while contributing to CI/CD pipelines and participating in an on-call rotation. This is a great opportunity for anyone who has a multitude of skills in DevOps and System Administration and can wear many hats and loves problem solving.

Key Responsibilities


Automation & Configuration Management
Design, develop, and maintain automation using Ansible and Ansible Tower.
Deploy and configure RHEL based systems.
Database maintenance and performance, routing, pooling and role management.


Cloud Infrastructure (AWS)


Architect and manage services including RDS (PostgreSQL), EC2, EKS, CloudFormation, CloudFront, GuardDuty, AWS VPN, AWS AD, and more.
Implement Autoscaling strategies and container orchestration with EC2 Autoscaling or EKS. Continuously monitor performance and feedback on systems.
Monitor and improve database performance, sharding strategies, and health metrics.
Monitor backups and maintain recovery point objectives for disaster recovery.


Security & Compliance


Support SOC II compliance initiatives through infrastructure hardening, monitoring, and alerting.
Leverage AWS security tools and best practices to ensure compliance and threat mitigation.


Networking & Connectivity


Manage VPCs, subnets, security groups, VPNs, and endpoint connectivity for both internal and external integrations.
Managing routes, DNS and VPN connectivity. Help internal users maintain their VPN connections.
Cost Optimization
Analyze AWS billing, usage reports, and recommend cost-saving strategies.


DevOps & CI/CD


Build and maintain CI/CD pipelines, enabling delivery of automation code from development to production.
Ensure high availability and zero-downtime deployments through automation and best practices.
Develop and maintain local dev environments for developers.


Collaboration & Culture


Work cooperatively in cross-functional teams, embracing a culture where the best ideas win.
Proactively identify infrastructure problems and lead with creative, scalable solutions.


Endpoint & Systems Management


Oversee and manage end-user systems and infrastructure endpoints to maintain security and stability.
Patch management and remediation, ensure established timelines and policies are followed.


On-Call Participation


Participate in an on-call rotation to respond to production incidents and infrastructure issues.


Requirements


Ansible, Ansible Tower, working in RHEL based environments.
Linux/RHEL expert, be able to design, deploy and fix everything from a systemd service to managing SFTP.
Ability to manage a Git repository, and perform peer review on automation code.
Monitoring tools such as Splunk, Grafana or similar.
Working knowledge of NGINX, basic webserver stacks.
Understanding of AWS, particularly RDS (PostgreSQL), CloudFormation, EC2, EKS
Kubernetes and containerization
Experience with database sharding and performance tuning
CI/CD pipeline design and implementation
Familiarity with SOC II compliance frameworks
Experience managing AWS networking, VPNs, and AWS AD
Security-first mindset with experience using AWS Org, AWS Tower, CloudFront, and related tools to ensure compliance.
Strong interpersonal skills with a collaborative mindset.


Nice-to-Have


LAMP/LNPP Stack experience
SVN Familiarity
Active Directory experience, basic Windows management
Experience with endpoint management platforms
Background in proactive monitoring/observability tooling
Prior involvement in security audits or compliance initiatives


Focus School Software‚Äôs compensation package offers the following benefits:


Medical Insurance
Dental/Vision Insurance
Life Insurance
Short and Long Term Disability Insurance
401(k) after 6 months
Paid Holidays
Paid Vacation and Sick Time
Remote Position"
"DevOps Engineer","Rain","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-rain-4318510257?position=32&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=i3yFe70EGV3wFWMnYunqEQ%3D%3D","Rain is empowering the next generation of money and financial products globally. We‚Äôre a lean and mighty team of passionate builders and veteran founders. We are looking for a DevOps engineer to join us in building a cutting edge platform at the intersection of real-world payments and digital money. You will have the opportunity to deliver massive impact at a small and quickly growing company that is funded by some of the top investors in fintech and crypto. Rain is backed by great investors including Lightspeed, Norwest, Khosla, along with great companies like Coinbase, Circle, and Uniswap.

Many of our engineers are based in NYC but we are open to fully remote candidates.

Our Ethos

We believe in an open and flat structure. You will be able to grow into the role that most aligns with your goals. Our team members at all levels have the freedom to explore ideas and impact the roadmap and vision of our company.

What You'll Do


Be a critical part of the technical infrastructure roadmap
Manage our cloud environments across GCP and AWS
Scale our infrastructure to millions of end users globally
Help drive the architectural decisions of a rapidly evolving product
Lead the creation and maintenance of our CI/CD pipelines to enable rapid, reliable deployments
Collaborate with the engineering team to improve infrastructure performance
Build infrastructure to interact with millions of smart contracts across dozens of blockchains
Automate security controls and compliance processes to protect sensitive financial data


What We're Looking For


Strong experience with Infrastructure as Code, particularly Terraform, for managing cloud resources at scale
Proven track record designing and implementing CI/CD pipelines and automation workflows
Experience managing production environments in cloud providers
Experience with monitoring, logging, and observability tools


Nice to haves, but not mandatory


Experience in fintech (neobank or card issuing experience gets extra brownie points)
Experience with blockchain infrastructure


Our perks enable working at Rain to be a fulfilling, healthy and happy experience.

Unlimited time off üõº Unlimited vacation can be daunting, so at Rain we require our teammates to take 10 days minimum for themselves.

Flexible working ‚òï We support a flexible workplace, if you feel comfortable at home please work from home. If you‚Äôd like to work with others in an office feel free to come in. We want everyone to be able to work in the environment in which they are their most confident and productive selves.

Flexible Benefits üß† Easy-to-access benefits, for all employees based in the US, Rain pays a percentage of your benefits for the employee and for your dependents. We offer comprehensive health, dental and vision plans as well as a 100% company-subsidized life insurance plan.

Equity plan üì¶ On top of a competitive salary, we offer every Rain employee an equity option plan so we can all can benefit from our success.

Rain Cards üåßÔ∏è We want our teammates to be knowledgeable about our core products and services and to support this mission we issue a card for our team to utilize the card for testing.

Health and Wellness üìö High performance begins from within. Our members are welcome to use their company card for eligible health and wellness spending like gym memberships, fitness classes and other wellness items.

Team summits ‚ú® Summits play an important role at Rain! Time spent together helps us get to know each other, strengthen our relationships, and build a common destiny. Stay tuned for upcoming destinations!"
"DevOps Engineer","Jasper","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-jasper-4318500931?position=33&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=LEBaDqUoCvC6FxbgZXNAqA%3D%3D","Jasper is the leading AI marketing platform, enabling the world's most innovative companies to reimagine their end-to-end marketing workflows and drive higher ROI through increased brand consistency, efficiency, and personalization at scale.

Jasper has been recognized as ""one of the Top 15 Most Innovative AI Companies of 2024"" by Fast Company and is trusted by nearly 20% of the Fortune 500 ‚Äì including Prudential, Ulta Beauty, and Wayfair. Founded in 2021, Jasper is a remote-first organization with team members across the US, France, and Australia.

About The Role

We're looking for an experienced DevOps Engineer to join our Platform team. This is a highly autonomous, high-impact role that blends Ops practices, infrastructure engineering, and delivery pipeline optimization. You'll work with a focused, collaborative, and fast-moving team where your contributions will directly impact system reliability, developer velocity, and our ability to safely deliver AI-powered products at scale. Candidates should also have a solid background in Cloud, IaC, and Kubernetes, and a drive to produce excellent solutions for a variety of challenges.

This fully remote role reports to the Staff Dev Ops Engineer and is open to candidates located anywhere in the continental US.

What You‚Äôll Do


Design, implement, and operate cloud-native infrastructure that scales efficiently, fails gracefully, and optimizes for performance and cost.
Build and refine software delivery pipelines to enable safe, fast, and frequent deployments with robust testing, rollback, and progressive release mechanisms.
Develop infrastructure-as-code solutions using Terraform and Helm to create self-healing, automated, and observable systems.
Collaborate with ML and product teams to support AI model training and inference through scalable compute and storage infrastructure.
Identify and eliminate single points of failure, performance bottlenecks, and scalability limits through proactive monitoring and reliability engineering practices.
Implement and enforce security best practices, including secrets management, access control, and compliance across all infrastructure layers.


What You‚Äôll Bring


Deep experience running Kubernetes in production (cluster management, networking, storage, security).
Expertise with Terraform, Helm, and configuration management to build reproducible, version-controlled infrastructure.
Proven success designing and maintaining CI/CD pipelines (GitHub Actions, Argo CD, Jenkins, etc.) balancing speed and safety.
Strong background in observability (especially Datadog) ‚Äî skilled at instrumentation, dashboard creation, and intelligent alerting.
Solid scripting skills in Python, Go, or Bash, with a focus on automation and operational efficiency.
Practical knowledge of Google Cloud Platform and cloud-native architectures.
Experience supporting multi-language environments (TypeScript, Python, Go) and AI/ML workloads, including GPU-based compute.
Familiarity with container security, secrets management, and policy enforcement.
(Bonus) History of open source contributions in infrastructure, CI/CD, or observability projects.


Compensation Range

At Jasper, we believe in pay transparency and are committed to providing our employees and candidates with access to information about our compensation practices. The expected base salary range offered for this role is $170,000 - $200,000. Compensation may vary based on relevant experience, skills, competencies, and certifications.

Benefits & Perks


Comprehensive Health, Dental, and Vision coverage beginning on the first day for employees and their families
401(k) program with up to 2% company matching
Equity grant participation
Flexible PTO with a FlexExperience budget ($900 annually) to help you make the most of your time away from work
FlexWellness program ($1,800 annually) to help support your personal health goals
Generous budget for home office set up
$1,500 annual learning and development stipend
16 weeks of paid parental leave


Our goal is to be a diverse workforce that is representative at all job levels as we know the more inclusive we are, the better our product will be. We are committed to celebrating and supporting our differences and that diversity is essential to innovation and makes us better able to serve our customers. We hire people of all levels and backgrounds who are excited to learn and develop their skills.

We are an equal opportunity employer. Applicants will not be discriminated against because of race, color, creed, sex, sexual orientation, gender identity or expression, age, religion, national origin, citizenship status, disability, ancestry, marital status, veteran status, medical condition, or any protected category prohibited by local, state or federal laws.

By submitting this application, you acknowledge that you have reviewed and agree to Jasper's CCPA Notice to Candidates, available at legal.jasper.ai/#ccpa."
"DevOps / Systems Engineer","Collate","San Francisco, CA","https://www.linkedin.com/jobs/view/devops-systems-engineer-at-collate-4302854141?position=34&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=o8Gc9eygV%2Fd5alNHHdhp0Q%3D%3D","About Collate

Collate is an AI document generation platform for life sciences. We automate paperwork with AI, helping our customers get life-saving innovations to patients years faster. Collate is an end-to-end solution, powering every step of drug, diagnostic, and medical device development‚Äîfrom concept to market.

Our CEO Surbhi Sarna is a former General Partner at Y Combinator. Surbhi founded nVision Medical, which developed a new method to detect ovarian cancer and was acquired by Boston Scientific. Our CTO Nate Smith is a former Visiting Partner at Y Combinator and founder of Lever. Our AI researchers, engineers, and designers have worked at Google, Nvidia, Meta, Netflix, Amazon, AirBnB, Hippocratic AI, and Grail, and 40% of our team are former founders.

We‚Äôre a small, elite team, with over $30M in seed funding from top investors (Redpoint, First Round Capital, Conviction, and Y Combinator) and leaders in healthcare and AI. This is a rare chance to join at the ground floor of a company with world-changing potential, experienced founders, and resources to execute at scale.

About The Role

We‚Äôre looking for a DevOps / Systems Engineer to own the infrastructure that powers Collate‚Äôs products. You‚Äôll build the systems and tooling that keep our platform reliable, secure, and fast as we scale.

This role is broad by design ‚Äî from managing CI/CD pipelines and cloud infrastructure to handling light security responsibilities like certificate management. You‚Äôll partner closely with backend, AI, and product engineers to ensure our systems are both easy to develop on and safe to deploy at scale.

At Collate, infrastructure isn‚Äôt just about uptime ‚Äî it‚Äôs about trust. The work you do will help ensure that the AI we build for healthcare runs with reliability and security in mind.

What You‚Äôll Do


Design and maintain cloud infrastructure to support Collate‚Äôs products as we grow from prototypes to production scale
Develop CI/CD pipelines and automation that accelerate developer velocity and reduce operational friction
Manage core system reliability, including monitoring, logging, and incident response
Take on light security responsibilities, such as handling certificates, secrets management, and supporting compliance needs
Collaborate closely with engineering teams to design infrastructure that balances speed, safety, and scale
Continuously improve internal tooling and workflows, helping the team move faster with confidence
Leverage tooling including AWS, Terraform, Kubernetes, Helm, ArgoCD, Grafana, and Github Actions



What We‚Äôre Looking For


Hands-on experience with cloud infrastructure (AWS, GCP, or similar) and modern DevOps practices
Proficiency with infrastructure-as-code and CI/CD tooling
Familiarity with monitoring, observability, and incident management
Interest or experience in light security work, including certificates, secrets management, or compliance support
A pragmatic approach: able to balance iteration speed with building for long-term reliability
Motivation to work in an early-stage startup where your infrastructure decisions shape the foundation of the company



Why Join Collate?

Impact: Build systems and experiences that touch real patients and providers, improving healthcare outcomes.

Ownership: Shape both our product experience and our engineering culture from the start.

Learning: Collaborate with a uniquely interdisciplinary team‚ÄîAI researchers, healthcare leaders, and experienced startup builders.

Upside: Join a company early enough to have meaningful equity and career-defining impact.

The base salary range for this role is $150,000‚Äì$300,000 USD annually, depending on experience and level (Tier 1, San Francisco)

We may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us."
"DevOps Engineer","Chartmetric","San Mateo, CA","https://www.linkedin.com/jobs/view/devops-engineer-at-chartmetric-4304688090?position=35&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=NTCnXUMajmPBeVaE74vjhw%3D%3D","About Chartmetric

Chartmetric, Inc. is a 10-year-old startup specializing in music data analytics. We are trusted by Universal MusicGroup, Sony, Warner, and Apple Music, as well as hundreds of other music companies and industry professionals. Our team has created a self-service data dashboard for the music industry to better understand the activity happening around artists. Together, we combine hundreds of thousands of real-time data points across iTunes, Spotify, YouTube, Google, Amazon, X, and others through our beautifully designed tool in order to make sense of the increasingly complex landscape of the music industry.

About The Role


We are seeking a talented DevOps / Developer Experience Engineer to join our team and play a pivotal role in enhancing our development infrastructure and streamlining the developer workflow. This position combines traditional DevOps responsibilities with a focus on creating exceptional developer experiences through tooling, automation, and process optimization.


What You'll Do


Infrastructure & Operations
Design, implement, and maintain scalable cloud infrastructure using Infrastructure as Code (IaC) principles
Manage CI/CD pipelines and deployment processes across multiple environments
Monitor system performance, reliability, and security, implementing proactive solutions
Automate operational tasks and eliminate manual toil through scripting and tooling
Ensure high availability and disaster recovery capabilities


Developer Experience
Build and maintain internal developer tools and platforms that improve productivity
Streamline onboarding processes for new developers and reduce time-to-first-commit
Design and implement developer-friendly APIs, SDKs, and documentation
Create self-service capabilities that reduce dependencies and waiting times
Gather feedback from development teams and iterate on tooling based on pain points


Collaboration & Process Improvement
Work closely with engineering teams to understand workflow challenges and requirements
Champion best practices for code deployment, testing, and monitoring
Lead initiatives to improve development velocity and reduce friction
Participate in incident response and post-mortem analysis
Mentor team members on DevOps practices and tooling

What We're Looking For


Technical Skills
3+ years of experience in DevOps, SRE, or Platform Engineering roles
Strong proficiency with cloud platforms (AWS, GCP, or Azure)
Experience with Infrastructure as Code tools (Terraform, CloudFormation, or Pulumi)
Hands-on experience with containerization (Docker) and orchestration (Kubernetes)
Proficiency in CI/CD tools (Jenkins, GitLab CI, GitHub Actions, or similar)
Strong scripting skills in Python, Bash, or Go
Experience with monitoring and observability tools (Prometheus, Grafana, ELK stack, or similar)


Developer Experience Focus
Experience building internal tools and platforms for development teams
Understanding of software development lifecycle and common developer pain points
Familiarity with API design and developer-facing documentation
Experience with version control systems and Git workflows
Knowledge of testing frameworks and quality assurance processes


Soft Skills
Strong problem-solving abilities and analytical thinking
Excellent communication skills and ability to work with cross-functional teams
Customer-focused mindset with emphasis on developer productivity
Proactive approach to identifying and resolving issues
Ability to balance technical debt with feature delivery


Preferred Qualifications
Knowledge of security best practices and compliance frameworks
Background in software development or engineering
Familiarity with cost optimization strategies for cloud infrastructure
Previous experience in a high-growth or scaling environment

What We Offer


Competitive salary and equity package
Comprehensive health, dental, and vision insurance
Opportunity to shape developer experience across the organization
Access to cutting-edge tools and technologies


Team Culture


We believe that great developer experiences lead to better products and happier teams. Our DevOps/DX team operates as enablers and force multipliers, working collaboratively to remove friction from the development process. We value automation, measurement, and continuous improvement, always asking ""how can we make this better for our developers?""


The Pay Range For This Role Is

135,000 - 165,000 USD per year(San Mateo)

120,000 - 150,000 USD per year(New York)"
"Cloud DevOps With Azure Experience -100%Remote","The Dignify Solutions, LLC","New Jersey, United States","https://www.linkedin.com/jobs/view/cloud-devops-with-azure-experience-100%25remote-at-the-dignify-solutions-llc-4341845867?position=36&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=%2FLn%2FykQcRqEOxTZ23mh%2FEA%3D%3D","In-depth knowledge of Azure services, including Azure Networking, Storage, Firewall, Compute, Function, Backup and Azure DevOps
Automating routine tasks using Ansible, Python, Terraform and Azure CLI for enhanced efficiency
Minimum 4 years of specialized experience DEVOPS engineer role with full automation using Ansible .
Minimum 2 years of Azure Infrastructure automation with Terraform.
Must have experience working with Terraform and Ansible for infrastructure provisioning and configuration management, respectively.
Experience configuring and managing CI/CD pipelines with tools such as GitLab, Jenkins, etc. for enterprise-level deployments.
Configuration-level knowledge for Linux sysadmin with RHEL.
Advanced troubleshooting and problem-solving skills, related to cloud and network infrastructure
Working-level experience in Azure Cloud (Azure/Azure GOV Cloud)
Advanced experience in large scale cloud architecture, design, and integration with a focus on automation, networking and NextGen Firewall
Experience with Terraform, Ansible, and Python
Linux OS
Proficiency in multi-cloud environments, especially in AWS, is highly desirable."
"DevOps Engineer - All Levels","CodeRabbit","San Francisco, CA","https://www.linkedin.com/jobs/view/devops-engineer-all-levels-at-coderabbit-4318518267?position=37&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=fAQ3v5xY%2FV1rM615%2B9ySOg%3D%3D","About CodeRabbit

CodeRabbit is an innovative research and development company focused on building extraordinarily productive human-machine collaboration systems. Our primary goal is to create the next generation of Gen AI-driven code reviewers: a symbiotic partnership between humans and advanced algorithms that significantly outperforms individual engineers. We combine language models with human ingenuity to push the boundaries of software development efficiency and quality.

Role Overview

As a DevOps Engineer at CodeRabbit, you‚Äôll play a key role in scaling, securing, and hardening the infrastructure that powers our AI-enabled developer tools. You‚Äôll work closely with our platform engineers, backend team, and applied AI teams to ensure that our systems are resilient, observable, fast, and easy to deploy.

This is a hands-on, IC-focused role for someone who thrives in fast-paced environments, takes ownership of critical infrastructure, and wants to build tooling that unblocks an ambitious engineering team.

Responsibilities


Design, implement, and maintain scalable CI/CD pipelines
Develop and manage infrastructure as code (e.g., Terraform, Pulumi)
Improve system reliability through monitoring, alerting, logging, and failover strategies
Work with platform and backend teams to identify and resolve performance bottlenecks
Contribute to deployment workflows, environment automation, and developer tooling
Ensure infrastructure security and compliance practices are in place


Qualifications


Education: Degree in Computer Science, Engineering, or a related technical field, or equivalent practical experience
Experience: 3+ years in a DevOps, Infrastructure, or SRE role at a fast-paced tech company or startup
Tooling: Expert-level proficiency with CI/CD systems (GitHub Actions, ArgoCD, etc.), Docker, and Kubernetes
Infrastructure: Expert with cloud providers (AWS/GCP), distributed systems architecture and implementation, IaC tools (Terraform, Pulumi), and secrets management (Vault, SSM, etc.)
Observability: Strong understanding of logging, metrics, and monitoring in large-scale distributed systems (e.g., Grafana, Prometheus, ELK, Datadog)
Collaboration: Effective at partnering with backend and ML teams to deliver stable, high-velocity systems
Security: Experience building with best practices in cloud and application-level security


Bonus Points


Experience supporting AI or ML workloads in production
Experience with ephemeral environments and preview deployments
Contributions to internal platform tools or DevOps open-source projects
Past ownership of high-uptime systems or regulated environments


Why Join Us?


Build the Future: We‚Äôre redefining code review with AI. You‚Äôll help shape a new development paradigm with cutting-edge technology that has real-world impact.
Real Ownership: Every engineer at CodeRabbit owns projects end-to-end ‚Äî from proposal to production.
Collaborative & Innovative Environment: Join a tight-knit team of engineers, designers, and researchers who are passionate about building transformative products.
Professional Growth: We invest in our people ‚Äî through mentorship, responsibility, and development opportunities.
Competitive Compensation: We offer a strong salary, equity, and benefits package.
Hybrid Work Culture: We collaborate in person in the Bay Area weekly, with flexibility for heads-down remote work.


Our Values


ü§ù Collaborative Humans: Prioritizing collective intelligence
üöÄ Fearless Innovators: Turning obstacles into growth opportunities
üí™ Persistent, Passionate Developers: Thriving on complex, long-term challenges
üéØ Impact-Driven Creators: Crafting intuitive tools for developers
üß† Rapid Learners and Un-learners: Adapting quickly in our fast-paced technological world


Base pay range for this role is $180k-260k. Actual salary will be based on job-related skills, experience, and location.

Apply Now ‚Äî If you're passionate about building high-impact infrastructure and enabling AI-powered developer experiences, we‚Äôd love to hear from you.

Compensation Range: $175K - $275K"
"DevOps Engineer","Uffizio","Michigan, United States","https://www.linkedin.com/jobs/view/devops-engineer-at-uffizio-4324397378?position=38&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=YSLOEqRc1YgYn4fPu8JSPw%3D%3D","Uffizio Group is looking for a proactive, ownership-driven DevOps Engineer who can lead our DevOps culture to the next level.

What We‚Äôre Looking For

Someone who doesn‚Äôt wait for tasks ‚Äî they identify improvements and execute.

A mindset of continuous innovation in CI/CD, infrastructure automation, logging, and monitoring.

Strong leadership to guide a DevOps team, set standards, and ensure timely delivery.

High accountability ‚Äî taking responsibility for stability, performance, and incident response.

Ability to introduce new tools, processes, and best practices.

Your Responsibilities

Own end-to-end CI/CD pipelines (GitHub/GitLab/Bitbucket).

Automate deployments across multi-cloud/AWS environments.

Improve observability (monitoring, alerting, logging).

Lead the team in incident management and RCA.

Build a DevOps roadmap that increases reliability and performance"
"DevOps Assistant (Entry-Level)","45PRESS","Canfield, OH","https://www.linkedin.com/jobs/view/devops-assistant-entry-level-at-45press-4301017192?position=39&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=lPnuZs%2F%2ByuFUkOA9HISy8Q%3D%3D","N/A"
"Senior DevOps Engineer","CEIPAL","Charlotte, NC","https://www.linkedin.com/jobs/view/senior-devops-engineer-at-ceipal-4305453358?position=40&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=W1bkuueGHlB1h6GRkvQQ8Q%3D%3D","N/A"
"DevOps engineer","OVA.Work","Alpharetta, GA","https://www.linkedin.com/jobs/view/devops-engineer-at-ova-work-4310657957?position=41&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=XT9RpEj6THmaPWLkBGA9bw%3D%3D","N/A"
"DevOps Engineer","Hudu","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-hudu-4323191230?position=42&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=iXEsYPpv8aMtDnNuUxsi0w%3D%3D","N/A"
"DevOps Engineer","Verra Mobility","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-verra-mobility-4335667666?position=43&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=jnWBf0rgQyaycHAmII9oyA%3D%3D","N/A"
"Staff Engineer: DevOps","Dispel","Austin, TX","https://www.linkedin.com/jobs/view/staff-engineer-devops-at-dispel-4339045806?position=44&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=Ap2VVboFpZ4wRsyx8kIc5g%3D%3D","N/A"
"DevOps Engineer","IT Automation LLC","Cary, NC","https://www.linkedin.com/jobs/view/devops-engineer-at-it-automation-llc-4324192032?position=45&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=615ZTYqlEkm5Em8XU75EhA%3D%3D","N/A"
"DevOps Engineer","CHEQUESPREAD PLC","Valley Forge, PA","https://www.linkedin.com/jobs/view/devops-engineer-at-chequespread-plc-4288904252?position=46&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=noGXoCzS7FT4qNjjXoECUw%3D%3D","N/A"
"Junior DevOps Engineer","eSimplicity","Columbia, MD","https://www.linkedin.com/jobs/view/junior-devops-engineer-at-esimplicity-4315888714?position=47&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=PphkPA0yVhqXK4xy8vCLNQ%3D%3D","N/A"
"Cloud/DevOps Engineer","Tagup, Inc.","New York, NY","https://www.linkedin.com/jobs/view/cloud-devops-engineer-at-tagup-inc-4333051833?position=48&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=DoQDWCi7dGwydOSfTz08GQ%3D%3D","N/A"
"DevOps Engineer","Mark43","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-mark43-4309062970?position=49&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=3YffZDVjwK7%2BsaeXvZQMvg%3D%3D","N/A"
"DevOps Engineer","CMG (Capital Markets Gateway)","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-cmg-capital-markets-gateway-4338419750?position=50&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=RaaHa91zjQaoIZ1QjhFUiA%3D%3D","N/A"
"DevOps Engineer","Mintlify","San Francisco, CA","https://www.linkedin.com/jobs/view/devops-engineer-at-mintlify-4318506680?position=51&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=5cxXfQvinZjydeIixok4%2BA%3D%3D","N/A"
"DevOps Support Engineer","Porter","New York, NY","https://www.linkedin.com/jobs/view/devops-support-engineer-at-porter-4295124575?position=52&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=y9MfjuV%2BE03S5bfjsFUU9g%3D%3D","N/A"
"DevOps Engineer","Northstrat Incorporated","Columbia, MD","https://www.linkedin.com/jobs/view/devops-engineer-at-northstrat-incorporated-4304125676?position=53&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=rehAqo9XOxPIIrWAkqxfvA%3D%3D","N/A"
"DevOps Engineer","Paramount","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-paramount-4335876548?position=54&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=Z6MHiQiUYGbERrg125c3Sw%3D%3D","N/A"
"DevOps Engineer","SmartVault","Houston, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-smartvault-4297941616?position=55&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=EZRCsOeKwSmcsyZ2kMnZ0g%3D%3D","N/A"
"DevOps Engineer","RSC2, Inc.","Hanover, MD","https://www.linkedin.com/jobs/view/devops-engineer-at-rsc2-inc-4311252822?position=56&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=ZNx8nGyYky%2FxfCza5DDkQw%3D%3D","N/A"
"Cloud DevOps Support Engineer","Nihon Kohden Digital Health Solutions","Irvine, CA","https://www.linkedin.com/jobs/view/cloud-devops-support-engineer-at-nihon-kohden-digital-health-solutions-4295710052?position=57&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=hkKmitbc3fBHWtAc41aiig%3D%3D","N/A"
"DevOps Engineer","PingWind","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-pingwind-4316019938?position=58&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=7LygKl3SeSvaoRXJldFx2g%3D%3D","N/A"
"DevOps Engineer","Cymertek Corporation","San Antonio, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-cymertek-corporation-4336305401?position=59&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=M3%2BUOgoDbogFEyUWRx0XDw%3D%3D","N/A"
"DevOps Engineer","Ryan","Dallas, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-ryan-4284462825?position=60&pageNum=0&refId=HF0O54QfEZonUB1uX955kA%3D%3D&trackingId=1nHfrFs95c9UumceRu7PhQ%3D%3D","N/A"
"Mid-Junior DevOps Engineer - USA","HERE","New York, NY","https://www.linkedin.com/jobs/view/mid-junior-devops-engineer-usa-at-here-4347377348?position=1&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=Ha%2F3UMzDjODeG%2BVwTazkIw%3D%3D","Mid-Junior DevOps Engineer

Location: New York, NY / Hybrid Remote / Remote within USA (EST / CST time zone)

We have an office in New York City and this position can either be based in the office, hybrid remote, or remote within the EST/CST time zones (subject to your existing legal right to work in the jurisdiction).

About HERE

Everything works right here‚Ñ¢.

Traditional browsers weren't built for work. In today's enterprise environment‚Äîwhere security threats are constant and productivity is critical‚Äîlegacy browsers fall short. That's why we built HERE, the browser purpose-built for work.

Powered by Chromium, HERE Enterprise Browser combines enterprise-grade security, seamless productivity, and native AI integration in one secure, intelligent workspace. Designed for regulated industries, HERE offers deep policy controls, identity-based access, secure workspace isolation, and full interoperability across SaaS, legacy, and virtualized environments. Our platform enables teams to work faster, more securely, and more intelligently‚Äîwithout compromise.

HERE technology is trusted by 90% of global banks and also used within the U.S. Intelligence Community and other sectors. We're backed by some of the world's most respected financial institutions and venture firms, including Bain Capital Ventures, Bank of America, J.P. Morgan, Wells Fargo and IQT, the not-for-profit strategic investor that accelerates the introduction of groundbreaking technologies to enhance the national security of America and its allies.

About the Role

HERE is seeking a mid-junior DevOps Engineer to join our infrastructure team! The primary responsibilities for this role will span CI/CD pipeline engineering and cloud operations, maintaining and improving our GitHub and GitLab CI/CD pipelines, and supporting our AWS cloud infrastructure. In this role, you will gain hands-on experience with real production build systems and cloud platforms- while having the opportunity to work on practical projects that directly impact both our development velocity and operational reliability.

We're actively evolving toward a cloud-agnostic, multi-cloud architecture and migrating to Kubernetes for container orchestration. While current AWS and ECS experience is essential, having exposure to Azure, GCP, and Kubernetes will position you well for our infrastructure roadmap.

This role offers the opportunity to collaborate with senior engineers who will provide guidance and mentorship, whilst giving you ownership of projects across the DevOps lifecycle. This is an excellent platform for building practical experience with modern build engineering (CI/CD automation, cloud infrastructure, and deployment practices) within a production environment.

Responsibilities


CI/CD Pipeline Development:
Build, maintain, and optimize GitLab CI/CD pipelines for multi-platform builds (Windows, macOS, Linux).
Work with YAML configurations, pipeline stages, artifacts, and deployment workflows.
Cloud Infrastructure Operations:
Help maintain and improve AWS infrastructure including ECS/Fargate deployments, RDS databases, Route53 DNS, VPC networking, and IAM policies.
Support multi-tenant and multi-region architecture.
Container & Deployment Management:
Work with Docker containers, ECS task definitions, and ECR registries.
Deploy and manage containerized Node.js applications in production environments.
Release Management:
Help manage release processes including version promotion, release channels (canary, beta, stable), and automated deployment to staging and production environments.
Database Operations:
Support PostgreSQL on AWS RDS‚Äîbackups, SSH tunneling through bastion hosts, read-only user management, and database configuration for multi-tenant environments.
Automation & Scripting:
Write and maintain automation scripts in Bash, PowerShell, Python, and Node.js.
Build tools to improve infrastructure reliability and developer experience.
Internal Tools Support:
Help maintain web-based DevOps tools built with Express.js, React, and TypeScript‚Äîtools for cloud settings management, tenant provisioning, and deployment monitoring.

What We're Looking For

Ideally 2 to 4 years of experience with the following core requirements:


GitLab CI/CD: Experience with GitLab CI/CD pipelines‚ÄîYAML configuration, stages, jobs, artifacts, rules, dependencies.
Understanding of CI/CD best practices and pipeline optimization.
AWS Cloud Fundamentals: Practical experience with core AWS services‚ÄîEC2, ECS/Fargate, RDS, Route53, VPC, IAM, Secrets Manager, CloudWatch. Comfortable navigating the AWS Console and CLI.
Multi-Platform Scripting: Solid scripting skills in Bash (Linux) and PowerShell (Windows). Ability to write maintainable automation scripts for both platforms.
Containerization: Hands-on Docker experience‚Äîbuilding images, writing Dockerfiles, docker-compose, understanding container networking, and working with ECS/ECR.
Build Systems: Experience with build tools and package managers‚Äînpm/Node.js, .NET/NuGet, Python packaging. Understanding of dependency management and build artifacts.
Version Control: Strong Git fundamentals‚Äîbranching strategies, merge requests, tagging. Experience with GitHub (or GitLab) workflows and code review practices.
Linux/Unix & Windows: Comfortable in both environments‚ÄîSSH, file permissions, package managers, systemd, PowerShell. Understanding of cross-platform operational challenges.
Node.js/JavaScript: Comfortable reading and writing JavaScript/Node.js code. Experience with npm, package.json, and basic Express.js applications for tooling.


Nice to Have


Kubernetes experience (EKS, GKE, AKS) or willingness to learn, we're migrating from ECS to K8s
Multi-cloud experience (Azure, GCP) or cloud-agnostic architecture knowledge
GitLab Runner administration and configuration
AWS CDK or CloudFormation for Infrastructure as Code
Terraform for multi-cloud infrastructure management
TypeScript development experience
PostgreSQL database administration and optimization
.NET build systems and NuGet package management
React or frontend framework experience
Airflow or workflow orchestration tools
Helm charts and Kubernetes manifest management


What We're Offering

Benefits -


Generous Paid Time Off, Paid Holidays & Sick Time
Competitive & Comprehensive Health Insurance
Thoughtfully-Planned Paid Parental Leave
Financial Well-Being Plans (FSA) (401k) (Life Insurance)
Stock Options
Professional Development Courses
Employee Resource Groups


Additional Perks -


One Medical - Free Membership
Talkspace - Mental Health Therapy 24/7
Team Lunches
Casual dress code
Commuter Benefits (NYC employees only)
Citibike (NYC employees only)


Life at HERE

At HERE, we pride ourselves on fostering a friendly, collaborative, and supportive culture that truly respects the diversity of thought. Our goal is to create a space where employees can learn and innovate, and overall, have a good time doing it. We value and appreciate that our employees have a wide set of interests and experiences and put importance on taking the time to get to know one another and form relationships. From virtual socials and in-person events, to informal meetings and employee resource groups, we make it easy to engage and connect. Our environment promotes a productive, enjoyable learning experience - aligned together, working to create compelling solutions for our clients. Everything works right here.‚Ñ¢

We are HERE - Read about our recent rebrand from OpenFin to HERE

Recent Awards


Voted ""Enterprise Browser of the Year"" by CIO Review (2025)
Voted ""100 Best Midsize Companies to Work For in NYC"" by BuiltIn (2025)
Voted ""Top 10 Contact Center Technologies & Capabilities of 2024"" by CX Today (2024)
Voted ""Best Enterprise Environment for Interoperability"" by TradingTech Insight Awards Europe (2024)
Voted ""Top 50 Best Startups to Work for in the US"" & ""Top 50 Best Startups to Work for in New York"" by BuiltIn (2024)
Voted as a ""Best Employer Award"" finalist at the UK FinTech Awards (2023)
Voted ""Best FinTech Company CEO"" at the FinTech Breakthrough Awards (2023)
Voted ""Best Internal Talent Team"" by Financial Technologist (2023)
Voted ""Best Solution for Workflow Automation"" at the Trading Tech Insight Awards (2023)
Voted ""Top Innovator Across Financial Markets"" in TabbFORUM NOVA Awards (2023)
Voted ""Best User Interface Innovation"" in the Risk Markets Technology Awards (2023)
Voted ""Top 100 Most Promising Private FinTech Companies"" by CB Insights (2023)
Voted ""Most Influential Financial Technology Firm"" by Harrington Starr (2023)


RECRUITERS NOTICE: Recruiters - if you wish to reach out to us regarding this job posting, you may reach out to externalrecruitment@here.io in order for your communication to be reviewed. HERE will review these communications if external help is needed for a position. Agencies may not contact individuals within our organization with solicitations. Firms that do not follow these guidelines risk having all communication from their firm being blocked. We thank you in advance for your cooperation in following our process.

Sponsorship - While we highly value all of our candidates, we are not offering sponsorship for this role.

Salary Range: $70k - $120k

Salary Range Disclaimer: This base salary range represents the low and high end salary range for this particular position; not all encompassing of the total compensation package. Actual salaries may vary depending upon but not limited to experience, special skill set, education and location. This range represents only one aspect of HERE's total compensation package offered to employees. Other forms of compensation may be stock options, commissions, paid time off and other variable benefits. Learn more about additional HERE compensation benefits above."
"junior devops engineer","OVA.Work","Alpharetta, GA","https://www.linkedin.com/jobs/view/junior-devops-engineer-at-ova-work-4309344701?position=2&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=xp56e1zQnReDrjUkXdvMHw%3D%3D","Job Title: Junior DevOps Engineer

Location: Remote

Job Type: Full-time

Experience Level: Entry-Level (0-2 years)

Department: IT / Engineering / DevOps

Job Summary

We are looking for a motivated and detail-oriented Junior DevOps Engineer to join our growing DevOps team. This role is ideal for someone with a foundational understanding of DevOps practices and a passion for automation, cloud technologies, and continuous integration/deployment. You will assist in maintaining and improving our infrastructure, deployment pipelines, and monitoring systems.

Key Responsibilities


Assist in the setup, maintenance, and monitoring of CI/CD pipelines.
Support cloud infrastructure (AWS, Azure, GCP) and help manage deployments.
Collaborate with development and operations teams to ensure reliable software delivery.
Write scripts and automation tools to streamline operations and deployments.
Monitor system performance and troubleshoot issues in development and production environments.
Maintain documentation for infrastructure and deployment processes.
Learn and apply best practices in security, scalability, and reliability.


Required Qualifications


Bachelor's degree in Computer Science, Information Technology, or related field.
Basic understanding of DevOps principles and software development lifecycle.
Familiarity with Linux/Unix systems and shell scripting.
Exposure to cloud platforms (AWS, Azure, or GCP).
Experience with version control systems (e.g., Git).
Knowledge of CI/CD tools (e.g., Jenkins, GitLab CI, GitHub Actions).
Strong problem-solving and communication skills.
Eagerness to learn and grow in a fast-paced environment.


Preferred Qualifications


Internship or project experience in DevOps or system administration.
Familiarity with containerization tools (Docker) and orchestration (Kubernetes).
Experience with Infrastructure as Code (Terraform, Ansible).
Basic knowledge of monitoring tools (Prometheus, Grafana, ELK Stack).


Benefits


Competitive salary and growth opportunities.
Mentorship from senior engineers.
Health and wellness benefits.
Flexible work hours and remote work options.
Access to training and certification programs."
"DevOps Engineer - Remote","The Dignify Solutions, LLC","Newtown Square, PA","https://www.linkedin.com/jobs/view/devops-engineer-remote-at-the-dignify-solutions-llc-4341955705?position=3&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=ILjgxWHsSeteyDbH1DQ0nw%3D%3D","Over 12 -15 years of overall expereince needed.
A solid foundation in computer science, with strong competencies in data structures, algorithms, and software design.
Large systems software design and development experience.
Experience performing in-depth troubleshooting and unit testing with both new and legacy production systems.
Experience in programming and experience with problem diagnosis and resolution.
Kubernetes (3-4 YOE) and Fieldglass Experience (1-2 YOE)"
"DevOps Engineer - Remote","The Dignify Solutions, LLC","Newtown Square, PA","https://www.linkedin.com/jobs/view/devops-engineer-remote-at-the-dignify-solutions-llc-4347005704?position=4&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=sjeh2pA%2BkooCDR0fnm1G7A%3D%3D","Bachelor's degree in a technical field such as computer science, computer engineering or related field required 0-2 years experience required.
1-2 years of experience with Kubernetes.
ISBN experience preferred.
A solid foundation in computer science , with strong competencies in data structures, algorithms, and software design large systems software design and development experience.
Experience performing in-depth troubleshooting and unit testing with both new and legacy production systems experience in programming and experience with problem diagnosis and resolution."
"Junior DevOps Engineer","GliaCell Technologies","Hanover, MD","https://www.linkedin.com/jobs/view/junior-devops-engineer-at-gliacell-technologies-4338894490?position=5&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=TEXDQhFIVyt3BKV2szGAFA%3D%3D","An active or rein-statable TS/SCI with Polygraph security clearance is REQUIRED. Please do not apply if you currently do not possess this level of clearance.***


Are you a Junior DevOps Engineer who is ready for a new challenge that will launch your career to the next level?


Tired of being treated like a company drone?
Tired of promised adventures during the hiring phase, then being dropped off on a remote contract and never seen or heard from the mothership again?
Our engineers were certainly tired of the same.


At GliaCell our slogan is ‚ÄúWe make It happen‚Äù.


We will immerse you in the latest technologies.
We will develop and support your own personalized training program to continue your individual growth.
We will provide you with work that matters with our mission-focused customers, and surround you with a family of brilliant engineers.


Culture isn‚Äôt something you need to talk about‚Ä¶if it just exists.

If this sounds interesting to you, then we‚Äôd like to have a discussion regarding your next adventure! If you want to be a drone, this isn‚Äôt the place for you.

We Make It Happen!

GliaCell Technologies focuses on Software & System Engineering in Enterprise and Cyber Security solution spaces. We excel at delivering stable and reliable software solutions using Agile Software Development principles. These provide us the capability to deliver a quick turn-around using interactive applications and the integration of industry standard software stacks.

GliaCell‚Äôs Enterprise capabilities include Full-Stack Application Development, Big Data, Cloud Technologies, Analytics, Machine Learning, AI, and DevOps Containerization. We also provide customer solutions in the areas of CND, CNE, and CNO by providing our customers with assessments and solutions in Threat Mitigation, Vulnerability Exposure, Penetration Testing, Threat Hunting, and Preventing Advanced Persistent Threat.

We Offer


Long term job security
Competitive salaries & bonus opportunities
Challenging work you are passionate about
Ability to work with some amazingly talented people


Job Description

GliaCell is seeking a Junior DevOps Engineer on one of our subcontracts. This is a full-time position offering the opportunity to support a U.S. Government customer. The mission is to provide technical expertise that assists in sustaining critical mission-related software and systems to a large government contract.

Responsibilities


Establishing a test framework and automated tests utilizing Cucumber and Cypru
Knowledgeable in Microservices design & architecture, CI/CD, Test frameworks and automation, Agile Methodology.
Execute load and performance testing, chaos testing, functional testing and end-to-end testin
Agile development and delivery of software
Communication and collaboration: Software Development is a team-oriented discipline. Engineers need to be able to communicate and collaborate effectively with other team members, as well as with stakeholders.


Required Skills


Python and Cucumber


Desired Skills:


AWS services such as Lambdas, Step Functions, EC2 and S3


Key Requirements

To be considered for this position you must have the following:


Possess an active or rein-statable TS/SCI with Polygraph security clearance.
U.S. Citizenship.
Works well independently as well as on a team.
6+ years experience as a Developer in programs and contracts of similar scope, type, and complexity is required. A bachelor‚Äôs degree in a technical discipline from an accredited college or university is required. Five (4) years of development experience may be substituted for a bachelor‚Äôs degree.


Location: Annapolis Junction, MD

Salary Range: The salary range for this full-time position is $50,000 to $120,000. Our salary ranges are determined by position, level, skills, professional experience, relevant education and certifications. The range displayed on each job posting reflects the minimum and maximum target salaries for this position across our projects. Within the range, your salary is determined by your individual benefits package selection. Your recruiter can share more about the specific salary range for your preferred position during the hiring process.

Benefits


Medical, Dental, and Vision Coverage for Employee and Dependents
Up to 25 Days of Paid Time Off
Up to 40 hours of PTO Carryover
11 Federal Government Holidays
Work From Home Opportunities
401K Company Contribution, Fully Vested Day 1
Discretionary, Certification, and Sign-On Bonus Potential
Employee Referral Bonus Program
Annual Professional Development
100% Premium Covered for Life & Disability Insurances
Additional Voluntary Life Insurance Coverage Available
Employee Assistance Program
Travel Protection Program
Financial Planning Assistance
Bereavement and Jury Duty Leave
Monthly Team and Family Events
Technology Budget
Global Entry
Annual Swag Budget


Learn more about GliaCell Technologies: https://gliacelltechnologies.applytojob.com/apply/

GliaCell Technologies, LLC is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status."
"DevOps Cloud Engineer Based in U.S.A","Advancio","United States","https://www.linkedin.com/jobs/view/devops-cloud-engineer-based-in-u-s-a-at-advancio-4324442139?position=6&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=z1H4CHucl7AE7QrKxqedQg%3D%3D","This is a remote position.

Who We Are:


At Advancio, we are passionate about technology and its ability to transform the world. We are rapidly expanding and building a company where we serve exceptional businesses, hire top talent, and have a lot of fun doing what we love!


Job Summary:

We are seeking a skilled DevOps Cloud Engineer to design, implement, and manage scalable cloud-based infrastructure and DevOps processes. The ideal candidate will have extensive experience with cloud platforms, CI/CD pipelines, and automation tools, ensuring the efficient deployment and operation of applications.


What will you do:


Design, deploy, and manage cloud infrastructure on platforms such as AWS, Azure, or Google Cloud Platform (GCP).

Build and maintain CI/CD pipelines to streamline development and deployment processes.

Automate infrastructure provisioning, configuration, and monitoring using tools like Terraform, Ansible, or similar.

Ensure system reliability, availability, and performance through robust monitoring and alerting.

Collaborate with development teams to optimize the delivery and scalability of applications.

Manage containerized workloads using Docker and orchestration platforms such as Kubernetes.

Implement security best practices for cloud environments, including identity management, encryption, and compliance adherence.

Stay updated with the latest DevOps tools and methodologies to enhance team efficiency.




Requirements






5+ years of experience in DevOps, cloud engineering, or related roles.

Advanced English communication skills, both verbal and written.

Proficiency in at least one major cloud platform (AWS, Azure, or GCP).

Hands-on experience with CI/CD tools (e.g., Jenkins, GitLab CI/CD, CircleCI).

Strong scripting skills in Python, Bash, or similar languages.

Solid knowledge of infrastructure-as-code (IaC) tools like Terraform or CloudFormation.

Experience with containerization (Docker) and orchestration (Kubernetes).

Familiarity with monitoring and logging tools like Prometheus, Grafana, or ELK Stack.

Strong understanding of networking, security, and system architecture."
"DeVops Engineer","Pittsburgh Robotics Network","Pittsburgh, PA","https://www.linkedin.com/jobs/view/devops-engineer-at-pittsburgh-robotics-network-4347073200?position=7&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=5nFnL%2B%2Bqx2DFcyhlCKZJPA%3D%3D","DevOps Engineer

TDK SensEI

Pittsburgh, PA

This position is for our Pittsburgh, PA office - only apply if you are based there or willing to relocate.

At TDK SensEI, we are transforming how industrial customers utilize and interact with sensor data. We specialize in developing advanced AI solutions capable of running directly on edge devices. By processing data locally, TDK SensEI enhances real-time decision-making, privacy, security, and cost efficiency. Our offerings include automated machine learning tools, AI-powered condition-based monitoring systems, and various sensor devices optimized for low latency and power consumption. Collaborating with leading global companies, we empower teams to effortlessly devise and implement machine learning solutions for industrial applications, all without the need for coding.

We are seeking a Dev Ops engineer to join our team. In this position, the candidate will be responsible for managing, operating, and provisioning cloud environments such as AWS, Azure, Google cloud. You will work with development, security, and operations teams to deploy, scale, and operate dev environments. You are also responsible for improving and automating the dev environment. You will establish configuration management, automate our infrastructure, implement continuous integration, and train the team in DevOps best practices.

As a Dev Ops Engineer, Your Responsibilities Will Include


Designing, implementing, and maintaining tools and processes for continuous integration, delivery, and deployment of software
Working with developers to deploy and manage code changes
Working with operations staff to ensure that systems are up and running smoothly
Automating, monitoring, testing, configuring, networking, and Infrastructure as Code (IaC)
Streamlining and automating processes while troubleshooting existing development procedures
Managing the creation, release, and configuration of production systems
Architecting and optimizing several service components running on AWS environment


Skills & Requirements


Bachelor‚Äôs degree or equivalent experience
Minimum 2 years of experience in DevOps, infrastructure automation or similar role
Knowledge of Linux/UNIX administration
Proficiency in Python, JavaScript and other script environments (e.g. bash)
Experience with containerization technologies, Docker and associated tooling
Experience designing and implementing CI/CD pipelines
Experience operating databases such as PostgreSQL or MySQL, especially in cloud-native services like RDS
Awareness of critical concepts in DevOps and Agile principles
US work authorization


Nice To Have


AWS certifications (e.g., AWS Certified DevOps Engineer, AWS Certified Solutions Architect).
Familiarity with other cloud providers (Azure, Google Cloud).
Experience with container orchestration systems such as Kubernetes/EKS"
"DevOps Engineer","Princeton IT Services, Inc","Englewood Cliffs, NJ","https://www.linkedin.com/jobs/view/devops-engineer-at-princeton-it-services-inc-4338714288?position=8&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=sQGsbxvArwRVDK7ZdvFnaw%3D%3D","Job Title: DevOps Engineer

Location: Englewood Cliffs, NJ

Employment Type: W2 Only

Job Summary

We are seeking a DevOps Engineer with strong hands-on experience in Linux, Docker, and Kubernetes to support and optimize our deployment environment in Englewood Cliffs, NJ. This is a W2-only role requiring solid skills in automation, CI/CD, and container orchestration. The ideal candidate will ensure smooth application releases, maintain system stability, and collaborate closely with development teams.

Key Responsibilities


Manage and support Linux-based systems in production and staging environments.
Build, maintain, and optimize CI/CD pipelines for automated deployments.
Create, manage, and troubleshoot Docker containers and images.
Deploy, monitor, and tune Kubernetes clusters and workloads.
Automate infrastructure tasks using Shell or Python scripts.
Implement and manage monitoring and logging tools (Prometheus, Grafana, ELK, etc.).
Troubleshoot system, container, and cluster-level issues end-to-end.
Work cross-functionally with development and QA teams to ensure smooth releases.


Required Skills


8+ years of DevOps or related experience.
Strong hands-on experience with Linux administration.
Solid experience working with Docker for containerization.
Strong working knowledge of Kubernetes (deployments, scaling, troubleshooting).
Experience building CI/CD pipelines (Jenkins, GitLab CI, GitHub Actions).
Strong scripting skills in Shell/Bash/Python.
Experience with monitoring and logging tools."
"DevOps Engineer","Lean TECHniques","Johnston, IA","https://www.linkedin.com/jobs/view/devops-engineer-at-lean-techniques-4336685413?position=9&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=%2BdnXKNTigPZfZBHNsXiIIQ%3D%3D","Maybe you‚Äôre bored and need a new challenge. Or you‚Äôre sick of all the bureaucracy and just want to focus on designing kick-ass software.

Whatever the reason, we want you to know that LT is different. And not just air quotes ‚Äúdifferent,‚Äù but more like ‚Äúbreathing easy for the first time in a long time‚Äù different.

It‚Äôs a place where you can write your own story and make a difference along the way. At LT, you‚Äôll have the freedom and flexibility to do what you think needs to be done, and you‚Äôll get to do it while working alongside a team of other curious individuals who love a good challenge too.

We‚Äôre currently looking to add a DevOps Engineer to our crew of nerds. If you‚Äôre someone who has 5+ years of DevOps experience, we'd love to chat!"
"DevOps Engineer","LifeMD","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-lifemd-4337132819?position=10&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=8lvYJiKfAw9Ew3DpLGX9RA%3D%3D","About us:

LifeMD is a leading digital healthcare company committed to expanding access to virtual care, pharmacy services, and diagnostics by making them more affordable and convenient for all.¬†Focused on both treatment and prevention, our unique care model is designed to optimize the patient experience and improve outcomes across more than 200 health concerns.¬†

To support our expanding patient base, LifeMD leverages a vertically-integrated, proprietary digital care platform, a 50-state affiliated medical group, a 22,500-square-foot affiliated pharmacy, and a U.S.-based patient care center.¬†Our company ‚Äî with offices in New York City; Greenville, SC; and Huntington Beach, CA ‚Äî is powered by a dynamic team of passionate professionals. From clinicians and technologists to creatives and analysts, we're united by a shared mission to revolutionize healthcare.¬†Employees enjoy a collaborative and inclusive work environment, hybrid work culture, and numerous opportunities for growth. Want your work to matter? Join us in building a future of accessible, innovative, and compassionate care.


About the role:

LifeMD is seeking a highly motivated and experienced DevOps Engineer to join our dynamic Technology team. This individual will serve as a critical link between software development and IT operations, playing a pivotal role in designing, implementing, and maintaining automated processes for software delivery, infrastructure management, and system monitoring. The primary objective is to accelerate our release cycles, enhance system stability, and improve overall operational efficiency across our diverse cloud infrastructure, all while strictly adhering to stringent healthcare industry compliance standards, including HIPAA and SOX.


Responsibilities:


Design, implement, and manage scalable, secure, and cost-effective cloud infrastructure primarily on AWS using Terraform
Develop and version control Terraform modules for automated provisioning, updating, and de-provisioning of cloud resources (e.g., EC2, S3, RDS, VPC, Lambda in AWS)
Design, build, and optimize automated CI/CD pipelines using GitHub Actions for various applications and microservices
Integrate automated testing, static code analysis, security scanning, and deployment steps into CI/CD workflows for high quality and secure releases
Implement, configure, and maintain comprehensive monitoring, logging, and alerting solutions (e.g., AWS CloudWatch, Datadog) for all environments
Develop custom dashboards, metrics, and alerts for real-time visibility into system health, performance, and security events
Proactively analyze logs and metrics to identify potential bottlenecks and issues
Participate in on-call rotations to swiftly respond to and resolve critical incidents, ensuring high service availability
Automate repetitive operational tasks, system configurations, and deployment processes using Python and Bash to enhance efficiency



Requirements



Basic Qualifications:

Bachelor's degree in Computer Science, Information Technology, Engineering, or a related technical field, or equivalent work experience
3+ years of progressive experience as a DevOps Engineer, Site Reliability Engineer (SRE), or similar role in a cloud-native environment
Expert-level proficiency in AWS services (EC2, S3, RDS, VPC, Lambda, IAM, CloudWatch, etc.). Solid understanding and working knowledge of GCP, Digital Ocean, and Azure concepts and services
Expertise in Terraform for multi-cloud infrastructure provisioning and management, including experience with state management, modules, and workspaces
Highly skilled in using Git and GitHub for source code management, branching strategies, and pull request workflows
Hands-on experience with implementing and managing monitoring and logging solutions (e.g., AWS CloudWatch, Datadog, ELK stack)
Solid understanding of cloud networking concepts, including VPCs, subnets, routing tables, load balancers, DNS, and VPNs
Strong understanding of cloud security best practices, identity and access management (IAM), security groups, network ACLs, and data protection principles
Working knowledge of database concepts and experience with various database types (e.g., MongoDB, PostgreSQL, MySQL)
Strong understanding and implementation of Ansible for cloud workload automations
Hands-on experience with Linux (Ubuntu) and update/patching mechanisms



Preferred Qualifications:

Experience in the healthcare industry or a highly regulated environment, with a demonstrable understanding of compliance requirements (e.g., HIPAA, SOC2)
Relevant cloud certifications (e.g., AWS Certified DevOps Engineer - Professional, AWS Certified Solutions Architect - Associate/Professional)
In-depth experience with GitHub Actions for designing, implementing, and maintaining automated build, test, and deployment pipelines. Familiarity with other CI/CD tools
Strong proficiency in Python and Bash scripting for automation, system administration, and tool development.
Knowledge of Node.js or PHP
Experience with Docker for containerizing applications. Familiarity with container orchestration platforms (e.g., Kubernetes, AWS ECS)
Exceptional problem-solving and analytical skills with a proactive approach to identifying and resolving complex technical issues
Excellent communication and interpersonal skills, capable of effectively collaborating with diverse cross-functional teams (developers, QA, product, security)
Strong sense of ownership, accountability, and ability to work independently while also being a strong team player
A continuous learning mindset, staying updated with emerging technologies, industry trends, and best practices in the DevOps space
Meticulous attention to detail and strong documentation skills



Benefits


Salary Range: $130,000-$140,000
Health Care Plan (Medical, Dental & Vision)
Retirement Plan (401k, IRA)
Life Insurance (Basic, Voluntary & AD&D)
Unlimited PTO Policy
Paid Holidays
Short Term & Long Term Disability
Training & Development"
"DevOps Engineer (35 LPA - 55 LPA)","CodeRound AI","Greater Bloomington Area","https://www.linkedin.com/jobs/view/devops-engineer-35-lpa-55-lpa-at-coderound-ai-4308183910?position=11&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=IRNQ6tjRvKZFpco2Jirdbw%3D%3D","üöÄ What We‚Äôre Building


CodeRound AI matches top 5% tech talent to fastest growing VC funded AI startups.
Candidates apply once and get UPTO 10 remote as well as onsite interview opportunities IF selected!
Top-tier product startups in US, UAE & India have hired top engineers & ML folk using CodeRound


üß© What You‚Äôll Do


Build and optimize our cloud infrastructure ‚Äî scalable, secure, and cost-effective (mostly AWS).
Set up and manage CI/CD pipelines to ensure smooth deployment across backend, AI services, and mobile.
Containerize backend services (FastAPI, Rails) and optimize them for performance.
Implement monitoring, alerting, and logging to catch issues before users do.
Optimize database performance (Postgres, Redis) and manage backups and scaling.
Collaborate with backend, AI, and product teams to deploy new features safely and quickly.
Champion infra-as-code and automation wherever possible.


üí• Why this is exciting


You'll own DevOps for a high-usage, real-world AI platform ‚Äî not just internal tools.
You‚Äôll work on real-time, high-stakes flows ‚Äî interviews, scoring, hiring decisions.
You‚Äôll work closely with founders, ship weekly, and see the direct impact of your work.


‚úÖ You‚Äôll Be Great At This If You


Have 4+ years of experience as a DevOps engineer, SRE, or infrastructure engineer.
Are strong with AWS services (EC2, RDS, ECS/EKS, S3, CloudWatch).
Can write clean, reusable Terraform or CloudFormation code.
Have experience setting up CI/CD pipelines and optimizing build/release flows.
Are comfortable with Docker, Linux servers, and basic networking (VPCs, security groups).
Understand application and database scaling (horizontal/vertical).


‚ö° Bonus If You


Have experience supporting AI/ML pipelines in production (fine-tuning infra, vector DBs, etc.).
Know cost optimization tricks for cloud infra (spot instances, autoscaling groups, etc.).
Are excited to eventually build a small infra team"
"Devops Engineer","The Dignify Solutions, LLC","Brooklyn, OH","https://www.linkedin.com/jobs/view/devops-engineer-at-the-dignify-solutions-llc-4341915759?position=12&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=CHn4FZN0YYMlGNMBkwHytg%3D%3D","Job Description:


Serve as a subject matter expert to develop and support DevOps Web Access Management solutions
Install, configure, and maintain automation solutions, in support of KeyBank infrastructure
Develop Standard Operating Procedures, maintenance plans and provide status reports as required
Perform daily operational tasks as required for the Web Access Management team


Qualifications:


General technical capabilities across all portions of the infrastructure stacks
Independent thinker and self-starter
Generates ideas, innovative
Experienced with automation frameworks using an automation first approach
Proficient in one or more programming/scripting languages (Python, Ansible, etc.)
Proficient with one or more cloud orchestration tools (Terraform, Cloud Formation, etc.)
Conduct performance analysis and optimization
Experienced with public cloud providers such as GCP, Azure and AWS
Comfortable operating in a Linux environment


Preferred Skills:


Public and Private Cloud automation experience in production & non-production environments
Knowledge of web access management technologies and deployments
Knowledge of web access management technologies and deployments
Knowledge of routing & switching technologies and configurations
Knowledge of compute and storage solutions in data center environments
Experience with Service Now change management and problem management platform
Ability to balance workload amidst competing deadlines
Ability to perform knowledge transfers with peer engineers
Contribute to the reliability, performance, supportability, and security of web access management infrastructure
Review procedures for change and configuration management in all environments"
"DevOps Engineer","LifeMD","Huntington Beach, CA","https://www.linkedin.com/jobs/view/devops-engineer-at-lifemd-4337182535?position=13&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=%2FH%2FoVwUmfbLVhKExV8ebZQ%3D%3D","About us:

LifeMD is a leading digital healthcare company committed to expanding access to virtual care, pharmacy services, and diagnostics by making them more affordable and convenient for all.¬†Focused on both treatment and prevention, our unique care model is designed to optimize the patient experience and improve outcomes across more than 200 health concerns.¬†

To support our expanding patient base, LifeMD leverages a vertically-integrated, proprietary digital care platform, a 50-state affiliated medical group, a 22,500-square-foot affiliated pharmacy, and a U.S.-based patient care center.¬†Our company ‚Äî with offices in New York City; Greenville, SC; and Huntington Beach, CA ‚Äî is powered by a dynamic team of passionate professionals. From clinicians and technologists to creatives and analysts, we're united by a shared mission to revolutionize healthcare.¬†Employees enjoy a collaborative and inclusive work environment, hybrid work culture, and numerous opportunities for growth. Want your work to matter? Join us in building a future of accessible, innovative, and compassionate care.


About the role:

LifeMD is seeking a highly motivated and experienced DevOps Engineer to join our dynamic Technology team. This individual will serve as a critical link between software development and IT operations, playing a pivotal role in designing, implementing, and maintaining automated processes for software delivery, infrastructure management, and system monitoring. The primary objective is to accelerate our release cycles, enhance system stability, and improve overall operational efficiency across our diverse cloud infrastructure, all while strictly adhering to stringent healthcare industry compliance standards, including HIPAA and SOX.


Responsibilities:


Design, implement, and manage scalable, secure, and cost-effective cloud infrastructure primarily on AWS using Terraform
Develop and version control Terraform modules for automated provisioning, updating, and de-provisioning of cloud resources (e.g., EC2, S3, RDS, VPC, Lambda in AWS)
Design, build, and optimize automated CI/CD pipelines using GitHub Actions for various applications and microservices
Integrate automated testing, static code analysis, security scanning, and deployment steps into CI/CD workflows for high quality and secure releases
Implement, configure, and maintain comprehensive monitoring, logging, and alerting solutions (e.g., AWS CloudWatch, Datadog) for all environments
Develop custom dashboards, metrics, and alerts for real-time visibility into system health, performance, and security events
Proactively analyze logs and metrics to identify potential bottlenecks and issues
Participate in on-call rotations to swiftly respond to and resolve critical incidents, ensuring high service availability
Automate repetitive operational tasks, system configurations, and deployment processes using Python and Bash to enhance efficiency



Requirements



Basic Qualifications:

Bachelor's degree in Computer Science, Information Technology, Engineering, or a related technical field, or equivalent work experience
3+ years of progressive experience as a DevOps Engineer, Site Reliability Engineer (SRE), or similar role in a cloud-native environment
Expert-level proficiency in AWS services (EC2, S3, RDS, VPC, Lambda, IAM, CloudWatch, etc.). Solid understanding and working knowledge of GCP, Digital Ocean, and Azure concepts and services
Expertise in Terraform for multi-cloud infrastructure provisioning and management, including experience with state management, modules, and workspaces
Highly skilled in using Git and GitHub for source code management, branching strategies, and pull request workflows
Hands-on experience with implementing and managing monitoring and logging solutions (e.g., AWS CloudWatch, Datadog, ELK stack)
Solid understanding of cloud networking concepts, including VPCs, subnets, routing tables, load balancers, DNS, and VPNs
Strong understanding of cloud security best practices, identity and access management (IAM), security groups, network ACLs, and data protection principles
Working knowledge of database concepts and experience with various database types (e.g., MongoDB, PostgreSQL, MySQL)
Strong understanding and implementation of Ansible for cloud workload automations
Hands-on experience with Linux (Ubuntu) and update/patching mechanisms



Preferred Qualifications:

Experience in the healthcare industry or a highly regulated environment, with a demonstrable understanding of compliance requirements (e.g., HIPAA, SOC2)
Relevant cloud certifications (e.g., AWS Certified DevOps Engineer - Professional, AWS Certified Solutions Architect - Associate/Professional)
In-depth experience with GitHub Actions for designing, implementing, and maintaining automated build, test, and deployment pipelines. Familiarity with other CI/CD tools
Strong proficiency in Python and Bash scripting for automation, system administration, and tool development.
Knowledge of Node.js or PHP
Experience with Docker for containerizing applications. Familiarity with container orchestration platforms (e.g., Kubernetes, AWS ECS)
Exceptional problem-solving and analytical skills with a proactive approach to identifying and resolving complex technical issues
Excellent communication and interpersonal skills, capable of effectively collaborating with diverse cross-functional teams (developers, QA, product, security)
Strong sense of ownership, accountability, and ability to work independently while also being a strong team player
A continuous learning mindset, staying updated with emerging technologies, industry trends, and best practices in the DevOps space
Meticulous attention to detail and strong documentation skills



Benefits


Salary Range: $130,000-$140,000
Health Care Plan (Medical, Dental & Vision)
Retirement Plan (401k, IRA)
Life Insurance (Basic, Voluntary & AD&D)
Unlimited PTO Policy
Paid Holidays
Short Term & Long Term Disability
Training & Development"
"Devops Engineer","Hoplite Solutions LLC","Bethesda, MD","https://www.linkedin.com/jobs/view/devops-engineer-at-hoplite-solutions-llc-4336082750?position=14&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=SDTG1%2FS%2F5qZr2aOl4RyEhA%3D%3D","Hoplite Solutions is hiring DevOps Engineers at all experience levels to join our team in Bethesda, MD. In this mission-critical role, you will provide essential system support to our customer while collaborating closely with software development teams and other key technology stakeholders. You will help maintain, enhance, and support a range of IC enterprise products‚Äîboth legacy systems and new solutions‚Äîwithin an Agile SAFe environment.

As a DevOps Engineer, you will work hand-in-hand with software engineering teams to deploy and operate systems, automate and optimize processes, and build and maintain tools that support deployment, monitoring, and ongoing operations. You will also troubleshoot and resolve issues across development, test, and production environments, ensuring reliability, efficiency, and continuous improvement across the enterprise.

Primary Responsibilities:


Supports software deployments, cloud infrastructure baselines, and operational availability of production systems
Managing, building, configuring, administering, operating and maintaining all components that comprise the DevOps environment
Defining enterprise Continuous Integration/Continuous Deployment processes and best practices
Codifying DevOps best practices across the enterprise
Developing and maintaining scripts to automate tool deployment to an AWS cloud environment and other tasks
Scripting and maintaining build environments
Working with project teams to integrate their products into the DevOps environment


Basic Qualifications


Demonstrated experience setting up one or more of the following tools: GitHub, Jira, Confluence, Jenkins, and Katalon Studio
Demonstrated experience troubleshooting issues with two or more of the following tools: GitHub, Jira, Confluence, Jenkins, and Katalon Studio
Demonstrated experience working within a software development team and supporting developers and developer activities
Bachelors degree with 4 or more years of prior relevant work experience or Masters with 2 or more years of prior relevant work experience. Will consider additional work experience in lieu of a degree
To be considered must have an active TS/SCI with polygraph security clearance


Preferred Qualifications


AWS Associate Certification (Developer, Solution Architect, or Sys Ops Administrator)
AWS Professional Certification (DevOps Engineer or Solutions Architect)
Demonstrated experience in container orchestration using Docker, Vagrant, Kubernetes, or AWS ECS/ECR
Demonstrated experience with Languages including Java, Python, JavaScript, Ruby, PHP, and Unix shell Scripting
Demonstrated experience with Ansible, or Puppet


Hoplite Solutions offers very competitive salaries and an excellent benefits package, to include a 7% employer 401k contribution, fully paid healthcare for our employees, outstanding training benefits, company funded life insurance and short-term disability insurance, and many more.

Powered by JazzHR

wwBe8pS8mn"
"DevOps Engineer","The Dignify Solutions, LLC","Brooklyn, OH","https://www.linkedin.com/jobs/view/devops-engineer-at-the-dignify-solutions-llc-4341985652?position=15&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=OIkvouN92QSjFYtLnMasfw%3D%3D","Qualifications:


General technical capabilities across all portions of the infrastructure stacks
Independent thinker and self-starter
Generates ideas, innovative
Experienced with automation frameworks using an automation first approach
Proficient in one or more programming/scripting languages (Python, Ansible, etc.)
Proficient with one or more cloud orchestration tools (Terraform, Cloud Formation, etc.)
Conduct performance analysis and optimization
Experienced with public cloud providers such as GCP, Azure and AWS
Comfortable operating in a Linux environment


Preferred Skills:


Public and Private Cloud automation experience in production & non-production environments
Knowledge of web access management technologies and deployments
Knowledge of web access management technologies and deployments
Knowledge of routing & switching technologies and configurations
Knowledge of compute and storage solutions in data center environments
Experience with Service Now change management and problem management platform
Ability to balance workload amidst competing deadlines
Ability to perform knowledge transfers with peer engineers
Contribute to the reliability, performance, supportability, and security of web access management infrastructure
Review procedures for change and configuration management in all environments."
"DevOps Engineer","Verra Mobility","Indianapolis, IN","https://www.linkedin.com/jobs/view/devops-engineer-at-verra-mobility-4339356296?position=16&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=g1l7bZ%2B8160RIZx5GEsCJA%3D%3D","Who we are‚Ä¶

Verra Mobility is a global leader in smart mobility. We develop technology-enabled solutions that help the world move safely and easily. We are fostering the development of safe cities, working with police departments and municipalities to install over 4,000 red-light, speed, and school bus stop arm safety cameras across North America. We are also creating smart roadways, serving the world's largest commercial fleets and rental car companies to manage tolling transactions and violations for over 8.5 million vehicles. And we are a leading provider of connected systems, processing nearly 165 million transactions each year across 50+ individual tolling authorities.

Culture

Verra Mobility Corporation is a rapidly-growing, entrepreneurial company that operates with a people-first philosophy and approach. The company lives by its core values‚ÄîDo What's Right, Lead with Grace, Win Together, and Own It‚Äîin everything it does for its customers and team members. The company seeks to grow aggressively, both organically and through acquisition, to continue to be the undisputed market leader with these five core competencies: bias for action, customer focus, teamwork, drive for results, and commitment to excellence.

Position Overview:

We are seeking an experienced and detail oriented Devops Engineer to join our team. In this role, you will be responsible for creating, maintaining, and securing our Devops pipelines and deployment systems to ensure high levels of performance and availability. This position is ideal for someone with a strong background in CI/CD methodologies particularly in cloud environments.

Essential Responsibilities:


Spend 50% writing automation scripts in Python and Bash.
Write various CI/CD pipelines for code releases.
Ensure that pipelines meet both operations and security requirements.
Partner with developers to identify areas of improvement in the developer experience.
Design and implement innovations that improve software velocity, infrastructure resiliency, security and data availability.
Work with Software and Engineering to ensure new pipelines are created in parallel to code build.
Work with Architecture on setting the path forward and gathering changes to the technology stack.
Ability to respond to system issues, drive and participate in high - priority incident calls and emergency activities outside of standard office hours as needed.
Collaborate with internal and external application, business partners to gain understanding of their business needs and adapt departmental roadmap plans and priorities to address operational challenges.
Work with QE to ensure all automated testing is run during the deployment of the code.
Ability to participate in an on-call rotation as needed.


Qualifications:


Must have 5 years of Devops Engineering experience.
Familiarity with a wide range of systems engineering tools, including source code repository hubs, continuous integration services, issue tracking, test automation, deployment automation, development team collaboration, project management.
Need to have strong scripting skills to create automation in Python preferred or Bash.
Experience with Cloudformation or Terraform for infrastructure as code.
Used continuous integration and continuous development (CI/CD) tools such as Jenkins, Gitlab, or Github Actions, preferred.
Knowledge of DevOps tools such as, GitHub Actions, CloudFormation, GIT, SVN, Jenkins, JIRA, Rally, Greenhopper, Puppet/Chef Vagrant, Selenium, Azure DevOps (for sprint planning).
Understanding of enterprise GIT repositories including branching and forking.
Hands-on Familiarity with AWS CloudWatch, AWS CloudTrail, AWS X-Ray, Grafana, and Prometheus.
Hands-on experience with Veracode and SonarQube are a plus.
Must be located in Phoenix, AZ, Indianapolis, IN, or NY and be willing to commute into office 3 days a week.


This position is not eligible for sponsorship now or in the future and is only considering local Arizona, New York, or Indiana talent.



Verra Mobility Values



An ideal candidate for this role naturally works in alignment with the Verra Mobility Core Values:


Own It. We focus on high performance and drive toward breakthrough outcomes. Our employees ensure accountability, optimize and align work, focus on the customer, and cultivate innovation.
Do What's Right. We champion integrity and good character. Our team members model ethical behavior, demonstrate good judgment and are courageous.
Lead with Grace. We express humility and compassion, and we are authentic and candid. Our employees demonstrate self-awareness, care for others, instill trust, and communicate effectively.
Win Together. We believe in growing and inspiring people together. We seek people who collaborate, value differences, think and act globally, foster an engaging work environment, and recognize and develop others.




With your explicit consent which you provided as part of the application process, we will retain candidate personal data solely for the business purpose for which it was collected. In no event will we retain such data more than two (2) years following the closure of the recruitment process relating to the role for which you applied or in the event other related job opportunities arise within the company. Verra Mobility Applicant Privacy Notice

Verra Mobility is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status."
"DevOps Engineer","Protege","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-protege-4331315574?position=17&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=XLsGNGjq9UZjOgmc1kpzyQ%3D%3D","Company Overview:

We are building Protege to solve the biggest unmet need in AI ‚Äî getting access to the right training data. The process today is time intensive, incredibly expensive, and often ends in failure. The Protege platform facilitates the secure, efficient, and privacy-centric exchange of AI training data.

Solving AI‚Äôs data problem is a generational opportunity. We‚Äôre backed by world-class investors and already powering partnerships with some of the most ambitious teams in AI. The company that succeeds will be one of the largest in AI ‚Äî and in tech.

We‚Äôre a lean, fast-moving, high-trust team of builders who are obsessed with velocity and impact. Our culture is built for people who thrive on ambiguity, own outcomes, and want to shape the future of data and AI.

Key Responsibilities and Scope:


As a DevOps Engineer, you will be a critical part of our engineering team, responsible for safeguarding our AI/ML platforms, data pipelines, and cloud infrastructure
You will implement and develop monitoring strategies, and drive controls to protect our most valuable assets


Qualifications:


4+ years of hands-on experience in a DevOps, Architecture, SecOps or Engineering role
Strong experience with major cloud platforms and building cloud-native services including containerization, threat detection, vulnerability, governance, compliance, etc. with AWS preferred
Proficient in scripting languages like Python, SQL, Typescript or similar
Strong experience with infra‚Äëas‚Äëcode, monitoring, and reliability for pipelines; contributing to platform guardrails, governance, compliance, etc
Experience working with cross-functional partners to develop tools and playbooks for best-practices related to Operations


About You:


You are curious, tenacious, and proactive
You are not bothered by ambiguity but embrace finding patterns in complex environments
Excellent problem-solving skills and adaptability in a dynamic and evolving tech landscape
Excited to work in a company that deals with moving and transforming large volumes of data


Bonus if you have these attributes:


Experience with cloud providers like GCP and Azure
Prior startup experience
Security operations and automation experience"
"Devops Engineer","PDG Consulting","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-pdg-consulting-4321885957?position=18&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=FVf8o0EHKAGfPk8EPYus6A%3D%3D","Overview

We are seeking a DevOps Engineer to set up, manage, and automate software development operations and processes. The ideal candidate will have strong experience in CI/CD pipelines, cloud service management, and infrastructure monitoring to support efficient, secure, and scalable software delivery.

Responsibilities


Design, implement, and manage CI/CD pipelines to streamline software deployment and integration.
Oversee cloud-based systems and infrastructure management, ensuring reliability and performance.
Automate workflows for system administration, documentation, and monitoring.
Support the development and deployment of AI chatbot infrastructures and related frameworks.
Collaborate with developers, QA engineers, and IT teams to optimize the software lifecycle.


Requirements


Minimum 4 years of experience in ICT systems support, including system administration, documentation, and monitoring.
Hands-on experience with cloud platforms, especially Amazon Web Services (AWS).
Proven experience creating and maintaining AI chatbot infrastructures or similar automation frameworks.
Previous experience working within the UN system is an advantage.
Excellent command of English (required).
Knowledge of French and Arabic is considered an advantage.


Powered by JazzHR"
"DevOps Engineer - 100% Remote","The Dignify Solutions, LLC","Newtown Square, PA","https://www.linkedin.com/jobs/view/devops-engineer-100%25-remote-at-the-dignify-solutions-llc-4347005722?position=19&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=8jAprFfGNBnM2BHTcMQLMg%3D%3D","Summary: The main function of a DevOps Engineer is to design, develop, implement, test, and maintain business and computer applications software or specialized utility programs including mainframe and client/server applications, and major enhancement of existing systems

Job Responsibilities: Fine-tune and improve a variety of sophisticated software implementation projects Gather and analyze system requirements, document specifications, and develop software solutions to meet client needs and data Analyze and review enhancement requests and specifications Implement system software and customize to client requirements Prepare the detailed software specifications and test plans Code new programs to client's specifications and create test data for testing Modify existing programs to new standards and conduct unit testing of developed programs Create migration packages for system testing, user testing, and implementation Provide quality assurance reviews Perform post-implementation validation of software and resolve any bugs found during testing


A solid foundation in computer science, with strong competencies in data structures, algorithms, and software design.
Large systems software design and development experience.
Experience performing in-depth troubleshooting and unit testing with both new and legacy production systems.
Experience in programming and experience with problem diagnosis and resolution.
SAC Experience (1-2 YOE)
Ariba ATHENA Report generation (Some experience)"
"CloudOps Engineer","Protera","United States","https://www.linkedin.com/jobs/view/cloudops-engineer-at-protera-4336621571?position=20&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=aPEVL2qitI4%2BRVI7GM1JLw%3D%3D","Summary

As a CloudOps Engineer at Protera, you will play a crucial role in maintaining and optimizing our cloud infrastructure. You will be responsible for monitoring and managing cloud services, ensuring the performance and reliability of our cloud applications, and automating processes to enhance operational efficiency. You will work closely with development teams to improve deployment practices and manage incidents in a fast-paced environment.

Key Responsibilities


Monitor cloud infrastructure performance and reliability to ensure optimal service delivery
Automate deployment processes using Infrastructure as Code (IaC) tools like Terraform
Implement and manage CI/CD pipelines to streamline application releases
Collaborate with development teams to integrate DevOps practices into application lifecycles
Troubleshoot cloud architecture and application issues to ensure minimal downtime
Conduct security assessments and implement best practices to secure cloud environments
Document processes and maintain configurations and operational standards


Requirements

Skills & Qualifications

Experience:


3+ years of experience in cloud operations, DevOps, or system administration


Technical Skills:


Proficient with AWS services and cloud architecture
Experience with Infrastructure as Code (IaC) tools, particularly Terraform
Strong understanding of containerization technologies like Docker and orchestration tools such as Kubernetes
Familiarity with CI/CD tools such as Jenkins, GitLab CI, or similar
Knowledge of monitoring tools and log management solutions
Solid troubleshooting skills across cloud-based systems


Education:


Bachelor's degree in Computer Science, Information Technology, or a related field is preferred


Certifications (Preferred):


AWS Certified Solutions Architect or related cloud certification
DevOps or Kubernetes certifications are a plus


Personal Attributes:


Strong analytical and problem-solving skills
Excellent communication and collaboration skills
Ability to work in a fast-paced environment and handle multiple tasks


About Protera

Protera Technologies (www.protera.com) is a leading provider of total IT outsourcing solutions for SAP-centric organizations. Founded in the mid-1990s, we are pioneers in providing SAP services on the cloud, managing thousands of workloads across various cloud platforms. With headquarters in Chicago and offices in Greece and India, we are committed to delivering exceptional cloud hosting, application management, and professional services globally.

Benefits

Protera offers a variety of health and wellbeing programs. Benefit options include two PPO Medical plans, Dental, Vision, Health Savings Account, Flexible Spending Accounts, Dependent Care FSA, 401k retirement savings plan, company paid Life Insurance, Flexible PTO policy, Paid Holidays."
"DevOps Systems Engineer","TensorWave","Las Vegas, NV","https://www.linkedin.com/jobs/view/devops-systems-engineer-at-tensorwave-4338727303?position=21&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=MD1xhrPb5O0wx%2FPXmQLhCg%3D%3D","At TensorWave, we‚Äôre leading the charge in AI compute, building a versatile cloud platform that‚Äôs driving the next generation of AI innovation. We‚Äôre focused on creating a foundation that empowers cutting-edge advancements in intelligent computing, pushing the boundaries of what‚Äôs possible in the AI landscape.

About The Role

We are seeking a highly skilled DevOps & Infrastructure Management Engineer to join our growing infrastructure team. This role is ideal for someone who thrives in hardware-centric environments, enjoys hands-on datacenter and system administration work, and can build reliable automation around large-scale infrastructure. You will be responsible for managing enterprise hardware, monitoring systems, network operations, infrastructure automation, and supporting our compute clusters across multiple data centers.

This role touches every layer of modern infrastructure‚Äîfrom bare metal provisioning, to OS and Kubernetes management, to monitoring and troubleshooting hardware. If you are detail-oriented, resourceful, and comfortable working with both low-level hardware systems and higher-level DevOps tooling, we‚Äôd love to talk.

Key Responsibilities

Hardware & Infrastructure Management


Manage and maintain enterprise-grade server hardware and infrastructure components.
Utilize out-of-band management systems (iLO, iDRAC, IPMI, Redfish, etc.) for remote operations.
Use automated hardware management tools (BMC/Redfish-based) to streamline provisioning and maintenance.
Perform hardware diagnostics and troubleshooting (CPU, memory, disks, PSUs, NICs, etc.).
Handle vendor interactions, including RMAs, part replacements, and inventory tracking.
Oversee datacenter hardware operations, including racking, cabling, PDU installation, and physical layout.


Datacenter & DCIM


Use Data Center Infrastructure Management (DCIM) tools for inventory, capacity planning, and environmental tracking.
Manage power delivery and consumption across racks and nodes.
Configure and monitor managed PDU systems for power cycling, monitoring, and alerts.
Collaborate with colocation providers on connectivity, power, security, and maintenance tasks.


Monitoring & Observability


Build and maintain infrastructure monitoring and alerting using tools such as Prometheus/Grafana, SNMP, Nagios, CheckMK, or similar platforms.
Implement automated alerting for hardware health, network status, power issues, and service-level metrics.
Create dashboards to give internal teams visibility into system performance and reliability.


Network Operations


Manage and configure firewalls, routing, and network segmentation.
Configure and troubleshoot VPN technologies (IPsec, OpenVPN, WireGuard).
Oversee subnetting, IP address allocation, and network architecture planning.
Configure managed switches, VLANs, port settings, and trunking.
Manage NAT, port forwarding, and related gateway/edge network configurations.


System Administration (Linux)


Install, configure, and manage Linux servers (Ubuntu/Debian preferred).
Perform system-level troubleshooting (boot issues, login problems, service failures).
Manage networking configuration (static IPs, DHCP).
Configure and maintain filesystems: partitioning, MD RAID, ext4/XFS, LVM, resizing/growing volumes.
Implement secure access using public key authentication and proper SSH hardening.
Manage certificates for internal systems, including issuance, revocation, HTTPS installation, and rotation.
Handle basic BIOS configuration relevant to bare metal provisioning or system bring-up.


Bare Metal Provisioning


Deploy and manage hardware provisioning tools such as MAAS, Foreman, or similar systems.
Configure and troubleshoot network boot mechanisms (PXE, UEFI Boot, HTTP Boot).
Automate provisioning pipelines to rapidly bring new nodes online.


Containerization & Orchestration


Work with Kubernetes clusters at a foundational level (cluster access, basic resource troubleshooting).
Deploy workloads using Helm charts and maintain cluster application lifecycle.
Assist with cluster scaling, node replacements, and security hardening.


Automation & Scripting


Write shell scripts (bash) for automation of system tasks, monitoring, or provisioning.
Use CLI tooling such as jq, sed, awk, grep, and rsync.
Optionally automate workflows using languages like Python, Go, PHP, or Perl.


Required Qualifications


Proven experience managing enterprise-grade hardware at scale.
Strong understanding of out-of-band management systems (IPMI/BMC/Redfish).
Hands-on expertise with monitoring systems (Prometheus, Grafana, SNMP, Nagios, CheckMK, or similar).
Solid knowledge of network administration, including firewalls, routing, VPNs, NAT, and managed switches.
Linux system administration experience (installation, configuration, troubleshooting).
Experience with filesystems, RAID, partitioning, and general storage management.
Familiarity with certificate management, key-based auth, and basic cryptographic functions.
Experience with bare metal provisioning (MAAS, Foreman, or similar).
Understanding of PXE/UEFI/HTTP boot systems.
Ability to write functional, maintainable bash scripts for automation.


Nice to Have


Experience with Kubernetes beyond the basics (operators, cluster scaling, CRDs).
Experience with Helm chart customization.
Familiarity with automation languages such as Python, Go, PHP, or Perl.
Previous datacenter operations or colocation management experience.
Exposure to high-availability or distributed compute environments.
Knowledge of infrastructure security and hardening practices.


What We Bring


Stock Options
100% paid Medical, Dental, and Vision insurance
Life and Voluntary Supplemental Insurance
Short Term Disability Insurance
Flexible Spending Account
401(k)
Flexible PTO
Paid Holidays
Parental Leave
Mental Health Benefits through Spring Health"
"DevOps Administrator","The Amatriot Group","Dallas, TX","https://www.linkedin.com/jobs/view/devops-administrator-at-the-amatriot-group-4310974393?position=22&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=JksOKcArCujA8xpxKxxJPg%3D%3D","DevOps Administrator

Salary: $135,000 ‚Äì 170,000

Contract Length: 12-month SOW

Location: Dallas, TX - in-office presence requirement 3 days weekly or more as needed


This represents the potential salary range for this position depending on education level, years of experience and/or certifications in addition to other position specific requirements which may impact salary


We‚Äôre seeking an experienced Administrator to join our Code Management team. The right candidate for this role will lead and execute strategic migrations, optimize CI/CD workflows, and drive infrastructure modernization. They will be critical in moving our automation ecosystem from legacy tools (Jenkins, Bitbucket, Automic) to GitLab, Ansible Automation Platform and Terraform, ensuring robust, scalable, and secure pipelines.

Required Skills And Experience


8+ years of experience in Administering different & complex applications and tools used in the Enterprise
Experience administering GitLab, Artifactory, Xray, & SonarQube
Experience with infrastructure-as-code tools (Terraform, Ansible, etc.)
Solid understanding of containerization (Docker) and orchestration (Kubernetes)
Familiarity with cloud platforms (AWS, Azure, IBM Cloud) and cloud-native tooling
Strong communication skills and a track record of cross-team collaboration
Knowledge of JFrog Artifactory, BitBucket / GIT, SVN and other SCM tools
Working knowledge of different Software Development Lifecycle Methodologies
Knowledge of desired state configuration, automated deployment, continuous integration, and release engineering tools like Puppet, Chef, Jenkins, Bamboo, Maven, Ant etc
Configure and manage GitLab Runners, Groups, Projects, and Permissions at scale
Harden GitLab for enterprise usage (SAML/SSO, LDAP, RBAC, backup/restore)
Design, implement, and optimize complex GitLab CI/CD pipelines using YAML best practices
Leverage Terraform, Ansible, or similar to provision and manage self-hosted GitLab and runners
Implement GitOps practices to manage infrastructure and environment configurations
Automate operational tasks and incident remediation via pipelines and scripts
Partner with application teams to onboard them onto GitLab workflows and best practices
Develop and maintain clear runbooks, wiki pages, and pipeline templates
Integrate monitoring (Prometheus/Grafana, ELK) for GitLab health and pipeline performance
Implement policies and guardrails to ensure code quality, compliance, and security posture
Troubleshoot and resolve CI/CD or migration-related incidents in a timely manner
Available for 24/7 On-call support


Preferred


A BS in Computer Science or equivalent work experience with good scripting/programming skills
GitLab Certified Administrator
Prior software experience with build management, configuration management and/or quality testing
Experience with SCM practices including Agile, continuous integration (CI) and continuous deployment (CD)


Team Culture

Our team is fast paced, fun, highly energetic, motivated and hardworking. We expect our candidates to be integrated into our results-driven and solution-oriented culture from the get-go. Our team attains high-quality results on challenging projects; the belief that outcomes are linked to one's effort rather than chance and the tendency to personally set challenging yet realistic goals."
"DevOps Engineer","Arize AI","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-arize-ai-4332964631?position=23&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=dY4IGRO678a23dhnVYp3qw%3D%3D","About Arize

AI is rapidly transforming the world. As generative AI reshapes industries, teams need powerful ways to monitor, troubleshoot, and optimize their AI systems. That‚Äôs where we come in. Arize AI is the leading AI & Agent Engineering observability and evaluation platform, empowering AI engineers to ship high-performing, reliable agents and applications. From first prototype to production scale, Arize AX unifies build, test, and run in a single workspace‚Äîso teams can ship faster with confidence.

We‚Äôre a Series C company backed by top-tier investors, with over $135M in funding and a rapidly growing customer base of 150+ leading enterprises and Fortune 500 companies. Customers like Booking.com, Uber, Siemens, and PepsiCo leverage Arize to deliver AI that works.

The Team

Our On-Prem engineering team is responsible for the deployment of Arize in customer environments. In addition to working with customers in defining infrastructure requirements, the team designs and develops software and tooling that enables the management of these systems at large scale. The On-Prem team has grown to be expert in Kubernetes and cloud deployment on GCP, Azure, and AWS as well as dealing with networking and security aspects of on-premise deployments. The team is dynamic and relies on few talented individuals with a high degree of autonomy and initiative.

What You‚Äôll Do


Work hands-on with the infrastructure that supports our distributed & highly scalable services in both SaaS and on-prem offerings
Gather requirements from customers and adapt manifests and software to support new environments
Use and augment monitoring tools to observe platform health, ensure performance and reliability
Interact with the product team to test new features and package new on-prem releases
Automate and optimize the release pipeline to make it as frictionless as possible
Exhibit continuous curiosity for emerging technology that could solve our challenges


What will set you apart:


3+ years of experience as a DevOps Engineer, Cloud Engineer, Infrastructure Engineer or similar
Excellent communication skills and ability to work directly with customers to understand and address their infrastructure needs
Experience and fluency in Kubernetes
A self starter with an ability to thrived in a fast paced environment
Experience working with multiple cloud providers (AWS, GCP, Azure) and understanding how to adapt cloud-native architectures for on-premises environments
Strong troubleshooting skills


The estimated annual salary for this role is between $100,000 - $185,000, plus a competitive equity package. Actual compensation is determined based upon a variety of job related factors that may include: transferable work experience, skill sets, and qualifications. Total compensation also includes a comprehensive benefit package, including: medical, dental, vision, 401(k) plan, unlimited paid time off, generous parental leave plan, and others for mental and wellness support.

While we are a remote-first company, we have opened offices in New York City and the San Francisco Bay Area, as an option for those in those cities who wish to work in-person. For all other employees, there is a WFH monthly stipend to pay for co-working spaces.

More About Arize

Arize‚Äôs mission is to make the world‚Äôs AI work‚Äîand work for people.

Our founders came together through a shared frustration: while investments in AI are growing rapidly across every industry, organizations face a critical challenge‚Äîunderstanding whether AI is performing and how to improve it at scale.

Learn more about what we're doing here:

https://techcrunch.com/2025/02/20/arize-ai-hopes-it-has-first-mover-advantage-in-ai-observability/

https://arize.com/blog/arize-ai-raises-70m-series-c-to-build-the-gold-standard-for-ai-evaluation-observability/

Diversity & Inclusion @ Arize

Our company's mission is to make AI work and make AI work for the people, we hope to make an impact in bias industry-wide and that's a big motivator for people who work here. We actively hope that individuals contribute to a good culture


Regularly have chats with industry experts, researchers, and ethicists across the ecosystem to advance the use of responsible AI
Culturally conscious events such as LGBTQ trivia during pride month
We have an active Lady Arizers subgroup"
"DevOps Engineer","Sustainment","Austin, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-sustainment-4335637240?position=24&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=oMmcvMJrVjSze0mKTHDcUg%3D%3D","Company Overview: Sustainment is an AI-native software platform that helps US-based manufacturers easily find and work with the critical suppliers they need to build and manage their supply chains. Our vision is to reimagine American manufacturing as a hyperconnected, secure, and resilient ecosystem of local and regional suppliers who can more easily connect, interact, and do business with the industry and government customers that rely on them. We are a dual-use technology platform that supports both DoD and commercial customers in pursuit of our vision.

Job Overview: We are looking for a DevOps/MLOps Engineer to drive the reliability, scalability, and performance of our AI-native procurement platform. The primary focus of the role is to build and maintain robust infrastructure, automate ML model deployment pipelines, and ensure database performance and reliability. You will be responsible for high-quality, secure deliverables that meet stringent compliance requirements (SOC 2, FedRAMP, CMMC Level 2) and for helping to create, evangelize, and enforce the standards necessary to meet team and company goals for operational excellence and mission-critical uptime.

Responsibilities:


Build partnerships and work collaboratively with engineering, AI, and product teams to meet shared objectives
Operate effectively in ambiguous situations, especially when scaling AI workloads and managing complex infrastructure transitions
Build and optimize DevOps pipelines including ML model training, versioning, deployment, monitoring, and retraining workflows
Administer and optimize PostgreSQL databases including performance tuning, query optimization, backup/recovery, and high availability configurations
Troubleshoot and resolve infrastructure, database, and pipeline issues in a resilient, performant manner
Implement and maintain infrastructure as code using tools like Terraform or Cloudformation
Monitor system health, performance, and database metrics using observability tools and respond to alerts proactively
Ensure security best practices and compliance requirements are met across all infrastructure and database layers
Participate in multi-resource projects in an agile environment
Evaluate and recommend industry standards, tools, and methods for DevOps, MLOps, and database management
Document infrastructure architecture, runbooks, and contribute to architecture reviews


Qualifications:


Bachelor's degree (computer science, engineering, or related) or equivalent work experience
2+ years of experience with cloud infrastructure (AWS preferred), container orchestration (Kubernetes), and CI/CD tools
2+ years of database administration experience with PostgreSQL or similar relational databases
Experience with ML model deployment, monitoring, and lifecycle management (MLOps)
Strong understanding of infrastructure as code (Terraform), GitOps practices, and declarative configuration management
Experience with security compliance frameworks (SOC 2, FedRAMP, or CMMC is a plus)
Product-driven mindset with deep empathy for internal developer experience and system reliability
Strong desire to work in a startup with interest to take on projects from zero to one with collaboration with the rest of the team
Love working hard and enjoy a fast-paced, ambiguous environment
Experience with distributed systems, microservices architecture, and reactive systems
Open mindset to exploring new tools and frameworks in the rapidly evolving DevOps/MLOps landscape
Passion for operational excellence and automation
Experience supporting cross-team efforts to roll out new infrastructure capabilities or ML features
Passion for learning and continuous improvement
Strong written and verbal communication skills, and ability to explain complex technical concepts
Experience working in a Scrum/agile environment
Experience with AWS GovCloud, defense/government sector compliance, or working in an early startup environment on SaaS products is a plus


Core Technologies:


AWS (including GovCloud), Kubernetes, Docker, Terraform
PostgreSQL
GitLab CI/CD, ArgoCD, Tilt
Model versioning, experiment tracking, ML pipeline orchestration
Datadog, CloudWatch
Python, Bash, experience with .NET ecosystem a plus
IAM, secrets management, encryption, audit logging, compliance automation


Sustainment offers a competitive benefits package for full time employees including medical, dental, vision, paid time off, company holidays, and 401K matching.

Sustainment is proud to be an equal opportunity employer. We provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, veteran status, or any other protected class.

Applicants must be authorized to work for ANY employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time.

Sustainment participates in E-Verify."
"Devops","The Dignify Solutions, LLC","Phoenix, AZ","https://www.linkedin.com/jobs/view/devops-at-the-dignify-solutions-llc-4347025595?position=25&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=ce%2FoReYTlt5dTX23pQI90g%3D%3D","Must have is


Associate should be in Phoenix from day 1 of the project
At least 5 years of experience in Devops area.
Strong skill in CI/CD pipeline, Jenkins, Github
Additional knowledge on any build related tools is an added advantage.


Java 8 knowledge

Docker

Kaffka

Kibana"
"DevOps Engineer I","Trustwell","Portland, OR","https://www.linkedin.com/jobs/view/devops-engineer-i-at-trustwell-4321600458?position=26&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=ulG1HPjSCU5dZ4lcM3Sw5w%3D%3D","Role{{:}} DevOps Engineer I

FLSA{{:}} Full Time | Exempt | Salaried | Remote

Reports to{{:}} Director of DevOps

Note{{:}} Candidate preferred to reside in PST. If not, candidate will be required to support PST working hours.

Trustwell is looking for ambitious, energetic problem-solvers who enjoy a fast-paced team environment filled with challenges and career growth opportunities in a rapidly growing tech firm. Trustwell is on a mission to change the food industry. Combining FoodLogiQ's supply chain management software with Genesis' nutritional analysis and label development solution, the Trustwell Connect platform creates the food industry's only full-scale solution connecting product development and regulatory-compliant labeling with supplier compliance, enhanced traceability, and automated recall management. From food and supplement manufacturers to retail grocers and restaurant chains, more than 2,500 food companies around the world use Trustwell software as their trusted source for compliance and quality solutions in the food industry. For more information, visit www.trustwell.com.

Scope of Position{{:}} The DevOps Engineer I will be part of a dynamic and agile team responsible for building and maintaining the platforms, systems, and services that power our customer-facing products. Working closely with Software Engineers and Engineering Leadership, you'll help shape architecture, implement best practices, and stay ahead of the curve in DevOps principles. You'll champion operational excellence and continuous improvement across the team.

Essential Duties & Responsibilities include but not limited to{{:}}


Contribute actively to an Agile delivery team, ensuring consistent, high-quality, and reliable software releases.
Collaborate closely with developers and cross-functional partners to design, build, and deploy best-in-class, scalable software solutions.
Champion an automation-first, code-centric mindset, driving efficiency and consistency across deployment, monitoring, and maintenance processes.
Support production operations through participation in incident response, troubleshooting, and on-call rotations to maintain system reliability and uptime.
Develop, implement, and maintain monitoring and alerting tools to ensure optimal application performance, health, and availability.
Design infrastructure and deployment solutions with scalability, resilience, and long-term maintainability as core principles‚Äîavoiding short-term workarounds.
Proactively identify and eliminate operational bottlenecks and unnecessary complexity, contributing to continuous improvement initiatives.
Engage in architectural reviews and solution design discussions, providing input that enhances performance, reliability, and security.
Perform other related duties as assigned, contributing to the overall success of the DevOps function and technology organization.


Education/Experience{{:}}


Bachelor's degree in Computer Science, Engineering, or a related field required. Will consider relevant experience/certifications in lieu of degree.
2+ years of experience in an SRE (Site Reliability Engineer) or equivalent engineering role
2+ years of experience as a DevOps Engineer or in a similar capacity
3+ years of hands-on experience managing and supporting production cloud environments (AWS, Azure, or GCP)
Extensive experience with DataDog, including APM, RUM, Synthetic Monitoring, Infrastructure Monitoring, and Dashboard development


Required Skills/Abilities{{:}}


Strong, hands-on experience with Infrastructure-as-Code (IaC) and configuration management tools such as Terraform, CloudFormation, and/or Ansible
Proven experience designing and managing cloud architectures in AWS and Microsoft Azure, with expertise in containerization and orchestration (Docker, Kubernetes, etc.)
Demonstrated experience building, maintaining, and optimizing CI/CD pipelines using tools such as CircleCI, TeamCity, GitHub Actions, or Jenkins
Background in delivering infrastructure initiatives within an Agile development environment
Collaborative mindset with the ability to partner effectively across cross-functional teams to achieve shared goals
Strong ""automation-first"" mindset with a focus on scalability, reliability, and efficiency


Total Rewards Package{{:}}


Full healthcare benefits, including medical, dental, and vision.
Supplemental benefits, including STD, LTD, HSA, 401k, etc.
Responsible Time Off (PTO) + Holiday Pay
Excellent culture, growth opportunities, plus much more...


What to expect - the Hiring Process!


Interview with Human Resources
Interview with Hiring Manager
Peer Panel Interview(s)
Offer of Employment (Background Screening/References)


Hiring Eligibility{{:}} This is a fully remote position open to candidates located anywhere within the United States. Eligibility to work remotely is subject to company policy and applicable state laws. Candidates must have work authorization to work for any U.S. based employer. Please note that certain benefits, taxes, or employment terms may vary by state.

Compensation{{:}} The compensation for this position starts at $80,000 per annum, with the potential for higher placement based on a candidate's experience, education, and overall qualifications. In addition to base salary, this role is bonus eligible‚Äîup to 10% annually, contingent on company performance and achievement of organizational objectives.

Trustwell is an equal employment opportunity employer committed to hiring and retaining a diverse workforce. Applicants receive fair and impartial consideration without regard to race, sex, sexual orientation, gender identity, color, religion, national origin, age, disability, veteran status, religion, or other legally protected class. If you need accommodation for any part of the employment process due to a medical condition, or any disability, please contact a member of our human resources team.

Acceptable Background and References Required; Upon any conditional offers made by Trustwell.

Equal Opportunity Employer/ DFWP/ Affirmative Action"
"DevOps Engineer","OVA.Work","Alpharetta, GA","https://www.linkedin.com/jobs/view/devops-engineer-at-ova-work-4338475165?position=27&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=0OJH81O8zlAtsvYYki8qRA%3D%3D","Job Title: DevOps Engineer

Location: Remote

Employment Type: Full-Time

Job Summary

We are looking for a skilled DevOps Engineer to join our technology team. The ideal candidate will design, implement, and manage CI/CD pipelines, automate infrastructure, and ensure smooth deployment processes across development and production environments. This role requires strong knowledge of cloud platforms, containerization, and scripting.

Key Responsibilities


Design, build, and maintain CI/CD pipelines for application deployment.
Automate infrastructure provisioning using tools like Terraform or Ansible.
Manage containerized environments using Docker and Kubernetes.
Monitor system performance and implement proactive solutions for scalability and reliability.
Collaborate with development and operations teams to streamline workflows.
Ensure security and compliance in cloud and on-prem environments.
Troubleshoot and resolve issues in production and staging environments.


Qualifications


Bachelor's degree in Computer Science, Engineering, or related field.
25 years of experience in DevOps or related roles.
Proficiency in cloud platforms (AWS, Azure, GCP).
Hands-on experience with CI/CD tools (Jenkins, GitLab CI, GitHub Actions).
Strong knowledge of containerization (Docker, Kubernetes).
Familiarity with Infrastructure as Code (Terraform, Ansible).
Scripting skills in Python, Bash, or similar languages.


Preferred Skills


Experience with monitoring tools (Prometheus, Grafana).
Knowledge of security best practices in DevOps.
Familiarity with microservices architecture.


Benefits


Competitive salary and performance bonuses.
Health insurance and retirement plans.
Flexible work options and professional development opportunities."
"DevOps Engineer (JIRA)","Rubix Solutions","Washington, DC","https://www.linkedin.com/jobs/view/devops-engineer-jira-at-rubix-solutions-4335995983?position=28&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=44llbql724e3TZr%2F1o2aBA%3D%3D","The DevOps Engineer (specifically Jira Platform Engineer) will serve as the technical owner of our Jira SaaS in government cloud, and is responsible for administering, configuring, and integrating the application within our enterprise technology ecosystem. This position plays a pivotal role in consolidating our collaborative planning tools‚Äîtransitioning from Azure DevOps (on-prem) and GitLab (on-prem) to Jira‚Äîwhile enabling and scaling Agile practices across the organization.

The ideal candidate is both technically proficient and strategically minded, with a strong understanding of Agile methodologies, DevSecOps workflows, and enterprise system

integration.

Responsibilities


Administer, configure, and optimize Jira SaaS to meet enterprise project management and Agile delivery needs.
Design and maintain custom workflows, issue types, screens, fields, and automation rules aligned with organizational Agile frameworks and guidelines.
Manage user permissions, group roles, and security schemes to ensure governance and compliance.
Monitor Jira license utilization, user growth, and application usage to ensure efficient use of subscriptions.
Collaborate with procurement teams to support renewal, optimization, and budget decisions.
Design, implement, and maintain seamless integrations between Jira with other enterprise systems, such as GitLab (source control & CI/CD), and ServiceNow (ITSM), using Okta,REST APIs, webhooks, middleware, and scripting.
Automate data synchronization across platforms to support traceability from planning to release.
Troubleshoot and optimize integration pipelines to ensure performance, security, and Scalability.
Partner with infrastructure and cybersecurity teams to align integrations with enterprise security and compliance standards.
Develop and maintain technical documentation, standards, and best practices.
Partner with the Agile Transformation Office to translate Agile practices into effective Jira configurations and usage patterns.
Provide technical guidance and mentoring to Scrum Masters, Product Owners, and teams on best-practice tool utilization.
Support reporting and analytics initiatives, ensuring reliable Agile metrics (velocity, burndown, cycle time, etc.).


Requirements


Must be able to obtain and maintain Moderate Risk Public Trust (MRPT) facility credentials/authorization. Note: US Citizenship is required for MRPT facility credentials/authorization at this work location.
Bachelor‚Äôs degree in Computer Science, Information Systems, or a related field (or equivalent experience).
3+ years of hands-on experience administering and/or engineering Jira (Self-hosting or SaaS).
Proven, hands-on experience developing custom integrations with enterprise platforms, especially GitLab and ServiceNow.
Proficiency in scripting (Python, PowerShell, or JavaScript) and REST API integration.
Strong understanding of Agile methodologies (Scrum, Kanban, SAFe) and DevSecOps principles.
Experience in enterprise migrations from Azure DevOps or similar tools to Jira.
Familiarity with Atlassian ecosystem (Confluence, Bitbucket) and marketplace apps.
Experience working in a DevSecOps or Platform Engineering environment.
Experience with information security, privacy, and risk assessment standards including FISMA, SOX, FedRAMP, etc. is preferred.
Federal government experience is preferred.
Atlassian Certified Professional (ACP-620, ACP-120, or equivalent) preferred."
"DevOps Engineer","Chartmetric","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-chartmetric-4291046434?position=29&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=Qc5sYwffI5j1898EaaRwMw%3D%3D","About Chartmetric

Chartmetric, Inc. is a 10-year-old startup specializing in music data analytics. We are trusted by Universal MusicGroup, Sony, Warner, and Apple Music, as well as hundreds of other music companies and industry professionals. Our team has created a self-service data dashboard for the music industry to better understand the activity happening around artists. Together, we combine hundreds of thousands of real-time data points across iTunes, Spotify, YouTube, Google, Amazon, X, and others through our beautifully designed tool in order to make sense of the increasingly complex landscape of the music industry.

About The Role


We are seeking a talented DevOps / Developer Experience Engineer to join our team and play a pivotal role in enhancing our development infrastructure and streamlining the developer workflow. This position combines traditional DevOps responsibilities with a focus on creating exceptional developer experiences through tooling, automation, and process optimization.


What You'll Do


Infrastructure & Operations
Design, implement, and maintain scalable cloud infrastructure using Infrastructure as Code (IaC) principles
Manage CI/CD pipelines and deployment processes across multiple environments
Monitor system performance, reliability, and security, implementing proactive solutions
Automate operational tasks and eliminate manual toil through scripting and tooling
Ensure high availability and disaster recovery capabilities


Developer Experience
Build and maintain internal developer tools and platforms that improve productivity
Streamline onboarding processes for new developers and reduce time-to-first-commit
Design and implement developer-friendly APIs, SDKs, and documentation
Create self-service capabilities that reduce dependencies and waiting times
Gather feedback from development teams and iterate on tooling based on pain points


Collaboration & Process Improvement
Work closely with engineering teams to understand workflow challenges and requirements
Champion best practices for code deployment, testing, and monitoring
Lead initiatives to improve development velocity and reduce friction
Participate in incident response and post-mortem analysis
Mentor team members on DevOps practices and tooling

What We're Looking For


Technical Skills
3+ years of experience in DevOps, SRE, or Platform Engineering roles
Strong proficiency with cloud platforms (AWS, GCP, or Azure)
Experience with Infrastructure as Code tools (Terraform, CloudFormation, or Pulumi)
Hands-on experience with containerization (Docker) and orchestration (Kubernetes)
Proficiency in CI/CD tools (Jenkins, GitLab CI, GitHub Actions, or similar)
Strong scripting skills in Python, Bash, or Go
Experience with monitoring and observability tools (Prometheus, Grafana, ELK stack, or similar)


Developer Experience Focus
Experience building internal tools and platforms for development teams
Understanding of software development lifecycle and common developer pain points
Familiarity with API design and developer-facing documentation
Experience with version control systems and Git workflows
Knowledge of testing frameworks and quality assurance processes


Soft Skills
Strong problem-solving abilities and analytical thinking
Excellent communication skills and ability to work with cross-functional teams
Customer-focused mindset with emphasis on developer productivity
Proactive approach to identifying and resolving issues
Ability to balance technical debt with feature delivery


Preferred Qualifications
Knowledge of security best practices and compliance frameworks
Background in software development or engineering
Familiarity with cost optimization strategies for cloud infrastructure
Previous experience in a high-growth or scaling environment

What We Offer


Competitive salary and equity package
Comprehensive health, dental, and vision insurance
Opportunity to shape developer experience across the organization
Access to cutting-edge tools and technologies


Team Culture


We believe that great developer experiences lead to better products and happier teams. Our DevOps/DX team operates as enablers and force multipliers, working collaboratively to remove friction from the development process. We value automation, measurement, and continuous improvement, always asking ""how can we make this better for our developers?""


The Pay Range For This Role Is

135,000 - 165,000 USD per year(San Mateo)

120,000 - 150,000 USD per year(New York)"
"DevOps Engineer","Broad Reach Partners","Alpharetta, GA","https://www.linkedin.com/jobs/view/devops-engineer-at-broad-reach-partners-4303987210?position=30&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=7H%2FzhrS%2FCLfPsBUshtgFHQ%3D%3D","We are seeking a Senior DevOps Engineer to join our team and play a critical role in designing, building, and optimizing the CI/CD pipelines that power our software delivery across on-prem and cloud environments.

In this role, you will work hand-in-hand with our development, operations, and security teams worldwide to implement best practices, automate deployments, and ensure our platforms are reliable, secure, and scalable. If you thrive on solving complex technical challenges, have a passion for automation, and want to influence how enterprise platforms evolve and modernize, this is an ideal opportunity for you.

As a Senior DevOps Engineer, your expertise will drive the continuous integration, delivery, and deployment (CI/CD) pipelines delivering software to both on-prem and cloud (AWS primarily) environments. You will work closely with our development, operations, and security teams distributed across the globe. This role requires a deep understanding of DevSecOps best practices and a strong ability to troubleshoot complex issues.

Your Responsibilities In This Role Will Include


Design, Develop and Maintain automated build and deployment pipelines using GitLab/GitHub/Jenkins to enhance software delivery.
Identify opportunities for automation and ensure continuous security, quality in application development by automating security checks, test executions in build and deployment pipelines.
Deploy and manage Kubernetes workloads to AWS EKS(A) using Helm, ArgoCD
Collaborate with development, operations and security team to build secure, optimized and efficient pipelines.
Create comprehensive documentation on pipeline functionality and provide training to required members.
Proactively monitor system performance and identify potential issues before they become critical.
Participate in on-call rotation.
Engage in continuous learning and actively advocate for Dev(Sec)Ops, GitOps best practices and standards across the team.


We are looking for you to have the following skills and experience:


8+ years of experience as a DevOps Engineer, Site Reliability Engineer, or equivalent
Strong knowledge of DevOps practices, continuous integration, continuous delivery, and related tools.
3+ years of experience with Amazon Web Services (AWS) or Microsoft Azure
3+ years of experience with Kubernetes clusters
Proficiency with public cloud environments (AWS preferred)
Experience with tools like New Relic and Graylog
Advanced proficiency working with CI/CD pipelines such as GitHub Actions/GitLab/Jenkins
Expert in containerization technologies such as Docker and orchestration tools like Kubernetes.
Proficiency in scripting language, like Bash, Groovy, Python
Excellent debugging and troubleshooting skills.
Ability to prioritize tasks efficiently and independently under minimal supervision.


Nice to Have


AWS Cloud certification
Familiar with .NET applications.
Knowledge in Terraform, Ansible, monitoring tools


We are located in the Alpharetta/Cumming area of Atlanta and are working in the office several days each week so YOU MUST LIVE WITHIN COMMUTING DISTANCE OF ALPHARETTA, GA to be considered for this role. We cannot sponsor at this time.

If this opportunity is a good match for your skills, experience and interest, please apply now so we can follow up with you with more details."
"AWS DevOps Specialist","Focus School Software","St. Petersburg, FL","https://www.linkedin.com/jobs/view/aws-devops-specialist-at-focus-school-software-4333597594?position=31&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=ZWjo%2BzvVD2P2SHlsBozjUQ%3D%3D","Focus School Software is a fast-growing school management software company. We thrive on creating some of the most innovative features on the market today, helping educators to meet their evolving needs in classrooms, district management, state reporting compliance, and other facets of student-centered education and technology.

We are seeking an experienced and proactive AWS DevOps Specialist to join our growing infrastructure team. This role is ideal for someone passionate about automation, cloud infrastructure, and scalable, secure systems. The ideal candidate brings expertise in AWS services, infrastructure as code, cost reduction strategies and DevOps best practices. You will play a key role in improving system performance, reliability, and security, while contributing to CI/CD pipelines and participating in an on-call rotation. This is a great opportunity for anyone who has a multitude of skills in DevOps and System Administration and can wear many hats and loves problem solving.

Key Responsibilities


Automation & Configuration Management
Design, develop, and maintain automation using Ansible and Ansible Tower.
Deploy and configure RHEL based systems.
Database maintenance and performance, routing, pooling and role management.


Cloud Infrastructure (AWS)


Architect and manage services including RDS (PostgreSQL), EC2, EKS, CloudFormation, CloudFront, GuardDuty, AWS VPN, AWS AD, and more.
Implement Autoscaling strategies and container orchestration with EC2 Autoscaling or EKS. Continuously monitor performance and feedback on systems.
Monitor and improve database performance, sharding strategies, and health metrics.
Monitor backups and maintain recovery point objectives for disaster recovery.


Security & Compliance


Support SOC II compliance initiatives through infrastructure hardening, monitoring, and alerting.
Leverage AWS security tools and best practices to ensure compliance and threat mitigation.


Networking & Connectivity


Manage VPCs, subnets, security groups, VPNs, and endpoint connectivity for both internal and external integrations.
Managing routes, DNS and VPN connectivity. Help internal users maintain their VPN connections.
Cost Optimization
Analyze AWS billing, usage reports, and recommend cost-saving strategies.


DevOps & CI/CD


Build and maintain CI/CD pipelines, enabling delivery of automation code from development to production.
Ensure high availability and zero-downtime deployments through automation and best practices.
Develop and maintain local dev environments for developers.


Collaboration & Culture


Work cooperatively in cross-functional teams, embracing a culture where the best ideas win.
Proactively identify infrastructure problems and lead with creative, scalable solutions.


Endpoint & Systems Management


Oversee and manage end-user systems and infrastructure endpoints to maintain security and stability.
Patch management and remediation, ensure established timelines and policies are followed.


On-Call Participation


Participate in an on-call rotation to respond to production incidents and infrastructure issues.


Requirements


Ansible, Ansible Tower, working in RHEL based environments.
Linux/RHEL expert, be able to design, deploy and fix everything from a systemd service to managing SFTP.
Ability to manage a Git repository, and perform peer review on automation code.
Monitoring tools such as Splunk, Grafana or similar.
Working knowledge of NGINX, basic webserver stacks.
Understanding of AWS, particularly RDS (PostgreSQL), CloudFormation, EC2, EKS
Kubernetes and containerization
Experience with database sharding and performance tuning
CI/CD pipeline design and implementation
Familiarity with SOC II compliance frameworks
Experience managing AWS networking, VPNs, and AWS AD
Security-first mindset with experience using AWS Org, AWS Tower, CloudFront, and related tools to ensure compliance.
Strong interpersonal skills with a collaborative mindset.


Nice-to-Have


LAMP/LNPP Stack experience
SVN Familiarity
Active Directory experience, basic Windows management
Experience with endpoint management platforms
Background in proactive monitoring/observability tooling
Prior involvement in security audits or compliance initiatives


Focus School Software‚Äôs compensation package offers the following benefits:


Medical Insurance
Dental/Vision Insurance
Life Insurance
Short and Long Term Disability Insurance
401(k) after 6 months
Paid Holidays
Paid Vacation and Sick Time
Remote Position"
"DevOps Engineer","Rain","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-rain-4318510257?position=32&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=8eZNlx304T4xDlWSQxyR%2Bg%3D%3D","Rain is empowering the next generation of money and financial products globally. We‚Äôre a lean and mighty team of passionate builders and veteran founders. We are looking for a DevOps engineer to join us in building a cutting edge platform at the intersection of real-world payments and digital money. You will have the opportunity to deliver massive impact at a small and quickly growing company that is funded by some of the top investors in fintech and crypto. Rain is backed by great investors including Lightspeed, Norwest, Khosla, along with great companies like Coinbase, Circle, and Uniswap.

Many of our engineers are based in NYC but we are open to fully remote candidates.

Our Ethos

We believe in an open and flat structure. You will be able to grow into the role that most aligns with your goals. Our team members at all levels have the freedom to explore ideas and impact the roadmap and vision of our company.

What You'll Do


Be a critical part of the technical infrastructure roadmap
Manage our cloud environments across GCP and AWS
Scale our infrastructure to millions of end users globally
Help drive the architectural decisions of a rapidly evolving product
Lead the creation and maintenance of our CI/CD pipelines to enable rapid, reliable deployments
Collaborate with the engineering team to improve infrastructure performance
Build infrastructure to interact with millions of smart contracts across dozens of blockchains
Automate security controls and compliance processes to protect sensitive financial data


What We're Looking For


Strong experience with Infrastructure as Code, particularly Terraform, for managing cloud resources at scale
Proven track record designing and implementing CI/CD pipelines and automation workflows
Experience managing production environments in cloud providers
Experience with monitoring, logging, and observability tools


Nice to haves, but not mandatory


Experience in fintech (neobank or card issuing experience gets extra brownie points)
Experience with blockchain infrastructure


Our perks enable working at Rain to be a fulfilling, healthy and happy experience.

Unlimited time off üõº Unlimited vacation can be daunting, so at Rain we require our teammates to take 10 days minimum for themselves.

Flexible working ‚òï We support a flexible workplace, if you feel comfortable at home please work from home. If you‚Äôd like to work with others in an office feel free to come in. We want everyone to be able to work in the environment in which they are their most confident and productive selves.

Flexible Benefits üß† Easy-to-access benefits, for all employees based in the US, Rain pays a percentage of your benefits for the employee and for your dependents. We offer comprehensive health, dental and vision plans as well as a 100% company-subsidized life insurance plan.

Equity plan üì¶ On top of a competitive salary, we offer every Rain employee an equity option plan so we can all can benefit from our success.

Rain Cards üåßÔ∏è We want our teammates to be knowledgeable about our core products and services and to support this mission we issue a card for our team to utilize the card for testing.

Health and Wellness üìö High performance begins from within. Our members are welcome to use their company card for eligible health and wellness spending like gym memberships, fitness classes and other wellness items.

Team summits ‚ú® Summits play an important role at Rain! Time spent together helps us get to know each other, strengthen our relationships, and build a common destiny. Stay tuned for upcoming destinations!"
"DevOps Engineer","Jasper","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-jasper-4318500931?position=33&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=RpsroDHV7fv9IwKXOTGPxQ%3D%3D","Jasper is the leading AI marketing platform, enabling the world's most innovative companies to reimagine their end-to-end marketing workflows and drive higher ROI through increased brand consistency, efficiency, and personalization at scale.

Jasper has been recognized as ""one of the Top 15 Most Innovative AI Companies of 2024"" by Fast Company and is trusted by nearly 20% of the Fortune 500 ‚Äì including Prudential, Ulta Beauty, and Wayfair. Founded in 2021, Jasper is a remote-first organization with team members across the US, France, and Australia.

About The Role

We're looking for an experienced DevOps Engineer to join our Platform team. This is a highly autonomous, high-impact role that blends Ops practices, infrastructure engineering, and delivery pipeline optimization. You'll work with a focused, collaborative, and fast-moving team where your contributions will directly impact system reliability, developer velocity, and our ability to safely deliver AI-powered products at scale. Candidates should also have a solid background in Cloud, IaC, and Kubernetes, and a drive to produce excellent solutions for a variety of challenges.

This fully remote role reports to the Staff Dev Ops Engineer and is open to candidates located anywhere in the continental US.

What You‚Äôll Do


Design, implement, and operate cloud-native infrastructure that scales efficiently, fails gracefully, and optimizes for performance and cost.
Build and refine software delivery pipelines to enable safe, fast, and frequent deployments with robust testing, rollback, and progressive release mechanisms.
Develop infrastructure-as-code solutions using Terraform and Helm to create self-healing, automated, and observable systems.
Collaborate with ML and product teams to support AI model training and inference through scalable compute and storage infrastructure.
Identify and eliminate single points of failure, performance bottlenecks, and scalability limits through proactive monitoring and reliability engineering practices.
Implement and enforce security best practices, including secrets management, access control, and compliance across all infrastructure layers.


What You‚Äôll Bring


Deep experience running Kubernetes in production (cluster management, networking, storage, security).
Expertise with Terraform, Helm, and configuration management to build reproducible, version-controlled infrastructure.
Proven success designing and maintaining CI/CD pipelines (GitHub Actions, Argo CD, Jenkins, etc.) balancing speed and safety.
Strong background in observability (especially Datadog) ‚Äî skilled at instrumentation, dashboard creation, and intelligent alerting.
Solid scripting skills in Python, Go, or Bash, with a focus on automation and operational efficiency.
Practical knowledge of Google Cloud Platform and cloud-native architectures.
Experience supporting multi-language environments (TypeScript, Python, Go) and AI/ML workloads, including GPU-based compute.
Familiarity with container security, secrets management, and policy enforcement.
(Bonus) History of open source contributions in infrastructure, CI/CD, or observability projects.


Compensation Range

At Jasper, we believe in pay transparency and are committed to providing our employees and candidates with access to information about our compensation practices. The expected base salary range offered for this role is $170,000 - $200,000. Compensation may vary based on relevant experience, skills, competencies, and certifications.

Benefits & Perks


Comprehensive Health, Dental, and Vision coverage beginning on the first day for employees and their families
401(k) program with up to 2% company matching
Equity grant participation
Flexible PTO with a FlexExperience budget ($900 annually) to help you make the most of your time away from work
FlexWellness program ($1,800 annually) to help support your personal health goals
Generous budget for home office set up
$1,500 annual learning and development stipend
16 weeks of paid parental leave


Our goal is to be a diverse workforce that is representative at all job levels as we know the more inclusive we are, the better our product will be. We are committed to celebrating and supporting our differences and that diversity is essential to innovation and makes us better able to serve our customers. We hire people of all levels and backgrounds who are excited to learn and develop their skills.

We are an equal opportunity employer. Applicants will not be discriminated against because of race, color, creed, sex, sexual orientation, gender identity or expression, age, religion, national origin, citizenship status, disability, ancestry, marital status, veteran status, medical condition, or any protected category prohibited by local, state or federal laws.

By submitting this application, you acknowledge that you have reviewed and agree to Jasper's CCPA Notice to Candidates, available at legal.jasper.ai/#ccpa."
"DevOps / Systems Engineer","Collate","San Francisco, CA","https://www.linkedin.com/jobs/view/devops-systems-engineer-at-collate-4302854141?position=34&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=sVfStPLkpJJQG0HBPuEguw%3D%3D","About Collate

Collate is an AI document generation platform for life sciences. We automate paperwork with AI, helping our customers get life-saving innovations to patients years faster. Collate is an end-to-end solution, powering every step of drug, diagnostic, and medical device development‚Äîfrom concept to market.

Our CEO Surbhi Sarna is a former General Partner at Y Combinator. Surbhi founded nVision Medical, which developed a new method to detect ovarian cancer and was acquired by Boston Scientific. Our CTO Nate Smith is a former Visiting Partner at Y Combinator and founder of Lever. Our AI researchers, engineers, and designers have worked at Google, Nvidia, Meta, Netflix, Amazon, AirBnB, Hippocratic AI, and Grail, and 40% of our team are former founders.

We‚Äôre a small, elite team, with over $30M in seed funding from top investors (Redpoint, First Round Capital, Conviction, and Y Combinator) and leaders in healthcare and AI. This is a rare chance to join at the ground floor of a company with world-changing potential, experienced founders, and resources to execute at scale.

About The Role

We‚Äôre looking for a DevOps / Systems Engineer to own the infrastructure that powers Collate‚Äôs products. You‚Äôll build the systems and tooling that keep our platform reliable, secure, and fast as we scale.

This role is broad by design ‚Äî from managing CI/CD pipelines and cloud infrastructure to handling light security responsibilities like certificate management. You‚Äôll partner closely with backend, AI, and product engineers to ensure our systems are both easy to develop on and safe to deploy at scale.

At Collate, infrastructure isn‚Äôt just about uptime ‚Äî it‚Äôs about trust. The work you do will help ensure that the AI we build for healthcare runs with reliability and security in mind.

What You‚Äôll Do


Design and maintain cloud infrastructure to support Collate‚Äôs products as we grow from prototypes to production scale
Develop CI/CD pipelines and automation that accelerate developer velocity and reduce operational friction
Manage core system reliability, including monitoring, logging, and incident response
Take on light security responsibilities, such as handling certificates, secrets management, and supporting compliance needs
Collaborate closely with engineering teams to design infrastructure that balances speed, safety, and scale
Continuously improve internal tooling and workflows, helping the team move faster with confidence
Leverage tooling including AWS, Terraform, Kubernetes, Helm, ArgoCD, Grafana, and Github Actions



What We‚Äôre Looking For


Hands-on experience with cloud infrastructure (AWS, GCP, or similar) and modern DevOps practices
Proficiency with infrastructure-as-code and CI/CD tooling
Familiarity with monitoring, observability, and incident management
Interest or experience in light security work, including certificates, secrets management, or compliance support
A pragmatic approach: able to balance iteration speed with building for long-term reliability
Motivation to work in an early-stage startup where your infrastructure decisions shape the foundation of the company



Why Join Collate?

Impact: Build systems and experiences that touch real patients and providers, improving healthcare outcomes.

Ownership: Shape both our product experience and our engineering culture from the start.

Learning: Collaborate with a uniquely interdisciplinary team‚ÄîAI researchers, healthcare leaders, and experienced startup builders.

Upside: Join a company early enough to have meaningful equity and career-defining impact.

The base salary range for this role is $150,000‚Äì$300,000 USD annually, depending on experience and level (Tier 1, San Francisco)

We may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us."
"DevOps Engineer","Chartmetric","San Mateo, CA","https://www.linkedin.com/jobs/view/devops-engineer-at-chartmetric-4304688090?position=35&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=I1B106Ch8oTK2yMktbF4jA%3D%3D","About Chartmetric

Chartmetric, Inc. is a 10-year-old startup specializing in music data analytics. We are trusted by Universal MusicGroup, Sony, Warner, and Apple Music, as well as hundreds of other music companies and industry professionals. Our team has created a self-service data dashboard for the music industry to better understand the activity happening around artists. Together, we combine hundreds of thousands of real-time data points across iTunes, Spotify, YouTube, Google, Amazon, X, and others through our beautifully designed tool in order to make sense of the increasingly complex landscape of the music industry.

About The Role


We are seeking a talented DevOps / Developer Experience Engineer to join our team and play a pivotal role in enhancing our development infrastructure and streamlining the developer workflow. This position combines traditional DevOps responsibilities with a focus on creating exceptional developer experiences through tooling, automation, and process optimization.


What You'll Do


Infrastructure & Operations
Design, implement, and maintain scalable cloud infrastructure using Infrastructure as Code (IaC) principles
Manage CI/CD pipelines and deployment processes across multiple environments
Monitor system performance, reliability, and security, implementing proactive solutions
Automate operational tasks and eliminate manual toil through scripting and tooling
Ensure high availability and disaster recovery capabilities


Developer Experience
Build and maintain internal developer tools and platforms that improve productivity
Streamline onboarding processes for new developers and reduce time-to-first-commit
Design and implement developer-friendly APIs, SDKs, and documentation
Create self-service capabilities that reduce dependencies and waiting times
Gather feedback from development teams and iterate on tooling based on pain points


Collaboration & Process Improvement
Work closely with engineering teams to understand workflow challenges and requirements
Champion best practices for code deployment, testing, and monitoring
Lead initiatives to improve development velocity and reduce friction
Participate in incident response and post-mortem analysis
Mentor team members on DevOps practices and tooling

What We're Looking For


Technical Skills
3+ years of experience in DevOps, SRE, or Platform Engineering roles
Strong proficiency with cloud platforms (AWS, GCP, or Azure)
Experience with Infrastructure as Code tools (Terraform, CloudFormation, or Pulumi)
Hands-on experience with containerization (Docker) and orchestration (Kubernetes)
Proficiency in CI/CD tools (Jenkins, GitLab CI, GitHub Actions, or similar)
Strong scripting skills in Python, Bash, or Go
Experience with monitoring and observability tools (Prometheus, Grafana, ELK stack, or similar)


Developer Experience Focus
Experience building internal tools and platforms for development teams
Understanding of software development lifecycle and common developer pain points
Familiarity with API design and developer-facing documentation
Experience with version control systems and Git workflows
Knowledge of testing frameworks and quality assurance processes


Soft Skills
Strong problem-solving abilities and analytical thinking
Excellent communication skills and ability to work with cross-functional teams
Customer-focused mindset with emphasis on developer productivity
Proactive approach to identifying and resolving issues
Ability to balance technical debt with feature delivery


Preferred Qualifications
Knowledge of security best practices and compliance frameworks
Background in software development or engineering
Familiarity with cost optimization strategies for cloud infrastructure
Previous experience in a high-growth or scaling environment

What We Offer


Competitive salary and equity package
Comprehensive health, dental, and vision insurance
Opportunity to shape developer experience across the organization
Access to cutting-edge tools and technologies


Team Culture


We believe that great developer experiences lead to better products and happier teams. Our DevOps/DX team operates as enablers and force multipliers, working collaboratively to remove friction from the development process. We value automation, measurement, and continuous improvement, always asking ""how can we make this better for our developers?""


The Pay Range For This Role Is

135,000 - 165,000 USD per year(San Mateo)

120,000 - 150,000 USD per year(New York)"
"Cloud DevOps With Azure Experience -100%Remote","The Dignify Solutions, LLC","New Jersey, United States","https://www.linkedin.com/jobs/view/cloud-devops-with-azure-experience-100%25remote-at-the-dignify-solutions-llc-4341845867?position=36&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=ZKAJaVEHguFWgKCn%2F0aQOQ%3D%3D","In-depth knowledge of Azure services, including Azure Networking, Storage, Firewall, Compute, Function, Backup and Azure DevOps
Automating routine tasks using Ansible, Python, Terraform and Azure CLI for enhanced efficiency
Minimum 4 years of specialized experience DEVOPS engineer role with full automation using Ansible .
Minimum 2 years of Azure Infrastructure automation with Terraform.
Must have experience working with Terraform and Ansible for infrastructure provisioning and configuration management, respectively.
Experience configuring and managing CI/CD pipelines with tools such as GitLab, Jenkins, etc. for enterprise-level deployments.
Configuration-level knowledge for Linux sysadmin with RHEL.
Advanced troubleshooting and problem-solving skills, related to cloud and network infrastructure
Working-level experience in Azure Cloud (Azure/Azure GOV Cloud)
Advanced experience in large scale cloud architecture, design, and integration with a focus on automation, networking and NextGen Firewall
Experience with Terraform, Ansible, and Python
Linux OS
Proficiency in multi-cloud environments, especially in AWS, is highly desirable."
"DevOps Engineer - All Levels","CodeRabbit","San Francisco, CA","https://www.linkedin.com/jobs/view/devops-engineer-all-levels-at-coderabbit-4318518267?position=37&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=5XrOT96CHl3GwvVFxLk7fg%3D%3D","About CodeRabbit

CodeRabbit is an innovative research and development company focused on building extraordinarily productive human-machine collaboration systems. Our primary goal is to create the next generation of Gen AI-driven code reviewers: a symbiotic partnership between humans and advanced algorithms that significantly outperforms individual engineers. We combine language models with human ingenuity to push the boundaries of software development efficiency and quality.

Role Overview

As a DevOps Engineer at CodeRabbit, you‚Äôll play a key role in scaling, securing, and hardening the infrastructure that powers our AI-enabled developer tools. You‚Äôll work closely with our platform engineers, backend team, and applied AI teams to ensure that our systems are resilient, observable, fast, and easy to deploy.

This is a hands-on, IC-focused role for someone who thrives in fast-paced environments, takes ownership of critical infrastructure, and wants to build tooling that unblocks an ambitious engineering team.

Responsibilities


Design, implement, and maintain scalable CI/CD pipelines
Develop and manage infrastructure as code (e.g., Terraform, Pulumi)
Improve system reliability through monitoring, alerting, logging, and failover strategies
Work with platform and backend teams to identify and resolve performance bottlenecks
Contribute to deployment workflows, environment automation, and developer tooling
Ensure infrastructure security and compliance practices are in place


Qualifications


Education: Degree in Computer Science, Engineering, or a related technical field, or equivalent practical experience
Experience: 3+ years in a DevOps, Infrastructure, or SRE role at a fast-paced tech company or startup
Tooling: Expert-level proficiency with CI/CD systems (GitHub Actions, ArgoCD, etc.), Docker, and Kubernetes
Infrastructure: Expert with cloud providers (AWS/GCP), distributed systems architecture and implementation, IaC tools (Terraform, Pulumi), and secrets management (Vault, SSM, etc.)
Observability: Strong understanding of logging, metrics, and monitoring in large-scale distributed systems (e.g., Grafana, Prometheus, ELK, Datadog)
Collaboration: Effective at partnering with backend and ML teams to deliver stable, high-velocity systems
Security: Experience building with best practices in cloud and application-level security


Bonus Points


Experience supporting AI or ML workloads in production
Experience with ephemeral environments and preview deployments
Contributions to internal platform tools or DevOps open-source projects
Past ownership of high-uptime systems or regulated environments


Why Join Us?


Build the Future: We‚Äôre redefining code review with AI. You‚Äôll help shape a new development paradigm with cutting-edge technology that has real-world impact.
Real Ownership: Every engineer at CodeRabbit owns projects end-to-end ‚Äî from proposal to production.
Collaborative & Innovative Environment: Join a tight-knit team of engineers, designers, and researchers who are passionate about building transformative products.
Professional Growth: We invest in our people ‚Äî through mentorship, responsibility, and development opportunities.
Competitive Compensation: We offer a strong salary, equity, and benefits package.
Hybrid Work Culture: We collaborate in person in the Bay Area weekly, with flexibility for heads-down remote work.


Our Values


ü§ù Collaborative Humans: Prioritizing collective intelligence
üöÄ Fearless Innovators: Turning obstacles into growth opportunities
üí™ Persistent, Passionate Developers: Thriving on complex, long-term challenges
üéØ Impact-Driven Creators: Crafting intuitive tools for developers
üß† Rapid Learners and Un-learners: Adapting quickly in our fast-paced technological world


Base pay range for this role is $180k-260k. Actual salary will be based on job-related skills, experience, and location.

Apply Now ‚Äî If you're passionate about building high-impact infrastructure and enabling AI-powered developer experiences, we‚Äôd love to hear from you.

Compensation Range: $175K - $275K"
"DevOps Engineer","Uffizio","Michigan, United States","https://www.linkedin.com/jobs/view/devops-engineer-at-uffizio-4324397378?position=38&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=RZZy60WAIuvg2dXTSGxTVg%3D%3D","N/A"
"DevOps Assistant (Entry-Level)","45PRESS","Canfield, OH","https://www.linkedin.com/jobs/view/devops-assistant-entry-level-at-45press-4301017192?position=39&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=qBkglRIdkox7xUjpmoHIDw%3D%3D","N/A"
"Senior DevOps Engineer","CEIPAL","Charlotte, NC","https://www.linkedin.com/jobs/view/senior-devops-engineer-at-ceipal-4305453358?position=40&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=bZVraPHMBvuSmZb227bfzA%3D%3D","N/A"
"DevOps engineer","OVA.Work","Alpharetta, GA","https://www.linkedin.com/jobs/view/devops-engineer-at-ova-work-4310657957?position=41&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=d3FhXuWzvPZzFbHZcyzOrg%3D%3D","N/A"
"DevOps Engineer","Hudu","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-hudu-4323191230?position=42&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=TRd%2BokkuCDqQNhERojXung%3D%3D","N/A"
"DevOps Engineer","Verra Mobility","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-verra-mobility-4335667666?position=43&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=gS9COpOgvIP1m93Bqcm2Lw%3D%3D","N/A"
"Staff Engineer: DevOps","Dispel","Austin, TX","https://www.linkedin.com/jobs/view/staff-engineer-devops-at-dispel-4339045806?position=44&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=Lkisr8gi78lwKR3iwDCC%2BA%3D%3D","N/A"
"DevOps Engineer","IT Automation LLC","Cary, NC","https://www.linkedin.com/jobs/view/devops-engineer-at-it-automation-llc-4324192032?position=45&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=zcVztF2a7No2dbToImsr%2FA%3D%3D","N/A"
"DevOps Engineer","CHEQUESPREAD PLC","Valley Forge, PA","https://www.linkedin.com/jobs/view/devops-engineer-at-chequespread-plc-4288904252?position=46&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=Bu3USDMdxSj2wGQU8yIjIg%3D%3D","N/A"
"Junior DevOps Engineer","eSimplicity","Columbia, MD","https://www.linkedin.com/jobs/view/junior-devops-engineer-at-esimplicity-4315888714?position=47&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=%2FMT6woty20NhE4CdpCfiVQ%3D%3D","N/A"
"Cloud/DevOps Engineer","Tagup, Inc.","New York, NY","https://www.linkedin.com/jobs/view/cloud-devops-engineer-at-tagup-inc-4333051833?position=48&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=%2Bb%2F4n60y04UDQrL7gyYFeA%3D%3D","N/A"
"DevOps Engineer","Mark43","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-mark43-4309062970?position=49&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=Hg88F9UCVAj6eTE%2Fd6PPUA%3D%3D","N/A"
"DevOps Engineer","CMG (Capital Markets Gateway)","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-cmg-capital-markets-gateway-4338419750?position=50&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=NwzEISJLfv7TmTs2hKY9Aw%3D%3D","N/A"
"DevOps Engineer","Mintlify","San Francisco, CA","https://www.linkedin.com/jobs/view/devops-engineer-at-mintlify-4318506680?position=51&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=urNOgoByKBq1CVSRpgzhxA%3D%3D","N/A"
"DevOps Support Engineer","Porter","New York, NY","https://www.linkedin.com/jobs/view/devops-support-engineer-at-porter-4295124575?position=52&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=kKPfQ57eGwFF%2Bhg7JugLQA%3D%3D","N/A"
"DevOps Engineer","Northstrat Incorporated","Columbia, MD","https://www.linkedin.com/jobs/view/devops-engineer-at-northstrat-incorporated-4304125676?position=53&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=1nFlqlx8DIpZpEsiWdlZTw%3D%3D","N/A"
"DevOps Engineer","Paramount","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-paramount-4335876548?position=54&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=zwiR%2F74I%2FoTnoBvd36ChVw%3D%3D","N/A"
"DevOps Engineer","SmartVault","Houston, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-smartvault-4297941616?position=55&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=n1nbiGuVgMFxGzNJtfyGkA%3D%3D","N/A"
"DevOps Engineer","RSC2, Inc.","Hanover, MD","https://www.linkedin.com/jobs/view/devops-engineer-at-rsc2-inc-4311252822?position=56&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=GLpra%2B4wjCFY4jBAtHBr3A%3D%3D","N/A"
"Cloud DevOps Support Engineer","Nihon Kohden Digital Health Solutions","Irvine, CA","https://www.linkedin.com/jobs/view/cloud-devops-support-engineer-at-nihon-kohden-digital-health-solutions-4295710052?position=57&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=sgjTGSzQyx%2FCNETFJMTgWg%3D%3D","N/A"
"DevOps Engineer","PingWind","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-pingwind-4316019938?position=58&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=mpIXb3dikS9P42uvTNRWRw%3D%3D","N/A"
"DevOps Engineer","Cymertek Corporation","San Antonio, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-cymertek-corporation-4336305401?position=59&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=kTLCWoXsQq0vLaYQzFicqg%3D%3D","N/A"
"DevOps Engineer","Ryan","Dallas, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-ryan-4284462825?position=60&pageNum=0&refId=fsoU20dYIoQZpm2iHxIqHg%3D%3D&trackingId=ZU9763wrECt9EAl%2FpVjSlQ%3D%3D","N/A"
"Mid-Junior DevOps Engineer - USA","HERE","New York, NY","https://www.linkedin.com/jobs/view/mid-junior-devops-engineer-usa-at-here-4347377348?position=1&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=zXM5OK5nf%2BBIqoGfPQnBBg%3D%3D","Mid-Junior DevOps Engineer

Location: New York, NY / Hybrid Remote / Remote within USA (EST / CST time zone)

We have an office in New York City and this position can either be based in the office, hybrid remote, or remote within the EST/CST time zones (subject to your existing legal right to work in the jurisdiction).

About HERE

Everything works right here‚Ñ¢.

Traditional browsers weren't built for work. In today's enterprise environment‚Äîwhere security threats are constant and productivity is critical‚Äîlegacy browsers fall short. That's why we built HERE, the browser purpose-built for work.

Powered by Chromium, HERE Enterprise Browser combines enterprise-grade security, seamless productivity, and native AI integration in one secure, intelligent workspace. Designed for regulated industries, HERE offers deep policy controls, identity-based access, secure workspace isolation, and full interoperability across SaaS, legacy, and virtualized environments. Our platform enables teams to work faster, more securely, and more intelligently‚Äîwithout compromise.

HERE technology is trusted by 90% of global banks and also used within the U.S. Intelligence Community and other sectors. We're backed by some of the world's most respected financial institutions and venture firms, including Bain Capital Ventures, Bank of America, J.P. Morgan, Wells Fargo and IQT, the not-for-profit strategic investor that accelerates the introduction of groundbreaking technologies to enhance the national security of America and its allies.

About the Role

HERE is seeking a mid-junior DevOps Engineer to join our infrastructure team! The primary responsibilities for this role will span CI/CD pipeline engineering and cloud operations, maintaining and improving our GitHub and GitLab CI/CD pipelines, and supporting our AWS cloud infrastructure. In this role, you will gain hands-on experience with real production build systems and cloud platforms- while having the opportunity to work on practical projects that directly impact both our development velocity and operational reliability.

We're actively evolving toward a cloud-agnostic, multi-cloud architecture and migrating to Kubernetes for container orchestration. While current AWS and ECS experience is essential, having exposure to Azure, GCP, and Kubernetes will position you well for our infrastructure roadmap.

This role offers the opportunity to collaborate with senior engineers who will provide guidance and mentorship, whilst giving you ownership of projects across the DevOps lifecycle. This is an excellent platform for building practical experience with modern build engineering (CI/CD automation, cloud infrastructure, and deployment practices) within a production environment.

Responsibilities


CI/CD Pipeline Development:
Build, maintain, and optimize GitLab CI/CD pipelines for multi-platform builds (Windows, macOS, Linux).
Work with YAML configurations, pipeline stages, artifacts, and deployment workflows.
Cloud Infrastructure Operations:
Help maintain and improve AWS infrastructure including ECS/Fargate deployments, RDS databases, Route53 DNS, VPC networking, and IAM policies.
Support multi-tenant and multi-region architecture.
Container & Deployment Management:
Work with Docker containers, ECS task definitions, and ECR registries.
Deploy and manage containerized Node.js applications in production environments.
Release Management:
Help manage release processes including version promotion, release channels (canary, beta, stable), and automated deployment to staging and production environments.
Database Operations:
Support PostgreSQL on AWS RDS‚Äîbackups, SSH tunneling through bastion hosts, read-only user management, and database configuration for multi-tenant environments.
Automation & Scripting:
Write and maintain automation scripts in Bash, PowerShell, Python, and Node.js.
Build tools to improve infrastructure reliability and developer experience.
Internal Tools Support:
Help maintain web-based DevOps tools built with Express.js, React, and TypeScript‚Äîtools for cloud settings management, tenant provisioning, and deployment monitoring.

What We're Looking For

Ideally 2 to 4 years of experience with the following core requirements:


GitLab CI/CD: Experience with GitLab CI/CD pipelines‚ÄîYAML configuration, stages, jobs, artifacts, rules, dependencies.
Understanding of CI/CD best practices and pipeline optimization.
AWS Cloud Fundamentals: Practical experience with core AWS services‚ÄîEC2, ECS/Fargate, RDS, Route53, VPC, IAM, Secrets Manager, CloudWatch. Comfortable navigating the AWS Console and CLI.
Multi-Platform Scripting: Solid scripting skills in Bash (Linux) and PowerShell (Windows). Ability to write maintainable automation scripts for both platforms.
Containerization: Hands-on Docker experience‚Äîbuilding images, writing Dockerfiles, docker-compose, understanding container networking, and working with ECS/ECR.
Build Systems: Experience with build tools and package managers‚Äînpm/Node.js, .NET/NuGet, Python packaging. Understanding of dependency management and build artifacts.
Version Control: Strong Git fundamentals‚Äîbranching strategies, merge requests, tagging. Experience with GitHub (or GitLab) workflows and code review practices.
Linux/Unix & Windows: Comfortable in both environments‚ÄîSSH, file permissions, package managers, systemd, PowerShell. Understanding of cross-platform operational challenges.
Node.js/JavaScript: Comfortable reading and writing JavaScript/Node.js code. Experience with npm, package.json, and basic Express.js applications for tooling.


Nice to Have


Kubernetes experience (EKS, GKE, AKS) or willingness to learn, we're migrating from ECS to K8s
Multi-cloud experience (Azure, GCP) or cloud-agnostic architecture knowledge
GitLab Runner administration and configuration
AWS CDK or CloudFormation for Infrastructure as Code
Terraform for multi-cloud infrastructure management
TypeScript development experience
PostgreSQL database administration and optimization
.NET build systems and NuGet package management
React or frontend framework experience
Airflow or workflow orchestration tools
Helm charts and Kubernetes manifest management


What We're Offering

Benefits -


Generous Paid Time Off, Paid Holidays & Sick Time
Competitive & Comprehensive Health Insurance
Thoughtfully-Planned Paid Parental Leave
Financial Well-Being Plans (FSA) (401k) (Life Insurance)
Stock Options
Professional Development Courses
Employee Resource Groups


Additional Perks -


One Medical - Free Membership
Talkspace - Mental Health Therapy 24/7
Team Lunches
Casual dress code
Commuter Benefits (NYC employees only)
Citibike (NYC employees only)


Life at HERE

At HERE, we pride ourselves on fostering a friendly, collaborative, and supportive culture that truly respects the diversity of thought. Our goal is to create a space where employees can learn and innovate, and overall, have a good time doing it. We value and appreciate that our employees have a wide set of interests and experiences and put importance on taking the time to get to know one another and form relationships. From virtual socials and in-person events, to informal meetings and employee resource groups, we make it easy to engage and connect. Our environment promotes a productive, enjoyable learning experience - aligned together, working to create compelling solutions for our clients. Everything works right here.‚Ñ¢

We are HERE - Read about our recent rebrand from OpenFin to HERE

Recent Awards


Voted ""Enterprise Browser of the Year"" by CIO Review (2025)
Voted ""100 Best Midsize Companies to Work For in NYC"" by BuiltIn (2025)
Voted ""Top 10 Contact Center Technologies & Capabilities of 2024"" by CX Today (2024)
Voted ""Best Enterprise Environment for Interoperability"" by TradingTech Insight Awards Europe (2024)
Voted ""Top 50 Best Startups to Work for in the US"" & ""Top 50 Best Startups to Work for in New York"" by BuiltIn (2024)
Voted as a ""Best Employer Award"" finalist at the UK FinTech Awards (2023)
Voted ""Best FinTech Company CEO"" at the FinTech Breakthrough Awards (2023)
Voted ""Best Internal Talent Team"" by Financial Technologist (2023)
Voted ""Best Solution for Workflow Automation"" at the Trading Tech Insight Awards (2023)
Voted ""Top Innovator Across Financial Markets"" in TabbFORUM NOVA Awards (2023)
Voted ""Best User Interface Innovation"" in the Risk Markets Technology Awards (2023)
Voted ""Top 100 Most Promising Private FinTech Companies"" by CB Insights (2023)
Voted ""Most Influential Financial Technology Firm"" by Harrington Starr (2023)


RECRUITERS NOTICE: Recruiters - if you wish to reach out to us regarding this job posting, you may reach out to externalrecruitment@here.io in order for your communication to be reviewed. HERE will review these communications if external help is needed for a position. Agencies may not contact individuals within our organization with solicitations. Firms that do not follow these guidelines risk having all communication from their firm being blocked. We thank you in advance for your cooperation in following our process.

Sponsorship - While we highly value all of our candidates, we are not offering sponsorship for this role.

Salary Range: $70k - $120k

Salary Range Disclaimer: This base salary range represents the low and high end salary range for this particular position; not all encompassing of the total compensation package. Actual salaries may vary depending upon but not limited to experience, special skill set, education and location. This range represents only one aspect of HERE's total compensation package offered to employees. Other forms of compensation may be stock options, commissions, paid time off and other variable benefits. Learn more about additional HERE compensation benefits above."
"junior devops engineer","OVA.Work","Alpharetta, GA","https://www.linkedin.com/jobs/view/junior-devops-engineer-at-ova-work-4309344701?position=2&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=tkz%2B%2BCRRmxgG1rz1Q3V46Q%3D%3D","Job Title: Junior DevOps Engineer

Location: Remote

Job Type: Full-time

Experience Level: Entry-Level (0-2 years)

Department: IT / Engineering / DevOps

Job Summary

We are looking for a motivated and detail-oriented Junior DevOps Engineer to join our growing DevOps team. This role is ideal for someone with a foundational understanding of DevOps practices and a passion for automation, cloud technologies, and continuous integration/deployment. You will assist in maintaining and improving our infrastructure, deployment pipelines, and monitoring systems.

Key Responsibilities


Assist in the setup, maintenance, and monitoring of CI/CD pipelines.
Support cloud infrastructure (AWS, Azure, GCP) and help manage deployments.
Collaborate with development and operations teams to ensure reliable software delivery.
Write scripts and automation tools to streamline operations and deployments.
Monitor system performance and troubleshoot issues in development and production environments.
Maintain documentation for infrastructure and deployment processes.
Learn and apply best practices in security, scalability, and reliability.


Required Qualifications


Bachelor's degree in Computer Science, Information Technology, or related field.
Basic understanding of DevOps principles and software development lifecycle.
Familiarity with Linux/Unix systems and shell scripting.
Exposure to cloud platforms (AWS, Azure, or GCP).
Experience with version control systems (e.g., Git).
Knowledge of CI/CD tools (e.g., Jenkins, GitLab CI, GitHub Actions).
Strong problem-solving and communication skills.
Eagerness to learn and grow in a fast-paced environment.


Preferred Qualifications


Internship or project experience in DevOps or system administration.
Familiarity with containerization tools (Docker) and orchestration (Kubernetes).
Experience with Infrastructure as Code (Terraform, Ansible).
Basic knowledge of monitoring tools (Prometheus, Grafana, ELK Stack).


Benefits


Competitive salary and growth opportunities.
Mentorship from senior engineers.
Health and wellness benefits.
Flexible work hours and remote work options.
Access to training and certification programs."
"DevOps Engineer - Remote","The Dignify Solutions, LLC","Newtown Square, PA","https://www.linkedin.com/jobs/view/devops-engineer-remote-at-the-dignify-solutions-llc-4341955705?position=3&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=GZgTi54cQaJ2tl1aRahtDA%3D%3D","Over 12 -15 years of overall expereince needed.
A solid foundation in computer science, with strong competencies in data structures, algorithms, and software design.
Large systems software design and development experience.
Experience performing in-depth troubleshooting and unit testing with both new and legacy production systems.
Experience in programming and experience with problem diagnosis and resolution.
Kubernetes (3-4 YOE) and Fieldglass Experience (1-2 YOE)"
"DevOps Engineer - Remote","The Dignify Solutions, LLC","Newtown Square, PA","https://www.linkedin.com/jobs/view/devops-engineer-remote-at-the-dignify-solutions-llc-4347005704?position=4&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=K%2BCwzeyWQbFBi9W5vcXEQQ%3D%3D","Bachelor's degree in a technical field such as computer science, computer engineering or related field required 0-2 years experience required.
1-2 years of experience with Kubernetes.
ISBN experience preferred.
A solid foundation in computer science , with strong competencies in data structures, algorithms, and software design large systems software design and development experience.
Experience performing in-depth troubleshooting and unit testing with both new and legacy production systems experience in programming and experience with problem diagnosis and resolution."
"Junior DevOps Engineer","GliaCell Technologies","Hanover, MD","https://www.linkedin.com/jobs/view/junior-devops-engineer-at-gliacell-technologies-4338894490?position=5&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=kL4SPerIYpm5sA39ZbYMHw%3D%3D","An active or rein-statable TS/SCI with Polygraph security clearance is REQUIRED. Please do not apply if you currently do not possess this level of clearance.***


Are you a Junior DevOps Engineer who is ready for a new challenge that will launch your career to the next level?


Tired of being treated like a company drone?
Tired of promised adventures during the hiring phase, then being dropped off on a remote contract and never seen or heard from the mothership again?
Our engineers were certainly tired of the same.


At GliaCell our slogan is ‚ÄúWe make It happen‚Äù.


We will immerse you in the latest technologies.
We will develop and support your own personalized training program to continue your individual growth.
We will provide you with work that matters with our mission-focused customers, and surround you with a family of brilliant engineers.


Culture isn‚Äôt something you need to talk about‚Ä¶if it just exists.

If this sounds interesting to you, then we‚Äôd like to have a discussion regarding your next adventure! If you want to be a drone, this isn‚Äôt the place for you.

We Make It Happen!

GliaCell Technologies focuses on Software & System Engineering in Enterprise and Cyber Security solution spaces. We excel at delivering stable and reliable software solutions using Agile Software Development principles. These provide us the capability to deliver a quick turn-around using interactive applications and the integration of industry standard software stacks.

GliaCell‚Äôs Enterprise capabilities include Full-Stack Application Development, Big Data, Cloud Technologies, Analytics, Machine Learning, AI, and DevOps Containerization. We also provide customer solutions in the areas of CND, CNE, and CNO by providing our customers with assessments and solutions in Threat Mitigation, Vulnerability Exposure, Penetration Testing, Threat Hunting, and Preventing Advanced Persistent Threat.

We Offer


Long term job security
Competitive salaries & bonus opportunities
Challenging work you are passionate about
Ability to work with some amazingly talented people


Job Description

GliaCell is seeking a Junior DevOps Engineer on one of our subcontracts. This is a full-time position offering the opportunity to support a U.S. Government customer. The mission is to provide technical expertise that assists in sustaining critical mission-related software and systems to a large government contract.

Responsibilities


Establishing a test framework and automated tests utilizing Cucumber and Cypru
Knowledgeable in Microservices design & architecture, CI/CD, Test frameworks and automation, Agile Methodology.
Execute load and performance testing, chaos testing, functional testing and end-to-end testin
Agile development and delivery of software
Communication and collaboration: Software Development is a team-oriented discipline. Engineers need to be able to communicate and collaborate effectively with other team members, as well as with stakeholders.


Required Skills


Python and Cucumber


Desired Skills:


AWS services such as Lambdas, Step Functions, EC2 and S3


Key Requirements

To be considered for this position you must have the following:


Possess an active or rein-statable TS/SCI with Polygraph security clearance.
U.S. Citizenship.
Works well independently as well as on a team.
6+ years experience as a Developer in programs and contracts of similar scope, type, and complexity is required. A bachelor‚Äôs degree in a technical discipline from an accredited college or university is required. Five (4) years of development experience may be substituted for a bachelor‚Äôs degree.


Location: Annapolis Junction, MD

Salary Range: The salary range for this full-time position is $50,000 to $120,000. Our salary ranges are determined by position, level, skills, professional experience, relevant education and certifications. The range displayed on each job posting reflects the minimum and maximum target salaries for this position across our projects. Within the range, your salary is determined by your individual benefits package selection. Your recruiter can share more about the specific salary range for your preferred position during the hiring process.

Benefits


Medical, Dental, and Vision Coverage for Employee and Dependents
Up to 25 Days of Paid Time Off
Up to 40 hours of PTO Carryover
11 Federal Government Holidays
Work From Home Opportunities
401K Company Contribution, Fully Vested Day 1
Discretionary, Certification, and Sign-On Bonus Potential
Employee Referral Bonus Program
Annual Professional Development
100% Premium Covered for Life & Disability Insurances
Additional Voluntary Life Insurance Coverage Available
Employee Assistance Program
Travel Protection Program
Financial Planning Assistance
Bereavement and Jury Duty Leave
Monthly Team and Family Events
Technology Budget
Global Entry
Annual Swag Budget


Learn more about GliaCell Technologies: https://gliacelltechnologies.applytojob.com/apply/

GliaCell Technologies, LLC is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status."
"DevOps Cloud Engineer Based in U.S.A","Advancio","United States","https://www.linkedin.com/jobs/view/devops-cloud-engineer-based-in-u-s-a-at-advancio-4324442139?position=6&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=ka4J%2BgcZ5%2FX0K3uL%2F8bbkg%3D%3D","This is a remote position.

Who We Are:


At Advancio, we are passionate about technology and its ability to transform the world. We are rapidly expanding and building a company where we serve exceptional businesses, hire top talent, and have a lot of fun doing what we love!


Job Summary:

We are seeking a skilled DevOps Cloud Engineer to design, implement, and manage scalable cloud-based infrastructure and DevOps processes. The ideal candidate will have extensive experience with cloud platforms, CI/CD pipelines, and automation tools, ensuring the efficient deployment and operation of applications.


What will you do:


Design, deploy, and manage cloud infrastructure on platforms such as AWS, Azure, or Google Cloud Platform (GCP).

Build and maintain CI/CD pipelines to streamline development and deployment processes.

Automate infrastructure provisioning, configuration, and monitoring using tools like Terraform, Ansible, or similar.

Ensure system reliability, availability, and performance through robust monitoring and alerting.

Collaborate with development teams to optimize the delivery and scalability of applications.

Manage containerized workloads using Docker and orchestration platforms such as Kubernetes.

Implement security best practices for cloud environments, including identity management, encryption, and compliance adherence.

Stay updated with the latest DevOps tools and methodologies to enhance team efficiency.




Requirements






5+ years of experience in DevOps, cloud engineering, or related roles.

Advanced English communication skills, both verbal and written.

Proficiency in at least one major cloud platform (AWS, Azure, or GCP).

Hands-on experience with CI/CD tools (e.g., Jenkins, GitLab CI/CD, CircleCI).

Strong scripting skills in Python, Bash, or similar languages.

Solid knowledge of infrastructure-as-code (IaC) tools like Terraform or CloudFormation.

Experience with containerization (Docker) and orchestration (Kubernetes).

Familiarity with monitoring and logging tools like Prometheus, Grafana, or ELK Stack.

Strong understanding of networking, security, and system architecture."
"DevOps Engineer","Princeton IT Services, Inc","Englewood Cliffs, NJ","https://www.linkedin.com/jobs/view/devops-engineer-at-princeton-it-services-inc-4338714288?position=7&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=1ZRcuADkbl44hV%2F2vLHI%2Bw%3D%3D","Job Title: DevOps Engineer

Location: Englewood Cliffs, NJ

Employment Type: W2 Only

Job Summary

We are seeking a DevOps Engineer with strong hands-on experience in Linux, Docker, and Kubernetes to support and optimize our deployment environment in Englewood Cliffs, NJ. This is a W2-only role requiring solid skills in automation, CI/CD, and container orchestration. The ideal candidate will ensure smooth application releases, maintain system stability, and collaborate closely with development teams.

Key Responsibilities


Manage and support Linux-based systems in production and staging environments.
Build, maintain, and optimize CI/CD pipelines for automated deployments.
Create, manage, and troubleshoot Docker containers and images.
Deploy, monitor, and tune Kubernetes clusters and workloads.
Automate infrastructure tasks using Shell or Python scripts.
Implement and manage monitoring and logging tools (Prometheus, Grafana, ELK, etc.).
Troubleshoot system, container, and cluster-level issues end-to-end.
Work cross-functionally with development and QA teams to ensure smooth releases.


Required Skills


8+ years of DevOps or related experience.
Strong hands-on experience with Linux administration.
Solid experience working with Docker for containerization.
Strong working knowledge of Kubernetes (deployments, scaling, troubleshooting).
Experience building CI/CD pipelines (Jenkins, GitLab CI, GitHub Actions).
Strong scripting skills in Shell/Bash/Python.
Experience with monitoring and logging tools."
"DevOps Engineer","Lean TECHniques","Johnston, IA","https://www.linkedin.com/jobs/view/devops-engineer-at-lean-techniques-4336685413?position=8&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=K57KPrvB%2FpYjSE4cCDZrHg%3D%3D","Maybe you‚Äôre bored and need a new challenge. Or you‚Äôre sick of all the bureaucracy and just want to focus on designing kick-ass software.

Whatever the reason, we want you to know that LT is different. And not just air quotes ‚Äúdifferent,‚Äù but more like ‚Äúbreathing easy for the first time in a long time‚Äù different.

It‚Äôs a place where you can write your own story and make a difference along the way. At LT, you‚Äôll have the freedom and flexibility to do what you think needs to be done, and you‚Äôll get to do it while working alongside a team of other curious individuals who love a good challenge too.

We‚Äôre currently looking to add a DevOps Engineer to our crew of nerds. If you‚Äôre someone who has 5+ years of DevOps experience, we'd love to chat!"
"DevOps Engineer","LifeMD","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-lifemd-4337132819?position=9&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=KcNF%2BD3GfDnsNzdH0U%2Fe3A%3D%3D","About us:

LifeMD is a leading digital healthcare company committed to expanding access to virtual care, pharmacy services, and diagnostics by making them more affordable and convenient for all.¬†Focused on both treatment and prevention, our unique care model is designed to optimize the patient experience and improve outcomes across more than 200 health concerns.¬†

To support our expanding patient base, LifeMD leverages a vertically-integrated, proprietary digital care platform, a 50-state affiliated medical group, a 22,500-square-foot affiliated pharmacy, and a U.S.-based patient care center.¬†Our company ‚Äî with offices in New York City; Greenville, SC; and Huntington Beach, CA ‚Äî is powered by a dynamic team of passionate professionals. From clinicians and technologists to creatives and analysts, we're united by a shared mission to revolutionize healthcare.¬†Employees enjoy a collaborative and inclusive work environment, hybrid work culture, and numerous opportunities for growth. Want your work to matter? Join us in building a future of accessible, innovative, and compassionate care.


About the role:

LifeMD is seeking a highly motivated and experienced DevOps Engineer to join our dynamic Technology team. This individual will serve as a critical link between software development and IT operations, playing a pivotal role in designing, implementing, and maintaining automated processes for software delivery, infrastructure management, and system monitoring. The primary objective is to accelerate our release cycles, enhance system stability, and improve overall operational efficiency across our diverse cloud infrastructure, all while strictly adhering to stringent healthcare industry compliance standards, including HIPAA and SOX.


Responsibilities:


Design, implement, and manage scalable, secure, and cost-effective cloud infrastructure primarily on AWS using Terraform
Develop and version control Terraform modules for automated provisioning, updating, and de-provisioning of cloud resources (e.g., EC2, S3, RDS, VPC, Lambda in AWS)
Design, build, and optimize automated CI/CD pipelines using GitHub Actions for various applications and microservices
Integrate automated testing, static code analysis, security scanning, and deployment steps into CI/CD workflows for high quality and secure releases
Implement, configure, and maintain comprehensive monitoring, logging, and alerting solutions (e.g., AWS CloudWatch, Datadog) for all environments
Develop custom dashboards, metrics, and alerts for real-time visibility into system health, performance, and security events
Proactively analyze logs and metrics to identify potential bottlenecks and issues
Participate in on-call rotations to swiftly respond to and resolve critical incidents, ensuring high service availability
Automate repetitive operational tasks, system configurations, and deployment processes using Python and Bash to enhance efficiency



Requirements



Basic Qualifications:

Bachelor's degree in Computer Science, Information Technology, Engineering, or a related technical field, or equivalent work experience
3+ years of progressive experience as a DevOps Engineer, Site Reliability Engineer (SRE), or similar role in a cloud-native environment
Expert-level proficiency in AWS services (EC2, S3, RDS, VPC, Lambda, IAM, CloudWatch, etc.). Solid understanding and working knowledge of GCP, Digital Ocean, and Azure concepts and services
Expertise in Terraform for multi-cloud infrastructure provisioning and management, including experience with state management, modules, and workspaces
Highly skilled in using Git and GitHub for source code management, branching strategies, and pull request workflows
Hands-on experience with implementing and managing monitoring and logging solutions (e.g., AWS CloudWatch, Datadog, ELK stack)
Solid understanding of cloud networking concepts, including VPCs, subnets, routing tables, load balancers, DNS, and VPNs
Strong understanding of cloud security best practices, identity and access management (IAM), security groups, network ACLs, and data protection principles
Working knowledge of database concepts and experience with various database types (e.g., MongoDB, PostgreSQL, MySQL)
Strong understanding and implementation of Ansible for cloud workload automations
Hands-on experience with Linux (Ubuntu) and update/patching mechanisms



Preferred Qualifications:

Experience in the healthcare industry or a highly regulated environment, with a demonstrable understanding of compliance requirements (e.g., HIPAA, SOC2)
Relevant cloud certifications (e.g., AWS Certified DevOps Engineer - Professional, AWS Certified Solutions Architect - Associate/Professional)
In-depth experience with GitHub Actions for designing, implementing, and maintaining automated build, test, and deployment pipelines. Familiarity with other CI/CD tools
Strong proficiency in Python and Bash scripting for automation, system administration, and tool development.
Knowledge of Node.js or PHP
Experience with Docker for containerizing applications. Familiarity with container orchestration platforms (e.g., Kubernetes, AWS ECS)
Exceptional problem-solving and analytical skills with a proactive approach to identifying and resolving complex technical issues
Excellent communication and interpersonal skills, capable of effectively collaborating with diverse cross-functional teams (developers, QA, product, security)
Strong sense of ownership, accountability, and ability to work independently while also being a strong team player
A continuous learning mindset, staying updated with emerging technologies, industry trends, and best practices in the DevOps space
Meticulous attention to detail and strong documentation skills



Benefits


Salary Range: $130,000-$140,000
Health Care Plan (Medical, Dental & Vision)
Retirement Plan (401k, IRA)
Life Insurance (Basic, Voluntary & AD&D)
Unlimited PTO Policy
Paid Holidays
Short Term & Long Term Disability
Training & Development"
"DevOps Engineer (35 LPA - 55 LPA)","CodeRound AI","Greater Bloomington Area","https://www.linkedin.com/jobs/view/devops-engineer-35-lpa-55-lpa-at-coderound-ai-4308183910?position=10&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=ehgrXv0BX1v5qf8xlDYxKw%3D%3D","üöÄ What We‚Äôre Building


CodeRound AI matches top 5% tech talent to fastest growing VC funded AI startups.
Candidates apply once and get UPTO 10 remote as well as onsite interview opportunities IF selected!
Top-tier product startups in US, UAE & India have hired top engineers & ML folk using CodeRound


üß© What You‚Äôll Do


Build and optimize our cloud infrastructure ‚Äî scalable, secure, and cost-effective (mostly AWS).
Set up and manage CI/CD pipelines to ensure smooth deployment across backend, AI services, and mobile.
Containerize backend services (FastAPI, Rails) and optimize them for performance.
Implement monitoring, alerting, and logging to catch issues before users do.
Optimize database performance (Postgres, Redis) and manage backups and scaling.
Collaborate with backend, AI, and product teams to deploy new features safely and quickly.
Champion infra-as-code and automation wherever possible.


üí• Why this is exciting


You'll own DevOps for a high-usage, real-world AI platform ‚Äî not just internal tools.
You‚Äôll work on real-time, high-stakes flows ‚Äî interviews, scoring, hiring decisions.
You‚Äôll work closely with founders, ship weekly, and see the direct impact of your work.


‚úÖ You‚Äôll Be Great At This If You


Have 4+ years of experience as a DevOps engineer, SRE, or infrastructure engineer.
Are strong with AWS services (EC2, RDS, ECS/EKS, S3, CloudWatch).
Can write clean, reusable Terraform or CloudFormation code.
Have experience setting up CI/CD pipelines and optimizing build/release flows.
Are comfortable with Docker, Linux servers, and basic networking (VPCs, security groups).
Understand application and database scaling (horizontal/vertical).


‚ö° Bonus If You


Have experience supporting AI/ML pipelines in production (fine-tuning infra, vector DBs, etc.).
Know cost optimization tricks for cloud infra (spot instances, autoscaling groups, etc.).
Are excited to eventually build a small infra team"
"Devops Engineer","The Dignify Solutions, LLC","Brooklyn, OH","https://www.linkedin.com/jobs/view/devops-engineer-at-the-dignify-solutions-llc-4341915759?position=11&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=oO2GiEvZ5Gm8eM0VH%2FvFqA%3D%3D","Job Description:


Serve as a subject matter expert to develop and support DevOps Web Access Management solutions
Install, configure, and maintain automation solutions, in support of KeyBank infrastructure
Develop Standard Operating Procedures, maintenance plans and provide status reports as required
Perform daily operational tasks as required for the Web Access Management team


Qualifications:


General technical capabilities across all portions of the infrastructure stacks
Independent thinker and self-starter
Generates ideas, innovative
Experienced with automation frameworks using an automation first approach
Proficient in one or more programming/scripting languages (Python, Ansible, etc.)
Proficient with one or more cloud orchestration tools (Terraform, Cloud Formation, etc.)
Conduct performance analysis and optimization
Experienced with public cloud providers such as GCP, Azure and AWS
Comfortable operating in a Linux environment


Preferred Skills:


Public and Private Cloud automation experience in production & non-production environments
Knowledge of web access management technologies and deployments
Knowledge of web access management technologies and deployments
Knowledge of routing & switching technologies and configurations
Knowledge of compute and storage solutions in data center environments
Experience with Service Now change management and problem management platform
Ability to balance workload amidst competing deadlines
Ability to perform knowledge transfers with peer engineers
Contribute to the reliability, performance, supportability, and security of web access management infrastructure
Review procedures for change and configuration management in all environments"
"DevOps Engineer","LifeMD","Huntington Beach, CA","https://www.linkedin.com/jobs/view/devops-engineer-at-lifemd-4337182535?position=12&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=tQmoRbLu97bUENWYReyqlw%3D%3D","About us:

LifeMD is a leading digital healthcare company committed to expanding access to virtual care, pharmacy services, and diagnostics by making them more affordable and convenient for all.¬†Focused on both treatment and prevention, our unique care model is designed to optimize the patient experience and improve outcomes across more than 200 health concerns.¬†

To support our expanding patient base, LifeMD leverages a vertically-integrated, proprietary digital care platform, a 50-state affiliated medical group, a 22,500-square-foot affiliated pharmacy, and a U.S.-based patient care center.¬†Our company ‚Äî with offices in New York City; Greenville, SC; and Huntington Beach, CA ‚Äî is powered by a dynamic team of passionate professionals. From clinicians and technologists to creatives and analysts, we're united by a shared mission to revolutionize healthcare.¬†Employees enjoy a collaborative and inclusive work environment, hybrid work culture, and numerous opportunities for growth. Want your work to matter? Join us in building a future of accessible, innovative, and compassionate care.


About the role:

LifeMD is seeking a highly motivated and experienced DevOps Engineer to join our dynamic Technology team. This individual will serve as a critical link between software development and IT operations, playing a pivotal role in designing, implementing, and maintaining automated processes for software delivery, infrastructure management, and system monitoring. The primary objective is to accelerate our release cycles, enhance system stability, and improve overall operational efficiency across our diverse cloud infrastructure, all while strictly adhering to stringent healthcare industry compliance standards, including HIPAA and SOX.


Responsibilities:


Design, implement, and manage scalable, secure, and cost-effective cloud infrastructure primarily on AWS using Terraform
Develop and version control Terraform modules for automated provisioning, updating, and de-provisioning of cloud resources (e.g., EC2, S3, RDS, VPC, Lambda in AWS)
Design, build, and optimize automated CI/CD pipelines using GitHub Actions for various applications and microservices
Integrate automated testing, static code analysis, security scanning, and deployment steps into CI/CD workflows for high quality and secure releases
Implement, configure, and maintain comprehensive monitoring, logging, and alerting solutions (e.g., AWS CloudWatch, Datadog) for all environments
Develop custom dashboards, metrics, and alerts for real-time visibility into system health, performance, and security events
Proactively analyze logs and metrics to identify potential bottlenecks and issues
Participate in on-call rotations to swiftly respond to and resolve critical incidents, ensuring high service availability
Automate repetitive operational tasks, system configurations, and deployment processes using Python and Bash to enhance efficiency



Requirements



Basic Qualifications:

Bachelor's degree in Computer Science, Information Technology, Engineering, or a related technical field, or equivalent work experience
3+ years of progressive experience as a DevOps Engineer, Site Reliability Engineer (SRE), or similar role in a cloud-native environment
Expert-level proficiency in AWS services (EC2, S3, RDS, VPC, Lambda, IAM, CloudWatch, etc.). Solid understanding and working knowledge of GCP, Digital Ocean, and Azure concepts and services
Expertise in Terraform for multi-cloud infrastructure provisioning and management, including experience with state management, modules, and workspaces
Highly skilled in using Git and GitHub for source code management, branching strategies, and pull request workflows
Hands-on experience with implementing and managing monitoring and logging solutions (e.g., AWS CloudWatch, Datadog, ELK stack)
Solid understanding of cloud networking concepts, including VPCs, subnets, routing tables, load balancers, DNS, and VPNs
Strong understanding of cloud security best practices, identity and access management (IAM), security groups, network ACLs, and data protection principles
Working knowledge of database concepts and experience with various database types (e.g., MongoDB, PostgreSQL, MySQL)
Strong understanding and implementation of Ansible for cloud workload automations
Hands-on experience with Linux (Ubuntu) and update/patching mechanisms



Preferred Qualifications:

Experience in the healthcare industry or a highly regulated environment, with a demonstrable understanding of compliance requirements (e.g., HIPAA, SOC2)
Relevant cloud certifications (e.g., AWS Certified DevOps Engineer - Professional, AWS Certified Solutions Architect - Associate/Professional)
In-depth experience with GitHub Actions for designing, implementing, and maintaining automated build, test, and deployment pipelines. Familiarity with other CI/CD tools
Strong proficiency in Python and Bash scripting for automation, system administration, and tool development.
Knowledge of Node.js or PHP
Experience with Docker for containerizing applications. Familiarity with container orchestration platforms (e.g., Kubernetes, AWS ECS)
Exceptional problem-solving and analytical skills with a proactive approach to identifying and resolving complex technical issues
Excellent communication and interpersonal skills, capable of effectively collaborating with diverse cross-functional teams (developers, QA, product, security)
Strong sense of ownership, accountability, and ability to work independently while also being a strong team player
A continuous learning mindset, staying updated with emerging technologies, industry trends, and best practices in the DevOps space
Meticulous attention to detail and strong documentation skills



Benefits


Salary Range: $130,000-$140,000
Health Care Plan (Medical, Dental & Vision)
Retirement Plan (401k, IRA)
Life Insurance (Basic, Voluntary & AD&D)
Unlimited PTO Policy
Paid Holidays
Short Term & Long Term Disability
Training & Development"
"Devops Engineer","Hoplite Solutions LLC","Bethesda, MD","https://www.linkedin.com/jobs/view/devops-engineer-at-hoplite-solutions-llc-4336082750?position=13&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=UucqyUc2vb%2BWsUXQXIbw0A%3D%3D","Hoplite Solutions is hiring DevOps Engineers at all experience levels to join our team in Bethesda, MD. In this mission-critical role, you will provide essential system support to our customer while collaborating closely with software development teams and other key technology stakeholders. You will help maintain, enhance, and support a range of IC enterprise products‚Äîboth legacy systems and new solutions‚Äîwithin an Agile SAFe environment.

As a DevOps Engineer, you will work hand-in-hand with software engineering teams to deploy and operate systems, automate and optimize processes, and build and maintain tools that support deployment, monitoring, and ongoing operations. You will also troubleshoot and resolve issues across development, test, and production environments, ensuring reliability, efficiency, and continuous improvement across the enterprise.

Primary Responsibilities:


Supports software deployments, cloud infrastructure baselines, and operational availability of production systems
Managing, building, configuring, administering, operating and maintaining all components that comprise the DevOps environment
Defining enterprise Continuous Integration/Continuous Deployment processes and best practices
Codifying DevOps best practices across the enterprise
Developing and maintaining scripts to automate tool deployment to an AWS cloud environment and other tasks
Scripting and maintaining build environments
Working with project teams to integrate their products into the DevOps environment


Basic Qualifications


Demonstrated experience setting up one or more of the following tools: GitHub, Jira, Confluence, Jenkins, and Katalon Studio
Demonstrated experience troubleshooting issues with two or more of the following tools: GitHub, Jira, Confluence, Jenkins, and Katalon Studio
Demonstrated experience working within a software development team and supporting developers and developer activities
Bachelors degree with 4 or more years of prior relevant work experience or Masters with 2 or more years of prior relevant work experience. Will consider additional work experience in lieu of a degree
To be considered must have an active TS/SCI with polygraph security clearance


Preferred Qualifications


AWS Associate Certification (Developer, Solution Architect, or Sys Ops Administrator)
AWS Professional Certification (DevOps Engineer or Solutions Architect)
Demonstrated experience in container orchestration using Docker, Vagrant, Kubernetes, or AWS ECS/ECR
Demonstrated experience with Languages including Java, Python, JavaScript, Ruby, PHP, and Unix shell Scripting
Demonstrated experience with Ansible, or Puppet


Hoplite Solutions offers very competitive salaries and an excellent benefits package, to include a 7% employer 401k contribution, fully paid healthcare for our employees, outstanding training benefits, company funded life insurance and short-term disability insurance, and many more.

Powered by JazzHR

wwBe8pS8mn"
"DevOps Engineer","The Dignify Solutions, LLC","Brooklyn, OH","https://www.linkedin.com/jobs/view/devops-engineer-at-the-dignify-solutions-llc-4341985652?position=14&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=CS1aiq6vHzov4ybjNaoBww%3D%3D","Qualifications:


General technical capabilities across all portions of the infrastructure stacks
Independent thinker and self-starter
Generates ideas, innovative
Experienced with automation frameworks using an automation first approach
Proficient in one or more programming/scripting languages (Python, Ansible, etc.)
Proficient with one or more cloud orchestration tools (Terraform, Cloud Formation, etc.)
Conduct performance analysis and optimization
Experienced with public cloud providers such as GCP, Azure and AWS
Comfortable operating in a Linux environment


Preferred Skills:


Public and Private Cloud automation experience in production & non-production environments
Knowledge of web access management technologies and deployments
Knowledge of web access management technologies and deployments
Knowledge of routing & switching technologies and configurations
Knowledge of compute and storage solutions in data center environments
Experience with Service Now change management and problem management platform
Ability to balance workload amidst competing deadlines
Ability to perform knowledge transfers with peer engineers
Contribute to the reliability, performance, supportability, and security of web access management infrastructure
Review procedures for change and configuration management in all environments."
"DevOps Engineer","Verra Mobility","Indianapolis, IN","https://www.linkedin.com/jobs/view/devops-engineer-at-verra-mobility-4339356296?position=15&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=xtA1sr87D3XmOzJ3o%2B5eXg%3D%3D","N/A"
"DevOps Engineer","Protege","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-protege-4331315574?position=16&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=Fq%2FsSJR39wzN%2FmpQTpveJA%3D%3D","N/A"
"Devops Engineer","PDG Consulting","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-pdg-consulting-4321885957?position=17&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=obskFC8JVKVQprmXcjU9Fg%3D%3D","N/A"
"DevOps Engineer - 100% Remote","The Dignify Solutions, LLC","Newtown Square, PA","https://www.linkedin.com/jobs/view/devops-engineer-100%25-remote-at-the-dignify-solutions-llc-4347005722?position=18&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=lELrSQDJZvSfCO5wx9ntzA%3D%3D","N/A"
"CloudOps Engineer","Protera","United States","https://www.linkedin.com/jobs/view/cloudops-engineer-at-protera-4336621571?position=19&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=4hUyXcV1PrIt1xme1uVEnw%3D%3D","N/A"
"DevOps Systems Engineer","TensorWave","Las Vegas, NV","https://www.linkedin.com/jobs/view/devops-systems-engineer-at-tensorwave-4338727303?position=20&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=cxYQ7i1hFbLKka85IoFM0Q%3D%3D","N/A"
"DevOps Administrator","The Amatriot Group","Dallas, TX","https://www.linkedin.com/jobs/view/devops-administrator-at-the-amatriot-group-4310974393?position=21&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=txlyKygbhw1YFlLqVI4sbw%3D%3D","N/A"
"DevOps Engineer","Arize AI","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-arize-ai-4332964631?position=22&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=lpLZIP8%2ByMr3q5ptpbenxw%3D%3D","N/A"
"DevOps Engineer","Sustainment","Austin, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-sustainment-4335637240?position=23&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=a8EERfjvwLEK2hd3l6fuZw%3D%3D","N/A"
"Devops","The Dignify Solutions, LLC","Phoenix, AZ","https://www.linkedin.com/jobs/view/devops-at-the-dignify-solutions-llc-4347025595?position=24&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=De4L2w63LVZcSLzp8hJJBQ%3D%3D","N/A"
"DevOps Engineer I","Trustwell","Portland, OR","https://www.linkedin.com/jobs/view/devops-engineer-i-at-trustwell-4321600458?position=25&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=xkAR5tyvHbWNZ6RkeG5rew%3D%3D","N/A"
"DevOps Engineer","OVA.Work","Alpharetta, GA","https://www.linkedin.com/jobs/view/devops-engineer-at-ova-work-4338475165?position=26&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=itcRIh9d5EO3d0PZnZz5dQ%3D%3D","N/A"
"DevOps Engineer (JIRA)","Rubix Solutions","Washington, DC","https://www.linkedin.com/jobs/view/devops-engineer-jira-at-rubix-solutions-4335995983?position=27&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=vhVR4LvYtfCBJQvb8saAgQ%3D%3D","N/A"
"DevOps Engineer","Chartmetric","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-chartmetric-4291046434?position=28&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=QArZDHJUUhxJV%2FDjcFUCvQ%3D%3D","N/A"
"DevOps Engineer","Broad Reach Partners","Alpharetta, GA","https://www.linkedin.com/jobs/view/devops-engineer-at-broad-reach-partners-4303987210?position=29&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=OZny5Gzr8QK2YwJWUs1Sfg%3D%3D","N/A"
"AWS DevOps Specialist","Focus School Software","St. Petersburg, FL","https://www.linkedin.com/jobs/view/aws-devops-specialist-at-focus-school-software-4333597594?position=30&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=dMH1qNgIOXKK90A%2FjCuiXQ%3D%3D","N/A"
"DevOps Engineer","Rain","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-rain-4318510257?position=31&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=7Fk637abVnZizHDOmVheFw%3D%3D","N/A"
"DevOps Engineer","Jasper","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-jasper-4318500931?position=32&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=Uro07j7j0dZmS5FReFoOVw%3D%3D","N/A"
"DevOps / Systems Engineer","Collate","San Francisco, CA","https://www.linkedin.com/jobs/view/devops-systems-engineer-at-collate-4302854141?position=33&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=SRX45Qe5zExP6fV5EJZWbQ%3D%3D","N/A"
"DevOps Engineer","Chartmetric","San Mateo, CA","https://www.linkedin.com/jobs/view/devops-engineer-at-chartmetric-4304688090?position=34&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=lpWi22IHuWB6SmXiZ6aStw%3D%3D","N/A"
"Cloud DevOps With Azure Experience -100%Remote","The Dignify Solutions, LLC","New Jersey, United States","https://www.linkedin.com/jobs/view/cloud-devops-with-azure-experience-100%25remote-at-the-dignify-solutions-llc-4341845867?position=35&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=gQPeBEoOs0U0EFXciehPnQ%3D%3D","N/A"
"DevOps Engineer - All Levels","CodeRabbit","San Francisco, CA","https://www.linkedin.com/jobs/view/devops-engineer-all-levels-at-coderabbit-4318518267?position=36&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=8cQBQy3xTlHa3BXvE3QGVw%3D%3D","N/A"
"DevOps Engineer","Uffizio","Michigan, United States","https://www.linkedin.com/jobs/view/devops-engineer-at-uffizio-4324397378?position=37&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=cPYwSeINdVdjF2kpGSVSmQ%3D%3D","N/A"
"DevOps Assistant (Entry-Level)","45PRESS","Canfield, OH","https://www.linkedin.com/jobs/view/devops-assistant-entry-level-at-45press-4301017192?position=38&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=HpNOzcMLEVAKEUFQy5BD4A%3D%3D","N/A"
"Senior DevOps Engineer","CEIPAL","Charlotte, NC","https://www.linkedin.com/jobs/view/senior-devops-engineer-at-ceipal-4305453358?position=39&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=AXi1kS8HBtbDKo5mzYSNgA%3D%3D","N/A"
"DevOps engineer","OVA.Work","Alpharetta, GA","https://www.linkedin.com/jobs/view/devops-engineer-at-ova-work-4310657957?position=40&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=%2BHwW%2Bwlnfj58NfLYbFWWIQ%3D%3D","N/A"
"DevOps Engineer","Hudu","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-hudu-4323191230?position=41&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=yWUJo1XK8E8wy14zlUcT%2FA%3D%3D","N/A"
"DevOps Engineer","Verra Mobility","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-verra-mobility-4335667666?position=42&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=QyVs%2BAwmihzBxD%2BMm7sVwQ%3D%3D","N/A"
"Staff Engineer: DevOps","Dispel","Austin, TX","https://www.linkedin.com/jobs/view/staff-engineer-devops-at-dispel-4339045806?position=43&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=oJ0MDuUbvGSD0MtScPrqMQ%3D%3D","N/A"
"DevOps Engineer","IT Automation LLC","Cary, NC","https://www.linkedin.com/jobs/view/devops-engineer-at-it-automation-llc-4324192032?position=44&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=yTt3taAiwpxFTLScwfkz9A%3D%3D","N/A"
"DevOps Engineer","CHEQUESPREAD PLC","Valley Forge, PA","https://www.linkedin.com/jobs/view/devops-engineer-at-chequespread-plc-4288904252?position=45&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=D4VuwLAAQAje%2BsAr1Rlhwg%3D%3D","N/A"
"Junior DevOps Engineer","eSimplicity","Columbia, MD","https://www.linkedin.com/jobs/view/junior-devops-engineer-at-esimplicity-4315888714?position=46&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=2AjRyUyX9CO6sKBbB04c7g%3D%3D","N/A"
"Cloud/DevOps Engineer","Tagup, Inc.","New York, NY","https://www.linkedin.com/jobs/view/cloud-devops-engineer-at-tagup-inc-4333051833?position=47&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=452WoIW8Bc9tUB%2FejOolbw%3D%3D","N/A"
"DevOps Engineer","Mark43","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-mark43-4309062970?position=48&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=0tYgSn1V6eO90Zpztd%2FJwg%3D%3D","N/A"
"DevOps Engineer","CMG (Capital Markets Gateway)","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-cmg-capital-markets-gateway-4338419750?position=49&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=522GVKb5Ak%2FRbe2f6D9YpQ%3D%3D","N/A"
"DevOps Engineer","Mintlify","San Francisco, CA","https://www.linkedin.com/jobs/view/devops-engineer-at-mintlify-4318506680?position=50&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=9gkruYr0dFveTD5RTzDWeA%3D%3D","N/A"
"DevOps Support Engineer","Porter","New York, NY","https://www.linkedin.com/jobs/view/devops-support-engineer-at-porter-4295124575?position=51&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=abB%2FSXPFqi5lcNOnzIaKYw%3D%3D","N/A"
"DevOps Engineer","Northstrat Incorporated","Columbia, MD","https://www.linkedin.com/jobs/view/devops-engineer-at-northstrat-incorporated-4304125676?position=52&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=YfltAawkbLHQ7T8n9vY4BA%3D%3D","N/A"
"DevOps Engineer","Paramount","New York, NY","https://www.linkedin.com/jobs/view/devops-engineer-at-paramount-4335876548?position=53&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=lORSZZryxRM1yEL9SCMTHA%3D%3D","N/A"
"DevOps Engineer","RSC2, Inc.","Hanover, MD","https://www.linkedin.com/jobs/view/devops-engineer-at-rsc2-inc-4311252822?position=54&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=SQ4IeFXOyVVhd3%2BfHpA1%2Bw%3D%3D","N/A"
"DevOps Engineer","SmartVault","Houston, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-smartvault-4297941616?position=55&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=GuiwHwLy3ZG2BbzYOPwT0Q%3D%3D","N/A"
"Cloud DevOps Support Engineer","Nihon Kohden Digital Health Solutions","Irvine, CA","https://www.linkedin.com/jobs/view/cloud-devops-support-engineer-at-nihon-kohden-digital-health-solutions-4295710052?position=56&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=kBAuZt61srQhNV4WzjIsHQ%3D%3D","N/A"
"DevOps Engineer","PingWind","United States","https://www.linkedin.com/jobs/view/devops-engineer-at-pingwind-4316019938?position=57&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=2iTVJo5CA8fmNaYOg1SBlw%3D%3D","N/A"
"Senior DevOps Engineer","Industrial Color","New York, NY","https://www.linkedin.com/jobs/view/senior-devops-engineer-at-industrial-color-4338405772?position=58&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=Yuwsu%2B6MgxjOSi%2FOP569SQ%3D%3D","N/A"
"DevOps Engineer","Ryan","Dallas, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-ryan-4284462825?position=59&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=TfK5tp6iAHP47Y9VIDxbdw%3D%3D","N/A"
"DevOps Engineer","Cymertek Corporation","San Antonio, TX","https://www.linkedin.com/jobs/view/devops-engineer-at-cymertek-corporation-4336305401?position=60&pageNum=0&refId=fSO1Rie3CWefyAk74vn6dQ%3D%3D&trackingId=KngWF16PfjDQO0xCzJ1O2A%3D%3D","N/A"